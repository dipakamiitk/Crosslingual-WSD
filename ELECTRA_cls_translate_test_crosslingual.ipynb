{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ELECTRA_cls_translate_test_crosslingual.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c6d48f246e8749e2abcfb16af52d5287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4f3443b37ab4451cb9a4a4ba2ebce2d5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2516e2a32aaf46b08241d8ec0ee1fedf",
              "IPY_MODEL_2f4166eb0f684e229158e130beb2fe1c"
            ]
          }
        },
        "4f3443b37ab4451cb9a4a4ba2ebce2d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2516e2a32aaf46b08241d8ec0ee1fedf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b5612faed808466ba2b007ba3d110793",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c946f8482c6d4136a5dfff1711cbf9d4"
          }
        },
        "2f4166eb0f684e229158e130beb2fe1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2d952722be754225abbe4071e40b4f03",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:01&lt;00:00, 161kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_93cad652a03544da86626e71d655bac4"
          }
        },
        "b5612faed808466ba2b007ba3d110793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c946f8482c6d4136a5dfff1711cbf9d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d952722be754225abbe4071e40b4f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "93cad652a03544da86626e71d655bac4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f46330dc380b459b9880548004f1fabd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_22e5185433a748e69ec8b5ed73d3b2ae",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e42db28e7ed149088cb91da2af1e356e",
              "IPY_MODEL_974cc57c10e84e5294c05868a21be487"
            ]
          }
        },
        "22e5185433a748e69ec8b5ed73d3b2ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e42db28e7ed149088cb91da2af1e356e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9b10b37818f04971a879b567c33bf220",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_579aed7ae1944a7ab86ba698b952b22b"
          }
        },
        "974cc57c10e84e5294c05868a21be487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7976129a14d74d24a21deb191f14a2df",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 849kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7e1e4b4133cf47229e02b816d82bce98"
          }
        },
        "9b10b37818f04971a879b567c33bf220": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "579aed7ae1944a7ab86ba698b952b22b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7976129a14d74d24a21deb191f14a2df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7e1e4b4133cf47229e02b816d82bce98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3cd8216eaef24542810ccb25e2fbb364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_33e195bd84c14ba9a84c4dfacc2646e8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ef15a2bd9d104cc9beee4f4157219ef4",
              "IPY_MODEL_5aa4b20ebd144772a41ab9210bc9626e"
            ]
          }
        },
        "33e195bd84c14ba9a84c4dfacc2646e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef15a2bd9d104cc9beee4f4157219ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d96a517d90b04aeead6ac5f03619173b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 469,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 469,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61c2846597c84ccd883c214f4df26525"
          }
        },
        "5aa4b20ebd144772a41ab9210bc9626e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e0d7f1e503c2434b8aba540439627806",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 469/469 [00:01&lt;00:00, 428B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_62f29a56e1c447c2837d480821d4adb9"
          }
        },
        "d96a517d90b04aeead6ac5f03619173b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61c2846597c84ccd883c214f4df26525": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e0d7f1e503c2434b8aba540439627806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "62f29a56e1c447c2837d480821d4adb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b72fd1319694a0284a963715212768e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_664389fcd63a4ed79aab5cb32c002ec0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_809df8c26cb24a75a6bf9509bbcc070c",
              "IPY_MODEL_9a282e8f5d1c4bea92973f9beec64138"
            ]
          }
        },
        "664389fcd63a4ed79aab5cb32c002ec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "809df8c26cb24a75a6bf9509bbcc070c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_38fbe02c53e34e269e40f17b21f3e063",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1344867008,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1344867008,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6abf7621bbfa440abdbde593757d86fb"
          }
        },
        "9a282e8f5d1c4bea92973f9beec64138": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_767ecc3c4386491589ecfc30f3c58a8e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.34G/1.34G [00:33&lt;00:00, 40.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f8d75d04b03a453b9ae0a645464e05ad"
          }
        },
        "38fbe02c53e34e269e40f17b21f3e063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6abf7621bbfa440abdbde593757d86fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "767ecc3c4386491589ecfc30f3c58a8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f8d75d04b03a453b9ae0a645464e05ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dipakamiitk/Crosslingual-WSD/blob/master/ELECTRA_cls_translate_test_crosslingual.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xya_BS1ic9q"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0Qy2pr4CnkY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a88084b-9500-49a6-95fc-535158ab79af"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvQ33K0jOjWu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8224ab3-d73b-4ed1-fcf0-f4b49254c57f"
      },
      "source": [
        "! ls \"/content/drive/My Drive/datasets/Split_WiC_dataset\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine_Sim  dev  train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMZslOtNoSby",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "d80ccc29-a9fa-493a-d03a-ef5a0c3f4f69"
      },
      "source": [
        "train_mcl_df = pd.read_csv(\"/content/drive/MyDrive/datasets/MCL_WiC_old_format/mcl_train_translated_7by8.csv\").rename(columns = {\"sent2\":\"byee\", \"sent2_tr\":\"sent2\"})\n",
        "\n",
        "train_mcl_df = pd.read_csv(\"/content/drive/MyDrive/datasets/final/train_rev_mcl.csv\")\n",
        "\n",
        "print(train_mcl_df)\n",
        "train_mcl_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            lemma   pos  ...  tag                    id\n",
            "0            play  NOUN  ...    F      training.en-en.0\n",
            "1            play  NOUN  ...    F      training.en-en.1\n",
            "2          esteem  NOUN  ...    T      training.en-en.2\n",
            "3          esteem  NOUN  ...    T      training.en-en.3\n",
            "4          holder  NOUN  ...    T      training.en-en.4\n",
            "...           ...   ...  ...  ...                   ...\n",
            "15995  positivity  NOUN  ...    T  training.en-en.15995\n",
            "15996     backing  NOUN  ...    F  training.en-en.15996\n",
            "15997     backing  NOUN  ...    T  training.en-en.15997\n",
            "15998        gird  VERB  ...    F  training.en-en.15998\n",
            "15999        gird  VERB  ...    T  training.en-en.15999\n",
            "\n",
            "[16000 rows x 12 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemma</th>\n",
              "      <th>pos</th>\n",
              "      <th>position1</th>\n",
              "      <th>start1</th>\n",
              "      <th>end1</th>\n",
              "      <th>position2</th>\n",
              "      <th>start2</th>\n",
              "      <th>end2</th>\n",
              "      <th>sent1</th>\n",
              "      <th>sent2</th>\n",
              "      <th>tag</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>play</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>11</td>\n",
              "      <td>69</td>\n",
              "      <td>73</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>14</td>\n",
              "      <td>In that context of coordination and integratio...</td>\n",
              "      <td>A musical play on the same subject was also st...</td>\n",
              "      <td>F</td>\n",
              "      <td>training.en-en.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>play</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>11</td>\n",
              "      <td>69</td>\n",
              "      <td>73</td>\n",
              "      <td>22</td>\n",
              "      <td>112</td>\n",
              "      <td>116</td>\n",
              "      <td>In that context of coordination and integratio...</td>\n",
              "      <td>In schools, when water is needed, it is girls ...</td>\n",
              "      <td>F</td>\n",
              "      <td>training.en-en.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>esteem</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>7</td>\n",
              "      <td>33</td>\n",
              "      <td>39</td>\n",
              "      <td>19</td>\n",
              "      <td>106</td>\n",
              "      <td>112</td>\n",
              "      <td>We would also like to convey our esteem and co...</td>\n",
              "      <td>Father Lini said that, because of that, the Un...</td>\n",
              "      <td>T</td>\n",
              "      <td>training.en-en.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>esteem</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>7</td>\n",
              "      <td>33</td>\n",
              "      <td>39</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>26</td>\n",
              "      <td>We would also like to convey our esteem and co...</td>\n",
              "      <td>This attests to the esteem and trust enjoyed b...</td>\n",
              "      <td>T</td>\n",
              "      <td>training.en-en.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>holder</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>12</td>\n",
              "      <td>74</td>\n",
              "      <td>81</td>\n",
              "      <td>6</td>\n",
              "      <td>27</td>\n",
              "      <td>33</td>\n",
              "      <td>This growth is the direct result of the increa...</td>\n",
              "      <td>A person may be either the holder of an option...</td>\n",
              "      <td>T</td>\n",
              "      <td>training.en-en.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    lemma   pos  ...  tag                id\n",
              "0    play  NOUN  ...    F  training.en-en.0\n",
              "1    play  NOUN  ...    F  training.en-en.1\n",
              "2  esteem  NOUN  ...    T  training.en-en.2\n",
              "3  esteem  NOUN  ...    T  training.en-en.3\n",
              "4  holder  NOUN  ...    T  training.en-en.4\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MYMHSdRFMbZ",
        "outputId": "808e1047-aca3-4e71-8a35-b79f4ce04c72"
      },
      "source": [
        "train_mcl_df = pd.concat([train_mcl_df.iloc[:4000,:], train_mcl_df.iloc[4000:,:].rename(columns = { \"byee\":\"sent2\", \"sent2\":\"bye\"})], ignore_index=True)\r\n",
        "print(train_mcl_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                       id  ...                                                bye\n",
            "0        training.en-en.0  ...                                                NaN\n",
            "1        training.en-en.1  ...                                                NaN\n",
            "2        training.en-en.2  ...                                                NaN\n",
            "3        training.en-en.3  ...                                                NaN\n",
            "4        training.en-en.4  ...                                                NaN\n",
            "...                   ...  ...                                                ...\n",
            "7995  training.en-en.7995  ...  Some Instagram users use the app to spread pos...\n",
            "7996  training.en-en.7996  ...  Between the 1959–1960 overdubs produced by Jac...\n",
            "7997  training.en-en.7997  ...  It is suggested that people who have pacemaker...\n",
            "7998  training.en-en.7998  ...  In the 1890s, Confederate memories no longer d...\n",
            "7999  training.en-en.7999  ...  The eastern side of Sgòr Gaoith is girded by s...\n",
            "\n",
            "[8000 rows x 15 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMgN12PR2cMv"
      },
      "source": [
        "train__mcl_rev_df = train_mcl_df.copy().rename(columns = {\"sent1\":\"sent2\", \"sent2\":\"sent1\", 'start1':'start2', 'start2':'start1', 'end1':'end2', 'end2':'end1'})\r\n",
        "train_mcl_df = pd.concat([train_mcl_df, train__mcl_rev_df], ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twi5seGd-3FU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "c2befdb6-0288-48b9-cea0-c6b4208d2edc"
      },
      "source": [
        "# combine the two datasets\n",
        "train_df = pd.concat([train_mcl_df], ignore_index=True)\n",
        "train_df = train_df[~train_df.lemma.str.contains(\"_\")].reset_index()\n",
        "print(train_df)\n",
        "train_df.head()\n",
        "#IDS ARE (NOT (NOT OK)) HUIHUI"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       index       lemma  ... tag                    id\n",
            "0          0        play  ...   F      training.en-en.0\n",
            "1          1        play  ...   F      training.en-en.1\n",
            "2          2      esteem  ...   T      training.en-en.2\n",
            "3          3      esteem  ...   T      training.en-en.3\n",
            "4          4      holder  ...   T      training.en-en.4\n",
            "...      ...         ...  ...  ..                   ...\n",
            "15995  15995  positivity  ...   T  training.en-en.15995\n",
            "15996  15996     backing  ...   F  training.en-en.15996\n",
            "15997  15997     backing  ...   T  training.en-en.15997\n",
            "15998  15998        gird  ...   F  training.en-en.15998\n",
            "15999  15999        gird  ...   T  training.en-en.15999\n",
            "\n",
            "[16000 rows x 13 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>lemma</th>\n",
              "      <th>pos</th>\n",
              "      <th>position1</th>\n",
              "      <th>start1</th>\n",
              "      <th>end1</th>\n",
              "      <th>position2</th>\n",
              "      <th>start2</th>\n",
              "      <th>end2</th>\n",
              "      <th>sent1</th>\n",
              "      <th>sent2</th>\n",
              "      <th>tag</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>play</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>11</td>\n",
              "      <td>69</td>\n",
              "      <td>73</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>14</td>\n",
              "      <td>In that context of coordination and integratio...</td>\n",
              "      <td>A musical play on the same subject was also st...</td>\n",
              "      <td>F</td>\n",
              "      <td>training.en-en.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>play</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>11</td>\n",
              "      <td>69</td>\n",
              "      <td>73</td>\n",
              "      <td>22</td>\n",
              "      <td>112</td>\n",
              "      <td>116</td>\n",
              "      <td>In that context of coordination and integratio...</td>\n",
              "      <td>In schools, when water is needed, it is girls ...</td>\n",
              "      <td>F</td>\n",
              "      <td>training.en-en.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>esteem</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>7</td>\n",
              "      <td>33</td>\n",
              "      <td>39</td>\n",
              "      <td>19</td>\n",
              "      <td>106</td>\n",
              "      <td>112</td>\n",
              "      <td>We would also like to convey our esteem and co...</td>\n",
              "      <td>Father Lini said that, because of that, the Un...</td>\n",
              "      <td>T</td>\n",
              "      <td>training.en-en.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>esteem</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>7</td>\n",
              "      <td>33</td>\n",
              "      <td>39</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>26</td>\n",
              "      <td>We would also like to convey our esteem and co...</td>\n",
              "      <td>This attests to the esteem and trust enjoyed b...</td>\n",
              "      <td>T</td>\n",
              "      <td>training.en-en.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>holder</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>12</td>\n",
              "      <td>74</td>\n",
              "      <td>81</td>\n",
              "      <td>6</td>\n",
              "      <td>27</td>\n",
              "      <td>33</td>\n",
              "      <td>This growth is the direct result of the increa...</td>\n",
              "      <td>A person may be either the holder of an option...</td>\n",
              "      <td>T</td>\n",
              "      <td>training.en-en.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index   lemma  ... tag                id\n",
              "0      0    play  ...   F  training.en-en.0\n",
              "1      1    play  ...   F  training.en-en.1\n",
              "2      2  esteem  ...   T  training.en-en.2\n",
              "3      3  esteem  ...   T  training.en-en.3\n",
              "4      4  holder  ...   T  training.en-en.4\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZpa7eW2hDsY"
      },
      "source": [
        "dev_df = pd.read_csv(\"/content/drive/MyDrive/datasets/MCL_WiC_old_format/mcl_dev_translated.csv\").rename(columns={\"sentence1\":\"sent1\", \"sent2_tr\":\"sent2\"})\n",
        "\n",
        "print(dev_df)\n",
        "dev_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaFlib8sPmIT",
        "outputId": "dd079b27-dd1a-42d1-91ce-2b10d180a604"
      },
      "source": [
        "dev_rev_df = dev_df.copy().rename(columns = {\"sent1\":\"sent2\", \"sent2\":\"sent1\", 'start1':'start2', 'start2':'start1', 'end1':'end2', 'end2':'end1'})\r\n",
        "dev_df = pd.concat([dev_df, dev_rev_df], ignore_index=True)\r\n",
        "print(dev_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 id  ...                                           sent2_ru\n",
            "0       dev.en-en.0  ...  Полностью осознавая, что епископы и основные н...\n",
            "1       dev.en-en.1  ...  В Сенегале сотрудник таможни и его начальство ...\n",
            "2       dev.en-en.2  ...  Эти жалобы, как правило, подаются на знакомых,...\n",
            "3       dev.en-en.3  ...  Сексуальное насилие со стороны не-партнеров от...\n",
            "4       dev.en-en.4  ...  В багаже у меня была венгерская грамматика и с...\n",
            "...             ...  ...                                                ...\n",
            "1995  dev.en-en.995  ...  Восемнадцатимесячное французское судебное расс...\n",
            "1996  dev.en-en.996  ...  Авторы подсчитали, что ежегодная стоимость $ 4...\n",
            "1997  dev.en-en.997  ...  В докладе подсчитано, что с 1937 года по декаб...\n",
            "1998  dev.en-en.998  ...  Например, делегат может быть использован для о...\n",
            "1999  dev.en-en.999  ...  Он пишет, что временная близость этих двух соб...\n",
            "\n",
            "[2000 rows x 17 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0ysGQFh4lKj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "974ccca9-cc32-49eb-daa8-1ebd3a94bf06"
      },
      "source": [
        "# test data load chinese\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/datasets/WiC_dataset/norm_wic_dev_new_format.csv\").rename(columns={\"sentence1\":\"sent1\", \"sentence2\":\"sent2\"})\n",
        "test_df.head()\n",
        "print(test_df)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           lemma pos  ...                                              sent2  tag\n",
            "0          board   N  ...               He nailed boards across the windows.    F\n",
            "1      circulate   V  ...  This letter is being circulated among the facu...    F\n",
            "2           hook   V  ...  He hooked a snake accidentally, and was so sca...    T\n",
            "3     recreation   N  ...  Drug abuse is often regarded as a form of recr...    T\n",
            "4    domesticity   N  ...  A royal family living in unpretentious domesti...    F\n",
            "..           ...  ..  ...                                                ...  ...\n",
            "633         base   N  ...  Bases include oxides and hydroxides of metals ...    F\n",
            "634        power   N  ...          The mysterious presence of an evil power.    F\n",
            "635  portmanteau   N  ...  ` motel ' is a portmanteau word made by combin...    T\n",
            "636      promise   V  ...                       I promised somebody my time.    T\n",
            "637       pierce   V  ...                       The path pierced the jungle.    F\n",
            "\n",
            "[638 rows x 11 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKzeUzVKQQBE",
        "outputId": "7791b7c3-716b-4f22-ee9a-8541fc776183"
      },
      "source": [
        "test_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(638, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6oExRDcVQgB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abcaac9a-92b5-43fc-9363-837b1c96d09c"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jan 29 20:55:33 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    24W / 300W |      0MiB / 16130MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmqHUdDlWC8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d73072e-0a1e-40bb-d144-f3a2a625c94d"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla V100-SXM2-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxokj4qqWRRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c943c45-9af8-4798-9211-004c3f2e9d90"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/b1/41130a228dd656a1a31ba281598a968320283f48d42782845f6ba567f00b/transformers-4.2.2-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 13.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 49.7MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 53.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=513ce09784e3244bb32682410afebba78ea799553742c8d57e9f52fe2d7ddce0\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5IQYV8QWVVm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134,
          "referenced_widgets": [
            "c6d48f246e8749e2abcfb16af52d5287",
            "4f3443b37ab4451cb9a4a4ba2ebce2d5",
            "2516e2a32aaf46b08241d8ec0ee1fedf",
            "2f4166eb0f684e229158e130beb2fe1c",
            "b5612faed808466ba2b007ba3d110793",
            "c946f8482c6d4136a5dfff1711cbf9d4",
            "2d952722be754225abbe4071e40b4f03",
            "93cad652a03544da86626e71d655bac4",
            "f46330dc380b459b9880548004f1fabd",
            "22e5185433a748e69ec8b5ed73d3b2ae",
            "e42db28e7ed149088cb91da2af1e356e",
            "974cc57c10e84e5294c05868a21be487",
            "9b10b37818f04971a879b567c33bf220",
            "579aed7ae1944a7ab86ba698b952b22b",
            "7976129a14d74d24a21deb191f14a2df",
            "7e1e4b4133cf47229e02b816d82bce98"
          ]
        },
        "outputId": "6492e91b-149a-4626-d08f-e398d29d4df5"
      },
      "source": [
        "from transformers import ElectraTokenizerFast\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading ernie tokenizer...')\n",
        "tokenizer = ElectraTokenizerFast.from_pretrained(\"google/electra-large-discriminator\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading ernie tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6d48f246e8749e2abcfb16af52d5287",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f46330dc380b459b9880548004f1fabd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKogR69WW9im",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b22d9b56-9cd0-4742-aa5b-27fac888c859"
      },
      "source": [
        "# sentences is a list 0f str\n",
        "\n",
        "\n",
        "train_sentences_1 = list(train_df['sent1'])\n",
        "train_sentences_2 = list(train_df['sent2'])\n",
        "\n",
        "dev_sentences_1 =  list(dev_df['sent1'])\n",
        "dev_sentences_2 = list(dev_df['sent2'])\n",
        "\n",
        "test_sentences_1 = list(test_df['sent1'])\n",
        "test_sentences_2 = list(test_df['sent2'])\n",
        "\n",
        "\n",
        "\n",
        "print((train_sentences_2[:10]))\n",
        "print((train_sentences_1[:10]))\n",
        "print(dev_sentences_1[:10])\n",
        "print(dev_sentences_2[:10])\n",
        "print(test_sentences_1[:10])\n",
        "print(test_sentences_2[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A musical play on the same subject was also staged in Kathmandu for three days.', 'In schools, when water is needed, it is girls who are sent to fetch it, taking time away from their studies and play.', 'Father Lini said that, because of that, the United Nations has a very special place in the affections and esteem of the people of Vanuatu.', 'This attests to the esteem and trust enjoyed by your country.', 'A person may be either the holder of an option, being the person entitled to buy or sell; or the writer of the option, being the person required to honour the holder’s right to buy or sell.', 'Over 5,000 now hold legal immigrant documents, which, after five years of annual renewal, entitles the holder to apply for permanent residence.', 'The conclusion of the first reading would make it possible to begin negotiations on a streamlined text.', 'It was precisely that consideration which led the Commission on first reading to introduce a special regime of compulsory arbitration in cases where countermeasures have been taken.', 'UNDP defines poverty as \"human poverty\", deprivation in the most basic choices people have -- such as to live a long and healthy life, to be educated, to have the means to a decent standard of living and to be able to be a part of the life of a community.', 'The approach was to promote a healthy drug-free lifestyle, which should lead to a decline in consumption.']\n",
            "['In that context of coordination and integration, Bolivia holds a key play in any process of infrastructure development.', 'In that context of coordination and integration, Bolivia holds a key play in any process of infrastructure development.', 'We would also like to convey our esteem and congratulations to fraternal Lebanon and its people on the unconditional liberation of its southern part.', 'We would also like to convey our esteem and congratulations to fraternal Lebanon and its people on the unconditional liberation of its southern part.', 'This growth is the direct result of the increased number of baccalaureate holders, who form the potential market for higher education.', 'This growth is the direct result of the increased number of baccalaureate holders, who form the potential market for higher education.', 'The Units have recreation, including television, reading and exercise facilities, and arrangements for medical care.', 'The Units have recreation, including television, reading and exercise facilities, and arrangements for medical care.', 'Yet, protection of the rights of the child called for a healthy socio-economic environment, financial stability at the national level, sustained economic recovery after financial crises, and international cooperation.', 'Yet, protection of the rights of the child called for a healthy socio-economic environment, financial stability at the national level, sustained economic recovery after financial crises, and international cooperation.']\n",
            "['No clause in a contract shall be interpreted as evading the responsibility of superiors under international law.', 'No clause in a contract shall be interpreted as evading the responsibility of superiors under international law.', 'Such acquaintance is a right and not an obligation for an accused.', 'Such acquaintance is a right and not an obligation for an accused.', 'Where any baggage of any passenger contains firearms or any other prohibited goods these persons are turned over to the police for prosecution.', 'Where any baggage of any passenger contains firearms or any other prohibited goods these persons are turned over to the police for prosecution.', 'The State party considers it improbable that the Libyan authorities would take so long to act on his refusal to obey them.', 'The State party considers it improbable that the Libyan authorities would take so long to act on his refusal to obey them.', \"As to the author's interest in being personally present at the court hearing, the State party begins by recalling the history of the author's case.\", \"As to the author's interest in being personally present at the court hearing, the State party begins by recalling the history of the author's case.\"]\n",
            "['While fully aware that the bishops and principals of religious institutes do not act as representatives or delegates of the Roman Pontiff, the Committee notes that subordinates in Catholic religious orders are bound by obedience to the Pope, in accordance with Canons 331 and 590 of the Code of Canon Law.', 'In Senegal, too, customs officers and their superiors receive a bonus for detecting and preventing smuggling.', 'Complaints tend to be filed against acquaintances, which may be in the immediate vicinity of the individual.', 'Sexual violence by non-partners refers to the violence of a parent, friend, acquaintance, neighbour, co-worker or stranger.', 'In my luggage, I had a Hungarian grammar book and dictionaries, but the police did not allow me to study Hungarian.', 'In addition, an airline may refuse to board diplomats or family members who refuse to voluntarily allow the search of their personal baggage or person.', 'However, when he learned that the Swedish authorities considered this proposal unlikely, he stated that he had participated, but had not organized, the demonstration.', 'Given the nature of the conflict in Somalia, it is highly unlikely that these munitions were imported prior to the imposition of the arms embargo.', 'The personal acts of a public servant, however well placed, who uses the state to commit an international crime, cannot include all the acts of the state constituting that crime.', 'His election to this high office is a tribute not only to him personally, but also to his great and beautiful country.']\n",
            "['Room and board.', 'Circulate a rumor.', 'Hook a fish.', 'For recreation he wrote poetry and solved crossword puzzles.', 'Making a hobby of domesticity.', \"The child 's acquisition of language.\", 'There was no meeting of minds.', 'They swam in the nude.', 'He left an indelible mark on the American theater.', 'Conditioning is a form of learning by association.']\n",
            "['He nailed boards across the windows.', 'This letter is being circulated among the faculty.', 'He hooked a snake accidentally, and was so scared he dropped his rod into the water.', 'Drug abuse is often regarded as a form of recreation.', 'A royal family living in unpretentious domesticity.', 'That graphite tennis racquet is quite an acquisition.', 'The meeting elected a chairperson.', \"The marketing rule ' nude sells ' spread from verbal to visual mainstream media in the 20th century.\", 'It was in London that he made his mark.', 'Many close associations with England.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1rfGjqdTUht"
      },
      "source": [
        "Adding Signal 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3vwh-V4dBYY"
      },
      "source": [
        "lem_train = list(train_df['lemma'])\r\n",
        "lem_dev = list(dev_df['lemma'])\r\n",
        "lem_test = list(test_df['lemma'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MMiL6KRdSJi",
        "outputId": "e5f6ee99-a612-412d-c95c-d0f7b2e2c64a"
      },
      "source": [
        "train_sentences_2 = list((map(lambda x,y: y+\" \"+x,lem_train, train_sentences_2)))\r\n",
        "dev_sentences_2 = list((map(lambda x,y: y+\" \"+x,lem_dev, dev_sentences_2)))\r\n",
        "test_sentences_2 = list((map(lambda x,y: y+\" \"+x,lem_test, test_sentences_2)))\r\n",
        "print(train_sentences_2[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A musical play on the same subject was also staged in Kathmandu for three days. play', 'In schools, when water is needed, it is girls who are sent to fetch it, taking time away from their studies and play. play', 'Father Lini said that, because of that, the United Nations has a very special place in the affections and esteem of the people of Vanuatu. esteem', 'This attests to the esteem and trust enjoyed by your country. esteem', 'A person may be either the holder of an option, being the person entitled to buy or sell; or the writer of the option, being the person required to honour the holder’s right to buy or sell. holder', 'Over 5,000 now hold legal immigrant documents, which, after five years of annual renewal, entitles the holder to apply for permanent residence. holder', 'The conclusion of the first reading would make it possible to begin negotiations on a streamlined text. reading', 'It was precisely that consideration which led the Commission on first reading to introduce a special regime of compulsory arbitration in cases where countermeasures have been taken. reading', 'UNDP defines poverty as \"human poverty\", deprivation in the most basic choices people have -- such as to live a long and healthy life, to be educated, to have the means to a decent standard of living and to be able to be a part of the life of a community. healthy', 'The approach was to promote a healthy drug-free lifestyle, which should lead to a decline in consumption. healthy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNh3KxV_qC5q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac934ce3-7c32-4751-abad-d18f80f15412"
      },
      "source": [
        "encoded_inputs_train = tokenizer(train_sentences_1, train_sentences_2, padding = True, truncation = True, return_tensors = 'pt', return_offsets_mapping=True)\n",
        "print(len(encoded_inputs_train['input_ids'][0]))\n",
        "print(type(encoded_inputs_train['input_ids']))\n",
        "\n",
        "encoded_inputs_train_rev = tokenizer(train_sentences_2, train_sentences_1, padding = True, truncation = True, return_tensors = 'pt', return_offsets_mapping=True)\n",
        "\n",
        "\n",
        "encoded_inputs_dev = tokenizer(dev_sentences_1, dev_sentences_2, padding = True, truncation = True, return_tensors = 'pt', return_offsets_mapping=True)\n",
        "print(len(encoded_inputs_dev['input_ids'][0]))\n",
        "print(type(encoded_inputs_dev['input_ids']))\n",
        "\n",
        "encoded_inputs_test = tokenizer(test_sentences_1, test_sentences_2, padding = True, truncation = True, return_tensors = 'pt', return_offsets_mapping=True)\n",
        "\n",
        "print(test_sentences_1[2])\n",
        "print(test_sentences_2[2])\n",
        "print((encoded_inputs_test['offset_mapping'][2]))\n",
        "print((encoded_inputs_test['input_ids'][2]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "151\n",
            "<class 'torch.Tensor'>\n",
            "128\n",
            "<class 'torch.Tensor'>\n",
            "Hook a fish.\n",
            "He hooked a snake accidentally, and was so scared he dropped his rod into the water. hook\n",
            "tensor([[ 0,  0],\n",
            "        [ 0,  4],\n",
            "        [ 5,  6],\n",
            "        [ 7, 11],\n",
            "        [11, 12],\n",
            "        [ 0,  0],\n",
            "        [ 0,  2],\n",
            "        [ 3,  9],\n",
            "        [10, 11],\n",
            "        [12, 17],\n",
            "        [18, 30],\n",
            "        [30, 31],\n",
            "        [32, 35],\n",
            "        [36, 39],\n",
            "        [40, 42],\n",
            "        [43, 49],\n",
            "        [50, 52],\n",
            "        [53, 60],\n",
            "        [61, 64],\n",
            "        [65, 68],\n",
            "        [69, 73],\n",
            "        [74, 77],\n",
            "        [78, 83],\n",
            "        [83, 84],\n",
            "        [85, 89],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0],\n",
            "        [ 0,  0]])\n",
            "tensor([  101,  8103,  1037,  3869,  1012,   102,  2002, 13322,  1037,  7488,\n",
            "         9554,  1010,  1998,  2001,  2061,  6015,  2002,  3333,  2010,  8473,\n",
            "         2046,  1996,  2300,  1012,  8103,   102,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLQvrr_Auw_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4e1f4bb-1a68-463a-9712-ea592d5ebeac"
      },
      "source": [
        "# labels = torch.from_numpy(train_gold_df['label'].values)\n",
        "train_gold_df_tmp = train_df[['tag']].replace({'F' : 0, 'T' : 1})\n",
        "train_labels = torch.from_numpy(train_gold_df_tmp.values)\n",
        "print(train_labels)\n",
        "\n",
        "dev_gold_df_tmp = dev_df[['tag']].replace({'F' : 0, 'T' : 1})\n",
        "dev_labels = torch.from_numpy(dev_gold_df_tmp.values)\n",
        "\n",
        "test_gold_df_tmp = test_df[['tag']].replace({'F' : 0, 'T' : 1})\n",
        "test_labels = torch.from_numpy(test_gold_df_tmp.values)\n",
        "print(len(test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0],\n",
            "        [0],\n",
            "        [1],\n",
            "        ...,\n",
            "        [1],\n",
            "        [0],\n",
            "        [1]])\n",
            "638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17X2mWJJFuUB"
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "train_dataset = TensorDataset(encoded_inputs_train['input_ids'], encoded_inputs_train['token_type_ids'],\n",
        "                              encoded_inputs_train['attention_mask'], train_labels)\n",
        "\n",
        "\n",
        "dev_dataset = TensorDataset(encoded_inputs_dev['input_ids'], encoded_inputs_dev['token_type_ids'],\n",
        "                              encoded_inputs_dev['attention_mask'], dev_labels)\n",
        "\n",
        "test_dataset = TensorDataset(encoded_inputs_test['input_ids'], encoded_inputs_test['token_type_ids'],\n",
        "                              encoded_inputs_test['attention_mask'], test_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIOoyHpCGo9U"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "dev_dataloader = DataLoader(\n",
        "            dev_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(dev_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "            test_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMHW4hZoFST1"
      },
      "source": [
        "**CUTOFF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odLzbaVGGw0F"
      },
      "source": [
        "from transformers import ElectraForSequenceClassification, AdamW, BertConfig\n",
        "import torch.nn as nn\n",
        "\n",
        "class BERTi(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(BERTi, self).__init__()\n",
        "\n",
        "        options_name = \"google/electra-large-discriminator\"\n",
        "        hidden_states = False\n",
        "        self.encoder = ElectraForSequenceClassification.from_pretrained(options_name, output_hidden_states = hidden_states, return_dict = False)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids, attention_mask, labels):\n",
        "        loss, logits = self.encoder(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask, labels = labels)\n",
        "\n",
        "        return loss, logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BMpmNJmG3QN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224,
          "referenced_widgets": [
            "3cd8216eaef24542810ccb25e2fbb364",
            "33e195bd84c14ba9a84c4dfacc2646e8",
            "ef15a2bd9d104cc9beee4f4157219ef4",
            "5aa4b20ebd144772a41ab9210bc9626e",
            "d96a517d90b04aeead6ac5f03619173b",
            "61c2846597c84ccd883c214f4df26525",
            "e0d7f1e503c2434b8aba540439627806",
            "62f29a56e1c447c2837d480821d4adb9",
            "1b72fd1319694a0284a963715212768e",
            "664389fcd63a4ed79aab5cb32c002ec0",
            "809df8c26cb24a75a6bf9509bbcc070c",
            "9a282e8f5d1c4bea92973f9beec64138",
            "38fbe02c53e34e269e40f17b21f3e063",
            "6abf7621bbfa440abdbde593757d86fb",
            "767ecc3c4386491589ecfc30f3c58a8e",
            "f8d75d04b03a453b9ae0a645464e05ad"
          ]
        },
        "outputId": "3e978038-82d2-4831-8119-b278c1767b6f"
      },
      "source": [
        "model_bert = BERTi().to(device)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3cd8216eaef24542810ccb25e2fbb364",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=469.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b72fd1319694a0284a963715212768e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1344867008.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXtgT0yeykKD"
      },
      "source": [
        "# model_bert.load_state_dict(torch.load(\"/content/drive/MyDrive/Model Analysis/Ausemcor/ernie_large_ausem_small_wic/model_bert_dev_best_dev_X_test_X_mcl_and_wic\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaxHb5XzHSA9"
      },
      "source": [
        "optimizer = AdamW(list(model_bert.parameters()),\n",
        "                  lr = 1e-5, # args.learning_rate - default is 5e-5, our notebook had 1e-5\n",
        "                  eps = 1e-8 ,\n",
        "                  # weight_decay = 1 # args.adam_epsilon  - default is 1e-8.\n",
        "                  )\n",
        "\n",
        "# scheduler??\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZMmS3xuw742"
      },
      "source": [
        "def loss_fn(output, targets):\n",
        "  return nn.BCEWithLogitsLoss(reduction='mean')(output, targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0jhTg1VHfdR"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    # print(pred_flat)\n",
        "    # print(labels_flat)\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def flat_accuracy_avg(preds, labels, m):\n",
        "    non_thresh_preds = (np.exp(preds[:,1])/(np.exp(preds[:,0])+ np.exp(preds[:,1]))).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    return np.sum(((non_thresh_preds[:m]+non_thresh_preds[m:])>1).astype(int) == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGjyERYSd68E"
      },
      "source": [
        "def flat_accuracy_single_logit(preds, labels):\n",
        "    pred_flat = (preds>0).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    # print(pred_flat)\n",
        "    # print(labels_flat)\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shJmEVhWQE7g"
      },
      "source": [
        "def flat_accuracy_single_logit_avg(preds, labels, m):\r\n",
        "    pred_flat = (1/(1+np.exp(-preds))).flatten()\r\n",
        "    labels_flat = labels.flatten()\r\n",
        "    # print(pred_flat)\r\n",
        "    # print(labels_flat)\r\n",
        "    return np.sum(((pred_flat[:m]+pred_flat[m:])>1).astype(int) == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTJU8ytyQCCA"
      },
      "source": [
        "def cross_entropy(predictions, targets):\r\n",
        "    N = predictions.shape[0]\r\n",
        "    predictions = (np.exp(predictions[:,1])/(np.exp(predictions[:,0])+ np.exp(predictions[:,1])))\r\n",
        "    ce = -np.sum(targets.flatten() * np.log(predictions) + (1-targets.flatten()) * np.log(1-predictions)) / N\r\n",
        "    return ce\r\n",
        "\r\n",
        "def cross_entropy_avg(predictions, targets,m):\r\n",
        "    N = predictions.shape[0]\r\n",
        "    predictions = (np.exp(predictions[:,1])/(np.exp(predictions[:,0])+ np.exp(predictions[:,1])))\r\n",
        "    predictions = (predictions[:m]+predictions[m:])/2\r\n",
        "    ce = -np.sum(targets.flatten() * np.log(predictions) + (1-targets.flatten()) * np.log(1-predictions)) / N\r\n",
        "    return ce"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBd7Pv-yHiv8"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWzs7IuM3wWP"
      },
      "source": [
        "path_this = \"/content/drive/MyDrive/SemEval Models b/Cross_Lingual/electra_nsp_mcl_rev_wang\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0lnd90FLg_f"
      },
      "source": [
        "accumulation_steps = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0pG6f5CHkqF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cfb1c624-38d5-474c-c549-a0dfb1258b58"
      },
      "source": [
        "# import random\n",
        "# import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "epochs = 12\n",
        "best_val_accuracy_n = 0\n",
        "best_val_accuracy_avg = 0\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model_bert.train()\n",
        "\n",
        "    if True:\n",
        "      # For each batch of training data...\n",
        "      for step, batch in enumerate(train_dataloader):\n",
        "          # if step == 0:\n",
        "          #   break\n",
        "\n",
        "          # Progress update every 40 batches.\n",
        "          if step % 100 == 0 and not step == 0:\n",
        "              # Calculate elapsed time in minutes.\n",
        "              elapsed = format_time(time.time() - t0)\n",
        "              \n",
        "              # Report progress.\n",
        "              print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "          if (step == int(len(train_dataloader)/5) or step == int(2*len(train_dataloader)/5) or step == int(3*len(train_dataloader)/5)\n",
        "          or step == int(4*len(train_dataloader)/5)):\n",
        "            print(\"\")\n",
        "            print(\"Running Validation...\")\n",
        "\n",
        "            t0 = time.time()\n",
        "\n",
        "            # Put the model in evaluation mode--the dropout layers behave differently\n",
        "            # during evaluation.\n",
        "            model_bert.eval()\n",
        "\n",
        "            # Tracking variables \n",
        "            total_eval_accuracy = 0\n",
        "            total_eval_loss = 0\n",
        "            nb_eval_steps = 0\n",
        "\n",
        "            t_labels = []\n",
        "            t_preds = []\n",
        "\n",
        "            # Evaluate data for one epoch\n",
        "            for atch in dev_dataloader:\n",
        "                \n",
        "                # Unpack this training batch from our dataloader. \n",
        "                #\n",
        "                # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "                # the `to` method.\n",
        "\n",
        "                b_input_ids = atch[0].to(device)\n",
        "                b_token_type_ids = atch[1].to(device)\n",
        "                b_attention_mask = atch[2].to(device)\n",
        "                b_labels = atch[3].to(device)\n",
        "                \n",
        "                # Tell pytorch not to bother with constructing the compute graph during\n",
        "                # the forward pass, since this is only needed for backprop (training).\n",
        "                with torch.no_grad():        \n",
        "\n",
        "                    loss, logits = model_bert(b_input_ids, b_token_type_ids, b_attention_mask, b_labels)\n",
        "                    \n",
        "                # Accumulate the validation loss.\n",
        "                total_eval_loss += loss.item()\n",
        "\n",
        "                # Move logits and labels to CPU\n",
        "                logits = logits.cpu().detach().numpy()\n",
        "                # print(logits)\n",
        "                label_ids = b_labels.cpu().numpy()\n",
        "\n",
        "                t_labels.append(label_ids)\n",
        "                t_preds.append(logits)\n",
        "                \n",
        "\n",
        "            all_dev_labels = np.concatenate(t_labels, axis=0)\n",
        "            all_dev_logits = np.concatenate(t_preds, axis=0)\n",
        "            # Report the final accuracy for this validation run.\n",
        "            # print(all_dev_logits)\n",
        "            avg_val_accuracy_n = flat_accuracy(all_dev_logits[:1000], all_dev_labels[:1000])\n",
        "            print(\"Normal Validation Accuracy: {0:.4f}\".format(avg_val_accuracy_n))\n",
        "\n",
        "            # Calculate the average loss over all of the batches.\n",
        "            # avg_val_loss = total_eval_loss / len(dev_dataloader)\n",
        "            print(\"   Normal Validation Loss: {0:.3f}\".format(cross_entropy(all_dev_logits[:1000], all_dev_labels[:1000])))\n",
        "\n",
        "            avg_val_accuracy_avg = flat_accuracy_avg(all_dev_logits, all_dev_labels[:1000], 1000)\n",
        "            print(\"Rev Avg Validation Accuracy: {0:.4f}\".format(avg_val_accuracy_avg))\n",
        "\n",
        "            # Calculate the average loss over all of the batches.\n",
        "            # avg_val_loss = total_eval_loss / len(dev_dataloader)\n",
        "            print(\"   Rev Avg Validation Loss: {0:.3f}\".format(cross_entropy_avg(all_dev_logits, all_dev_labels[:1000], 1000)))\n",
        "            \n",
        "            # Measure how long the validation run took.\n",
        "            validation_time = format_time(time.time() - t0)\n",
        "\n",
        "            if(avg_val_accuracy_n > best_val_accuracy_n):\n",
        "              # flag = True\n",
        "              best_val_accuracy_n = avg_val_accuracy_n\n",
        "              best_val_preds = all_dev_logits\n",
        "              np.save(os.path.join(path_this, \"dev_preds_normal\"), best_val_preds)\n",
        "              # best_bert_parameters = model_bert.state_dict()\n",
        "              # best_log_reg_parameters = model_log_reg.state_dict()    \n",
        "              torch.save(model_bert.state_dict(), os.path.join(path_this, \"normal_model_bert_dev_best\"))\n",
        "\n",
        "            if(avg_val_accuracy_avg > best_val_accuracy_avg):\n",
        "              # flag = True\n",
        "              best_val_accuracy_avg = avg_val_accuracy_avg\n",
        "              best_val_preds = all_dev_logits\n",
        "              np.save(os.path.join(path_this, \"rev_avg_dev_preds\"), best_val_preds)\n",
        "              # best_bert_parameters = model_bert.state_dict()\n",
        "              # best_log_reg_parameters = model_log_reg.state_dict()    \n",
        "              torch.save(model_bert.state_dict(), os.path.join(path_this, \"rev_avg_model_bert_dev_best\"))\n",
        "            \n",
        "            # print(\"  Validation Loss: {0:.3f}\".format(avg_val_loss))\n",
        "            print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "            model_bert.train()\n",
        "\n",
        "\n",
        "          # Unpack this training batch from our dataloader. \n",
        "          #\n",
        "          # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "          # `to` method.\n",
        "\n",
        "          b_input_ids = batch[0].to(device)\n",
        "          b_token_type_ids = batch[1].to(device)\n",
        "          b_attention_mask = batch[2].to(device)\n",
        "          b_labels = batch[3].to(device)\n",
        "\n",
        "          if step%accumulation_steps == 0:\n",
        "            optimizer.zero_grad()        \n",
        "\n",
        "          loss, logits = model_bert(b_input_ids, b_token_type_ids, b_attention_mask, b_labels)\n",
        "\n",
        "          total_train_loss += loss.item()\n",
        "\n",
        "          # Perform a backward pass to calculate the gradients.\n",
        "          loss.backward()\n",
        "\n",
        "          # Clip the norm of the gradients to 1.0.\n",
        "          # This is to help prevent the \"exploding gradients\" problem.\n",
        "          # TODO logsistic REG????/\n",
        "          if (step%accumulation_steps == (accumulation_steps-1)):\n",
        "            torch.nn.utils.clip_grad_norm_(model_bert.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "          # # Update the learning rate.\n",
        "          # scheduler.step()\n",
        "        \n",
        "    \n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model_bert.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    t_labels = []\n",
        "    t_preds = []\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in dev_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_token_type_ids = batch[1].to(device)\n",
        "        b_attention_mask = batch[2].to(device)\n",
        "        b_labels = batch[3].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            loss, logits = model_bert(b_input_ids, b_token_type_ids, b_attention_mask, b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.cpu().detach().numpy()\n",
        "        # print(logits)\n",
        "        label_ids = b_labels.cpu().numpy()\n",
        "\n",
        "        t_labels.append(label_ids)\n",
        "        t_preds.append(logits)\n",
        "        \n",
        "\n",
        "    all_dev_labels = np.concatenate(t_labels, axis=0)\n",
        "    all_dev_logits = np.concatenate(t_preds, axis=0)\n",
        "    # Report the final accuracy for this validation run.\n",
        "    # print(all_dev_logits)\n",
        "    avg_val_accuracy_n = flat_accuracy(all_dev_logits[:1000], all_dev_labels[:1000])\n",
        "    print(\"Normal Validation Accuracy: {0:.4f}\".format(avg_val_accuracy_n))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    # avg_val_loss = total_eval_loss / len(dev_dataloader)\n",
        "    print(\"   Normal Validation Loss: {0:.3f}\".format(cross_entropy(all_dev_logits[:1000], all_dev_labels[:1000])))\n",
        "\n",
        "    avg_val_accuracy_avg = flat_accuracy_avg(all_dev_logits, all_dev_labels[:1000], 1000)\n",
        "    print(\"Rev Avg Validation Accuracy: {0:.4f}\".format(avg_val_accuracy_avg))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    # avg_val_loss = total_eval_loss / len(dev_dataloader)\n",
        "    print(\"   Rev Avg Validation Loss: {0:.3f}\".format(cross_entropy_avg(all_dev_logits, all_dev_labels[:1000], 1000)))\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "\n",
        "    if(avg_val_accuracy_n > best_val_accuracy_n):\n",
        "      # flag = True\n",
        "      best_val_accuracy_n = avg_val_accuracy_n\n",
        "      best_val_preds = all_dev_logits\n",
        "      np.save(os.path.join(path_this, \"dev_preds_normal\"), best_val_preds)\n",
        "      # best_bert_parameters = model_bert.state_dict()\n",
        "      # best_log_reg_parameters = model_log_reg.state_dict()    \n",
        "      torch.save(model_bert.state_dict(), os.path.join(path_this, \"normal_model_bert_dev_best\"))\n",
        "\n",
        "    if(avg_val_accuracy_avg > best_val_accuracy_avg):\n",
        "      # flag = True\n",
        "      best_val_accuracy_avg = avg_val_accuracy_avg\n",
        "      best_val_preds = all_dev_logits\n",
        "      np.save(os.path.join(path_this, \"rev_avg_dev_preds\"), best_val_preds)\n",
        "      # best_bert_parameters = model_bert.state_dict()\n",
        "      # best_log_reg_parameters = model_log_reg.state_dict()    \n",
        "      torch.save(model_bert.state_dict(), os.path.join(path_this, \"rev_avg_model_bert_dev_best\"))\n",
        "    \n",
        "    # print(\"  Validation Loss: {0:.3f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    \n",
        "    # fgfg\n",
        "\n",
        "    # # Do same on test data\n",
        "    # # Tracking variables \n",
        "    # total_eval_accuracy = 0\n",
        "    # total_eval_loss = 0\n",
        "    # nb_eval_steps = 0\n",
        "\n",
        "    # t_labels = []\n",
        "    # t_preds = []\n",
        "\n",
        "    # # Evaluate data for one epoch\n",
        "    # for batch in test_dataloader:\n",
        "        \n",
        "    #     # Unpack this training batch from our dataloader. \n",
        "    #     #\n",
        "    #     # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "    #     # the `to` method.\n",
        "\n",
        "    #     b_input_ids = batch[0].to(device)\n",
        "    #     b_token_type_ids = batch[1].to(device)\n",
        "    #     b_attention_mask = batch[2].to(device)\n",
        "    #     b_poses = batch[3].to(device)\n",
        "    #     b_labels = batch[4].to(device)\n",
        "        \n",
        "    #     # Tell pytorch not to bother with constructing the compute graph during\n",
        "    #     # the forward pass, since this is only needed for backprop (training).\n",
        "    #     with torch.no_grad():\n",
        "    #         last_layer = model_bert(b_input_ids, b_token_type_ids, b_attention_mask)\n",
        "    #         b_poses = b_poses.unsqueeze(-1).repeat(1, 1, 4096)\n",
        "    #         gathered_activations = torch.gather(last_layer, 1, b_poses)\n",
        "    #         logits = model_log_reg(gathered_activations.view(gathered_activations.size()[0], -1))\n",
        "    #         loss = loss_fn(logits, b_labels.type_as(logits))\n",
        "            \n",
        "    #     # Accumulate the validation loss.\n",
        "    #     total_eval_loss += loss.item()\n",
        "\n",
        "    #     # Move logits and labels to CPU\n",
        "    #     logits = logits.cpu().detach().numpy()\n",
        "    #     label_ids = b_labels.cpu().numpy()\n",
        "\n",
        "    #     t_labels.append(label_ids)\n",
        "    #     t_preds.append(logits)\n",
        "        \n",
        "\n",
        "    # all_dev_labels = np.concatenate(t_labels, axis=0)\n",
        "    # all_dev_logits = np.concatenate(t_preds, axis=0)\n",
        "    # # Report the final accuracy for this validation run.\n",
        "    # avg_val_accuracy = flat_accuracy_single_logit(all_dev_logits, all_dev_labels)\n",
        "    # print(\"Test Accuracy: {0:.4f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # if flag == True:\n",
        "    #   np.save(os.path.join(path_this, \"test_preds_at_best_dev\"), best_val_preds)\n",
        "    #   flag = False\n",
        "\n",
        "    # if(avg_val_accuracy > t_best_val_accuracy):\n",
        "    #   t_best_val_accuracy = avg_val_accuracy\n",
        "    #   t_best_val_preds = all_dev_logits\n",
        "    #   np.save(os.path.join(path_this, \"test_preds\"), t_best_val_preds)\n",
        "    #   torch.save(model_bert.state_dict(), os.path.join(path_this, \"model_bert_test_best\"))\n",
        "    #   torch.save(model_log_reg.state_dict(), os.path.join(path_this, \"model_log_reg_test_best\"))\n",
        "\n",
        "    # # Calculate the average loss over all of the batches.\n",
        "    # avg_val_loss = total_eval_loss / len(test_dataloader)\n",
        "    \n",
        "    # # Measure how long the validation run took.\n",
        "    # validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    # print(\"  Test Avg Loss: {0:.3f}\".format(avg_val_loss))\n",
        "    # print(\"  Testing Validation took: {:}\".format(validation_time))\n",
        "\n",
        "   \n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 12 ========\n",
            "Training...\n",
            "  Batch   100  of  1,000.    Elapsed: 0:00:49.\n",
            "  Batch   200  of  1,000.    Elapsed: 0:01:37.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.6680\n",
            "   Normal Validation Loss: 0.635\n",
            "Rev Avg Validation Accuracy: 0.6750\n",
            "   Rev Avg Validation Loss: 0.306\n",
            "  Validation took: 0:00:14\n",
            "  Batch   300  of  1,000.    Elapsed: 0:01:23.\n",
            "  Batch   400  of  1,000.    Elapsed: 0:02:11.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.7640\n",
            "   Normal Validation Loss: 0.532\n",
            "Rev Avg Validation Accuracy: 0.7610\n",
            "   Rev Avg Validation Loss: 0.266\n",
            "  Validation took: 0:00:14\n",
            "  Batch   500  of  1,000.    Elapsed: 0:01:23.\n",
            "  Batch   600  of  1,000.    Elapsed: 0:02:11.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.8260\n",
            "   Normal Validation Loss: 0.428\n",
            "Rev Avg Validation Accuracy: 0.8220\n",
            "   Rev Avg Validation Loss: 0.213\n",
            "  Validation took: 0:00:14\n",
            "  Batch   700  of  1,000.    Elapsed: 0:01:24.\n",
            "  Batch   800  of  1,000.    Elapsed: 0:02:13.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.8440\n",
            "   Normal Validation Loss: 0.394\n",
            "Rev Avg Validation Accuracy: 0.8390\n",
            "   Rev Avg Validation Loss: 0.196\n",
            "  Validation took: 0:00:14\n",
            "  Batch   900  of  1,000.    Elapsed: 0:01:24.\n",
            "\n",
            "  Average training loss: 0.47\n",
            "  Training epcoh took: 0:02:12\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.8370\n",
            "   Normal Validation Loss: 0.469\n",
            "Rev Avg Validation Accuracy: 0.8350\n",
            "   Rev Avg Validation Loss: 0.229\n",
            "  Validation took: 0:00:14\n",
            "\n",
            "======== Epoch 2 / 12 ========\n",
            "Training...\n",
            "  Batch   100  of  1,000.    Elapsed: 0:00:48.\n",
            "  Batch   200  of  1,000.    Elapsed: 0:01:35.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.8050\n",
            "   Normal Validation Loss: 0.685\n",
            "Rev Avg Validation Accuracy: 0.7970\n",
            "   Rev Avg Validation Loss: 0.328\n",
            "  Validation took: 0:00:14\n",
            "  Batch   300  of  1,000.    Elapsed: 0:01:02.\n",
            "  Batch   400  of  1,000.    Elapsed: 0:01:50.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.8390\n",
            "   Normal Validation Loss: 0.542\n",
            "Rev Avg Validation Accuracy: 0.8440\n",
            "   Rev Avg Validation Loss: 0.256\n",
            "  Validation took: 0:00:14\n",
            "  Batch   500  of  1,000.    Elapsed: 0:01:10.\n",
            "  Batch   600  of  1,000.    Elapsed: 0:01:57.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.8350\n",
            "   Normal Validation Loss: 0.551\n",
            "Rev Avg Validation Accuracy: 0.8270\n",
            "   Rev Avg Validation Loss: 0.269\n",
            "  Validation took: 0:00:14\n",
            "  Batch   700  of  1,000.    Elapsed: 0:01:02.\n",
            "  Batch   800  of  1,000.    Elapsed: 0:01:49.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.8360\n",
            "   Normal Validation Loss: 0.679\n",
            "Rev Avg Validation Accuracy: 0.8330\n",
            "   Rev Avg Validation Loss: 0.329\n",
            "  Validation took: 0:00:14\n",
            "  Batch   900  of  1,000.    Elapsed: 0:01:02.\n",
            "\n",
            "  Average training loss: 0.22\n",
            "  Training epcoh took: 0:01:49\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.8380\n",
            "   Normal Validation Loss: 0.710\n",
            "Rev Avg Validation Accuracy: 0.8360\n",
            "   Rev Avg Validation Loss: 0.334\n",
            "  Validation took: 0:00:14\n",
            "\n",
            "======== Epoch 3 / 12 ========\n",
            "Training...\n",
            "  Batch   100  of  1,000.    Elapsed: 0:00:47.\n",
            "  Batch   200  of  1,000.    Elapsed: 0:01:34.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.8220\n",
            "   Normal Validation Loss: 0.914\n",
            "Rev Avg Validation Accuracy: 0.8090\n",
            "   Rev Avg Validation Loss: 0.437\n",
            "  Validation took: 0:00:14\n",
            "  Batch   300  of  1,000.    Elapsed: 0:01:01.\n",
            "  Batch   400  of  1,000.    Elapsed: 0:01:48.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.8480\n",
            "   Normal Validation Loss: 0.833\n",
            "Rev Avg Validation Accuracy: 0.8420\n",
            "   Rev Avg Validation Loss: 0.387\n",
            "  Validation took: 0:00:14\n",
            "  Batch   500  of  1,000.    Elapsed: 0:01:09.\n",
            "  Batch   600  of  1,000.    Elapsed: 0:01:56.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.8350\n",
            "   Normal Validation Loss: 0.980\n",
            "Rev Avg Validation Accuracy: 0.8270\n",
            "   Rev Avg Validation Loss: 0.442\n",
            "  Validation took: 0:00:14\n",
            "  Batch   700  of  1,000.    Elapsed: 0:01:01.\n",
            "  Batch   800  of  1,000.    Elapsed: 0:01:48.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.8560\n",
            "   Normal Validation Loss: 0.831\n",
            "Rev Avg Validation Accuracy: 0.8480\n",
            "   Rev Avg Validation Loss: 0.376\n",
            "  Validation took: 0:00:14\n",
            "  Batch   900  of  1,000.    Elapsed: 0:01:22.\n",
            "\n",
            "  Average training loss: 0.10\n",
            "  Training epcoh took: 0:02:09\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.8360\n",
            "   Normal Validation Loss: 0.910\n",
            "Rev Avg Validation Accuracy: 0.8340\n",
            "   Rev Avg Validation Loss: 0.417\n",
            "  Validation took: 0:00:14\n",
            "\n",
            "======== Epoch 4 / 12 ========\n",
            "Training...\n",
            "  Batch   100  of  1,000.    Elapsed: 0:00:47.\n",
            "  Batch   200  of  1,000.    Elapsed: 0:01:33.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.8530\n",
            "   Normal Validation Loss: 0.921\n",
            "Rev Avg Validation Accuracy: 0.8510\n",
            "   Rev Avg Validation Loss: 0.419\n",
            "  Validation took: 0:00:14\n",
            "  Batch   300  of  1,000.    Elapsed: 0:01:08.\n",
            "  Batch   400  of  1,000.    Elapsed: 0:01:55.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.8330\n",
            "   Normal Validation Loss: 1.094\n",
            "Rev Avg Validation Accuracy: 0.8360\n",
            "   Rev Avg Validation Loss: 0.486\n",
            "  Validation took: 0:00:14\n",
            "  Batch   500  of  1,000.    Elapsed: 0:01:01.\n",
            "  Batch   600  of  1,000.    Elapsed: 0:01:48.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.8640\n",
            "   Normal Validation Loss: 0.869\n",
            "Rev Avg Validation Accuracy: 0.8550\n",
            "   Rev Avg Validation Loss: 0.408\n",
            "  Validation took: 0:00:14\n",
            "  Batch   700  of  1,000.    Elapsed: 0:01:22.\n",
            "  Batch   800  of  1,000.    Elapsed: 0:02:09.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.8490\n",
            "   Normal Validation Loss: 0.940\n",
            "Rev Avg Validation Accuracy: 0.8550\n",
            "   Rev Avg Validation Loss: 0.418\n",
            "  Validation took: 0:00:14\n",
            "  Batch   900  of  1,000.    Elapsed: 0:01:02.\n",
            "\n",
            "  Average training loss: 0.06\n",
            "  Training epcoh took: 0:01:49\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.8340\n",
            "   Normal Validation Loss: 1.134\n",
            "Rev Avg Validation Accuracy: 0.8410\n",
            "   Rev Avg Validation Loss: 0.497\n",
            "  Validation took: 0:00:14\n",
            "\n",
            "======== Epoch 5 / 12 ========\n",
            "Training...\n",
            "  Batch   100  of  1,000.    Elapsed: 0:00:47.\n",
            "  Batch   200  of  1,000.    Elapsed: 0:01:34.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.8250\n",
            "   Normal Validation Loss: 1.274\n",
            "Rev Avg Validation Accuracy: 0.8250\n",
            "   Rev Avg Validation Loss: 0.567\n",
            "  Validation took: 0:00:14\n",
            "  Batch   300  of  1,000.    Elapsed: 0:01:02.\n",
            "  Batch   400  of  1,000.    Elapsed: 0:01:49.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.5000\n",
            "   Normal Validation Loss: 0.697\n",
            "Rev Avg Validation Accuracy: 0.5000\n",
            "   Rev Avg Validation Loss: 0.348\n",
            "  Validation took: 0:00:14\n",
            "  Batch   500  of  1,000.    Elapsed: 0:01:01.\n",
            "  Batch   600  of  1,000.    Elapsed: 0:01:49.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.5000\n",
            "   Normal Validation Loss: 0.693\n",
            "Rev Avg Validation Accuracy: 0.5000\n",
            "   Rev Avg Validation Loss: 0.347\n",
            "  Validation took: 0:00:14\n",
            "  Batch   700  of  1,000.    Elapsed: 0:01:01.\n",
            "  Batch   800  of  1,000.    Elapsed: 0:01:49.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.5000\n",
            "   Normal Validation Loss: 0.698\n",
            "Rev Avg Validation Accuracy: 0.5000\n",
            "   Rev Avg Validation Loss: 0.349\n",
            "  Validation took: 0:00:14\n",
            "  Batch   900  of  1,000.    Elapsed: 0:01:01.\n",
            "\n",
            "  Average training loss: 0.54\n",
            "  Training epcoh took: 0:01:49\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.5000\n",
            "   Normal Validation Loss: 0.693\n",
            "Rev Avg Validation Accuracy: 0.5000\n",
            "   Rev Avg Validation Loss: 0.347\n",
            "  Validation took: 0:00:14\n",
            "\n",
            "======== Epoch 6 / 12 ========\n",
            "Training...\n",
            "  Batch   100  of  1,000.    Elapsed: 0:00:47.\n",
            "  Batch   200  of  1,000.    Elapsed: 0:01:34.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.5000\n",
            "   Normal Validation Loss: 0.694\n",
            "Rev Avg Validation Accuracy: 0.5000\n",
            "   Rev Avg Validation Loss: 0.347\n",
            "  Validation took: 0:00:14\n",
            "  Batch   300  of  1,000.    Elapsed: 0:01:01.\n",
            "  Batch   400  of  1,000.    Elapsed: 0:01:48.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.5000\n",
            "   Normal Validation Loss: 0.694\n",
            "Rev Avg Validation Accuracy: 0.5000\n",
            "   Rev Avg Validation Loss: 0.347\n",
            "  Validation took: 0:00:14\n",
            "  Batch   500  of  1,000.    Elapsed: 0:01:01.\n",
            "  Batch   600  of  1,000.    Elapsed: 0:01:49.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.5000\n",
            "   Normal Validation Loss: 0.695\n",
            "Rev Avg Validation Accuracy: 0.5000\n",
            "   Rev Avg Validation Loss: 0.348\n",
            "  Validation took: 0:00:14\n",
            "  Batch   700  of  1,000.    Elapsed: 0:01:01.\n",
            "  Batch   800  of  1,000.    Elapsed: 0:01:49.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.5000\n",
            "   Normal Validation Loss: 0.693\n",
            "Rev Avg Validation Accuracy: 0.5000\n",
            "   Rev Avg Validation Loss: 0.347\n",
            "  Validation took: 0:00:14\n",
            "  Batch   900  of  1,000.    Elapsed: 0:01:01.\n",
            "\n",
            "  Average training loss: 0.69\n",
            "  Training epcoh took: 0:01:48\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.5000\n",
            "   Normal Validation Loss: 0.695\n",
            "Rev Avg Validation Accuracy: 0.5000\n",
            "   Rev Avg Validation Loss: 0.347\n",
            "  Validation took: 0:00:14\n",
            "\n",
            "======== Epoch 7 / 12 ========\n",
            "Training...\n",
            "  Batch   100  of  1,000.    Elapsed: 0:00:47.\n",
            "  Batch   200  of  1,000.    Elapsed: 0:01:34.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.5000\n",
            "   Normal Validation Loss: 0.696\n",
            "Rev Avg Validation Accuracy: 0.5000\n",
            "   Rev Avg Validation Loss: 0.348\n",
            "  Validation took: 0:00:14\n",
            "  Batch   300  of  1,000.    Elapsed: 0:01:01.\n",
            "  Batch   400  of  1,000.    Elapsed: 0:01:49.\n",
            "\n",
            "Running Validation...\n",
            "Normal Validation Accuracy: 0.5000\n",
            "   Normal Validation Loss: 0.693\n",
            "Rev Avg Validation Accuracy: 0.5000\n",
            "   Rev Avg Validation Loss: 0.347\n",
            "  Validation took: 0:00:14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-14dd12914856>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m           \u001b[0;31m# Perform a backward pass to calculate the gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m           \u001b[0;31m# Clip the norm of the gradients to 1.0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmUdKqNJ71kH",
        "outputId": "041501b3-eb43-4239-8432-b84ef4c21f01"
      },
      "source": [
        "print(best_val_accuracy_n) #mcl_rev_wang\r\n",
        "print(best_val_accuracy_avg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.864\n",
            "0.855\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}