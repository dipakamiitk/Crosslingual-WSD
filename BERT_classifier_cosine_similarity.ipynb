{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_classifier_cosine_similarity.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "853e615470004ded8ed3138291dde0ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b780194a5bc44a6dae67bb1592c1ce9a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c16a12f01a094839a7a08c95e41fd473",
              "IPY_MODEL_f3f9c0f66c314047aedf1e5f60fb3261"
            ]
          }
        },
        "b780194a5bc44a6dae67bb1592c1ce9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c16a12f01a094839a7a08c95e41fd473": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b2e334d31cf343deb198e8ca1f7e8dee",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2fb3848c06e14f76b285f6bf4a1f0209"
          }
        },
        "f3f9c0f66c314047aedf1e5f60fb3261": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2c284621da6143e7bc7652f89765b69b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 269kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e60c9c4166fb4a5d91f8e2eb61f08c2e"
          }
        },
        "b2e334d31cf343deb198e8ca1f7e8dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2fb3848c06e14f76b285f6bf4a1f0209": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c284621da6143e7bc7652f89765b69b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e60c9c4166fb4a5d91f8e2eb61f08c2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4fd0dfeb361f4fdba7680c500c985097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_869d47c8b8e8448882e073da73a28cc5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_41ffb0350cd7400da84ae0a08291704b",
              "IPY_MODEL_11cef1b122b448a3a8e919a5563d0443"
            ]
          }
        },
        "869d47c8b8e8448882e073da73a28cc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41ffb0350cd7400da84ae0a08291704b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d46db668d9ad46b5ad39d5db62ddf2c5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_73bef72b200240fe8478bdee6e3304ba"
          }
        },
        "11cef1b122b448a3a8e919a5563d0443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d69af1aab3ca4ce782d48c1b7e7a3d91",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:10&lt;00:00, 42.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3e4cc409261e4631a9ba4b785933b755"
          }
        },
        "d46db668d9ad46b5ad39d5db62ddf2c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "73bef72b200240fe8478bdee6e3304ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d69af1aab3ca4ce782d48c1b7e7a3d91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3e4cc409261e4631a9ba4b785933b755": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0dbf26656def482c8a23af9a2fc08228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a304455623054836b900706aa38815f8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e88272100c5c44049b90f792fd443ad8",
              "IPY_MODEL_a8ce4fa897384f6881dc60929ebcc210"
            ]
          }
        },
        "a304455623054836b900706aa38815f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e88272100c5c44049b90f792fd443ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1958baab202c4ef38d16fe07f193cacf",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_30be075cbd1c4ddd840393110ab4bb5f"
          }
        },
        "a8ce4fa897384f6881dc60929ebcc210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9e0cfe2f34d44f2890bb7ef86279a0b2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:10&lt;00:00, 44.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8aa741e69a9e4c42bef40837d86d6d6c"
          }
        },
        "1958baab202c4ef38d16fe07f193cacf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "30be075cbd1c4ddd840393110ab4bb5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e0cfe2f34d44f2890bb7ef86279a0b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8aa741e69a9e4c42bef40837d86d6d6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xya_BS1ic9q"
      },
      "source": [
        "import os\n",
        "import pandas\n",
        "import numpy as np\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0Qy2pr4CnkY",
        "outputId": "dc264341-cc47-4b8e-a018-b89b8a1dc7d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzEeI0fUNJcG"
      },
      "source": [
        "wic_path  = \"/content/drive/My Drive/datasets/WiC_dataset\"\n",
        "patht = \"/content/drive/My Drive/datasets/WiC_dataset\"\n",
        "path_wic_constant = \"/content/drive/My Drive/datasets/WiC_dataset\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvQ33K0jOjWu",
        "outputId": "1bc39565-dc9f-4af5-d91b-3312eae9f985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "! ls \"/content/drive/My Drive/datasets/Split_WiC_dataset\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine_Sim  dev  train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlCkId1fiLoT",
        "outputId": "b76b072e-d5d0-40d5-c932-e192a9ac5fe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "wic_train_path_d = os.path.join(wic_path, \"train/train.data.txt\")\n",
        "wic_train_path_g = os.path.join(wic_path, \"train/train.gold.txt\")\n",
        "\n",
        "train_data_df = pandas.read_csv(wic_train_path_d, sep = \"\\t\", names = ['word', 'pos', 'position1', 'sent1', 'sent2'])\n",
        "train_gold_df = pandas.read_csv(wic_train_path_g, sep = \"\\t\", names = ['label'])\n",
        "\n",
        "train_data_df[['position1', 'position2']] = train_data_df['position1'].str.split(\"-\", expand = True)\n",
        "train_data_df = train_data_df[['word', 'pos', 'position1', 'position2', 'sent1', 'sent2']]\n",
        "\n",
        "train_data_df.head()\n",
        "# train_gold_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "      <th>position1</th>\n",
              "      <th>position2</th>\n",
              "      <th>sent1</th>\n",
              "      <th>sent2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>carry</td>\n",
              "      <td>V</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>You must carry your camping gear .</td>\n",
              "      <td>Sound carries well over water .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>go</td>\n",
              "      <td>V</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>Messages must go through diplomatic channels .</td>\n",
              "      <td>Do you think the sofa will go through the door ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>break</td>\n",
              "      <td>V</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Break an alibi .</td>\n",
              "      <td>The wholesaler broke the container loads into ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cup</td>\n",
              "      <td>N</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>He wore a jock strap with a metal cup .</td>\n",
              "      <td>Bees filled the waxen cups with honey .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>academy</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>The Academy of Music .</td>\n",
              "      <td>The French Academy .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      word  ...                                              sent2\n",
              "0    carry  ...                    Sound carries well over water .\n",
              "1       go  ...   Do you think the sofa will go through the door ?\n",
              "2    break  ...  The wholesaler broke the container loads into ...\n",
              "3      cup  ...            Bees filled the waxen cups with honey .\n",
              "4  academy  ...                               The French Academy .\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJp4ec3LyV7c",
        "outputId": "38b8e034-9868-4827-ea24-991b96cea9ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "source": [
        "# do same for dev data\n",
        "wic_dev_path_d = os.path.join(wic_path, \"dev/dev.data.txt\")\n",
        "wic_dev_path_g = os.path.join(wic_path, \"dev/dev.gold.txt\")\n",
        "\n",
        "dev_data_df = pandas.read_csv(wic_dev_path_d, sep = \"\\t\", names = ['word', 'pos', 'position1', 'sent1', 'sent2'])\n",
        "dev_gold_df = pandas.read_csv(wic_dev_path_g, sep = \"\\t\", names = ['label'])\n",
        "print(dev_data_df)\n",
        "\n",
        "dev_data_df[['position1', 'position2']] = dev_data_df['position1'].str.split(\"-\", expand = True)\n",
        "dev_data_df = dev_data_df[['word', 'pos', 'position1', 'position2', 'sent1', 'sent2']]\n",
        "\n",
        "dev_data_df.head()\n",
        "# dev_gold_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            word  ...                                              sent2\n",
            "0          board  ...              He nailed boards across the windows .\n",
            "1      circulate  ...  This letter is being circulated among the facu...\n",
            "2           hook  ...  He hooked a snake accidentally , and was so sc...\n",
            "3     recreation  ...  Drug abuse is often regarded as a form of recr...\n",
            "4    domesticity  ...  A royal family living in unpretentious domesti...\n",
            "..           ...  ...                                                ...\n",
            "633         base  ...  Bases include oxides and hydroxides of metals ...\n",
            "634        power  ...         The mysterious presence of an evil power .\n",
            "635  portmanteau  ...  ` motel ' is a portmanteau word made by combin...\n",
            "636      promise  ...                      I promised somebody my time .\n",
            "637       pierce  ...                      The path pierced the jungle .\n",
            "\n",
            "[638 rows x 5 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "      <th>position1</th>\n",
              "      <th>position2</th>\n",
              "      <th>sent1</th>\n",
              "      <th>sent2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>board</td>\n",
              "      <td>N</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Room and board .</td>\n",
              "      <td>He nailed boards across the windows .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>circulate</td>\n",
              "      <td>V</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Circulate a rumor .</td>\n",
              "      <td>This letter is being circulated among the facu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hook</td>\n",
              "      <td>V</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Hook a fish .</td>\n",
              "      <td>He hooked a snake accidentally , and was so sc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>recreation</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>For recreation he wrote poetry and solved cros...</td>\n",
              "      <td>Drug abuse is often regarded as a form of recr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>domesticity</td>\n",
              "      <td>N</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>Making a hobby of domesticity .</td>\n",
              "      <td>A royal family living in unpretentious domesti...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          word  ...                                              sent2\n",
              "0        board  ...              He nailed boards across the windows .\n",
              "1    circulate  ...  This letter is being circulated among the facu...\n",
              "2         hook  ...  He hooked a snake accidentally , and was so sc...\n",
              "3   recreation  ...  Drug abuse is often regarded as a form of recr...\n",
              "4  domesticity  ...  A royal family living in unpretentious domesti...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6oExRDcVQgB",
        "outputId": "a58f8447-17e9-4d0f-f489-ae04a5233775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Oct 19 17:29:40 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmqHUdDlWC8_",
        "outputId": "f3cef351-a780-4626-a00e-c9f32518532d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxokj4qqWRRX",
        "outputId": "88013747-6d57-46e7-9bf5-7e2fc408fd0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 7.2MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 37.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 39.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 40.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=5fb069f00159df2065102a1dbcba3ebc9b745204aff69e4bf1b93969118730de\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5IQYV8QWVVm",
        "outputId": "f6d58db7-0213-45ba-fbe2-9dde22cdb025",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "853e615470004ded8ed3138291dde0ba",
            "b780194a5bc44a6dae67bb1592c1ce9a",
            "c16a12f01a094839a7a08c95e41fd473",
            "f3f9c0f66c314047aedf1e5f60fb3261",
            "b2e334d31cf343deb198e8ca1f7e8dee",
            "2fb3848c06e14f76b285f6bf4a1f0209",
            "2c284621da6143e7bc7652f89765b69b",
            "e60c9c4166fb4a5d91f8e2eb61f08c2e"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "853e615470004ded8ed3138291dde0ba",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfoTji0N_Bgb"
      },
      "source": [
        "# l = int(len(train_data_df['sent1'])*0.8)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKogR69WW9im",
        "outputId": "d54dd0df-da94-4444-a745-bb05c8ca9d4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# sentences is a list 0f str\n",
        "train_sentences_1 =  list(train_data_df['sent1'])\n",
        "train_sentences_2 = list(train_data_df['sent2'])\n",
        "print(len(train_sentences_1))\n",
        "\n",
        "dev_sentences_1 =  list(dev_data_df['sent1'])\n",
        "dev_sentences_2 = list(dev_data_df['sent2'])\n",
        "print(len(dev_sentences_1))\n",
        "\n",
        "# test_sentences_1 =  list(test_data_df['sent1'])\n",
        "# test_sentences_2 = list(test_data_df['sent2'])\n",
        "# print(len(test_sentences_1))\n",
        "\n",
        "# dev_sentences_1 =  list(train_data_df['sent1'])[l:]\n",
        "# dev_sentences_2 = list(train_data_df['sent2'])[l:]\n",
        "# print(len(dev_sentences_1))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5428\n",
            "638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFQrLjVsjSOO",
        "outputId": "25e994a8-607b-4f8f-cd7a-702c83a0853a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# find out the offset start position for each character\n",
        "train_offsets_1 = []\n",
        "train_offsets_2 = []\n",
        "\n",
        "for i in range(len(train_sentences_1)):\n",
        "  sentence_1 = train_sentences_1[i]\n",
        "  sentence_2 = train_sentences_2[i]\n",
        "\n",
        "  sentence_1 = sentence_1.split()\n",
        "  offset_1 = 0\n",
        "  for j, word in enumerate(sentence_1):\n",
        "    if j == int(train_data_df['position1'][i]):\n",
        "      break\n",
        "    offset_1 = offset_1 + len(word)+1\n",
        "  train_offsets_1.append(offset_1)\n",
        "\n",
        "  sentence_2 = sentence_2.split()\n",
        "  offset_2 = 0\n",
        "  for j, word in enumerate(sentence_2):\n",
        "    if j == int(train_data_df['position2'][i]):\n",
        "      break\n",
        "    offset_2 = offset_2 + len(word)+1\n",
        "  train_offsets_2.append(offset_2)\n",
        "\n",
        "print(len(train_sentences_2))\n",
        "print(len(train_offsets_2))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5428\n",
            "5428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNh3KxV_qC5q"
      },
      "source": [
        "encoded_inputs_train1 = tokenizer(train_sentences_1, padding = True, truncation = True, return_tensors = 'pt', return_offsets_mapping=True)\n",
        "encoded_inputs_train2 = tokenizer(train_sentences_2, padding = True, truncation = True, return_tensors = 'pt', return_offsets_mapping=True)\n",
        "\n",
        "\n",
        "encoded_inputs_dev1 = tokenizer(dev_sentences_1, padding = True, truncation = True, return_tensors = 'pt', return_offsets_mapping=True)\n",
        "encoded_inputs_dev2 = tokenizer(dev_sentences_2, padding = True, truncation = True, return_tensors = 'pt', return_offsets_mapping=True)\n",
        "# print(len(encoded_inputs_dev['input_ids'][0]))\n",
        "# print(type(encoded_inputs_dev['input_ids']))\n",
        "\n",
        "# encoded_inputs_test = tokenizer(test_sentences_1, test_sentences_2, padding = True, truncation = True, return_tensors = 'pt', return_offsets_mapping=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8Fm61IfoIAA",
        "outputId": "9b2cadb7-def5-47e9-c872-dc4ede4aa30c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# create wordpeice indices of the words of interest now\n",
        "train_pos_1 = []\n",
        "train_pos_2 = []\n",
        "for j in range(len(train_sentences_1)):\n",
        "  vocab_ind = encoded_inputs_train1['input_ids'][j].detach().numpy()\n",
        "  which_word = 0\n",
        "  pos1 = -1\n",
        "  target_word_1 = int(train_data_df['position1'][j])\n",
        "  # print(\"The targets are \"+str((target_word_1, target_word_2)) + \" and we have j = \"+str(j))\n",
        "  for i,v_ind in enumerate(vocab_ind):\n",
        "    # print(v_ind)\n",
        "    # skip cls token\n",
        "    if i == 0:\n",
        "      # print(\"oui\"+ str(v_ind))\n",
        "      which_word = 0\n",
        "      old_char_poses =  encoded_inputs_train1['offset_mapping'][j][i].detach().numpy()\n",
        "      continue\n",
        "\n",
        "    # this token's character positions\n",
        "    char_poses =  encoded_inputs_train1['offset_mapping'][j][i].detach().numpy()\n",
        "    # print(char_poses)\n",
        "\n",
        "    if char_poses[0] == old_char_poses[1]+1:\n",
        "      which_word = which_word + 1\n",
        "\n",
        "    if (which_word == target_word_1):\n",
        "      done = True\n",
        "      pos1 = i\n",
        "      break\n",
        "\n",
        "    old_char_poses = char_poses\n",
        "\n",
        "  train_pos_1.append(pos1)\n",
        "\n",
        "for j in range(len(train_sentences_2)):\n",
        "  vocab_ind = encoded_inputs_train2['input_ids'][j].detach().numpy()\n",
        "  which_word = 0\n",
        "  pos2 = -1\n",
        "  target_word_2 = int(train_data_df['position2'][j])\n",
        "  # print(\"The targets are \"+str((target_word_1, target_word_2)) + \" and we have j = \"+str(j))\n",
        "  for i,v_ind in enumerate(vocab_ind):\n",
        "    # skip cls token\n",
        "    if i == 0:\n",
        "      # print(\"oui\"+ str(v_ind))\n",
        "      which_word = 0\n",
        "      old_char_poses =  encoded_inputs_train2['offset_mapping'][j][i].detach().numpy()\n",
        "      continue\n",
        "\n",
        "    # this token's character positions\n",
        "    char_poses =  encoded_inputs_train2['offset_mapping'][j][i].detach().numpy()\n",
        "    # print(char_poses)\n",
        "\n",
        "    if char_poses[0] == old_char_poses[1]+1:\n",
        "      which_word = which_word + 1\n",
        "\n",
        "    if (which_word == target_word_2):\n",
        "      done = True\n",
        "      pos2 = i\n",
        "      break\n",
        "\n",
        "    old_char_poses = char_poses\n",
        "\n",
        "  train_pos_2.append(pos2)\n",
        "\n",
        "dev_pos_1 = []\n",
        "dev_pos_2 = []\n",
        "\n",
        "for j in range(len(dev_sentences_1)):\n",
        "  vocab_ind = encoded_inputs_dev1['input_ids'][j].detach().numpy()\n",
        "  which_word = 0\n",
        "  pos1 = -1\n",
        "  target_word_1 = int(dev_data_df['position1'][j])\n",
        "  # print(\"The targets are \"+str((target_word_1, target_word_2)) + \" and we have j = \"+str(j))\n",
        "  for i,v_ind in enumerate(vocab_ind):\n",
        "    # print(v_ind)\n",
        "    # skip cls token\n",
        "    if i == 0:\n",
        "      # print(\"oui\"+ str(v_ind))\n",
        "      which_word = 0\n",
        "      old_char_poses =  encoded_inputs_dev1['offset_mapping'][j][i].detach().numpy()\n",
        "      continue\n",
        "\n",
        "    # this token's character positions\n",
        "    char_poses =  encoded_inputs_dev1['offset_mapping'][j][i].detach().numpy()\n",
        "    # print(char_poses)\n",
        "\n",
        "    if char_poses[0] == old_char_poses[1]+1:\n",
        "      which_word = which_word + 1\n",
        "\n",
        "    if (which_word == target_word_1):\n",
        "      done = True\n",
        "      pos1 = i\n",
        "      break\n",
        "\n",
        "    old_char_poses = char_poses\n",
        "\n",
        "  dev_pos_1.append(pos1)\n",
        "\n",
        "\n",
        "for j in range(len(dev_sentences_2)):\n",
        "  vocab_ind = encoded_inputs_dev1['input_ids'][j].detach().numpy()\n",
        "  which_word = 0\n",
        "  pos2 = -1\n",
        "  target_word_2 = int(dev_data_df['position2'][j])\n",
        "  # print(\"The targets are \"+str((target_word_1, target_word_2)) + \" and we have j = \"+str(j))\n",
        "  for i,v_ind in enumerate(vocab_ind):\n",
        "    # print(v_ind)\n",
        "    # skip cls token\n",
        "    if i == 0:\n",
        "      # print(\"oui\"+ str(v_ind))\n",
        "      which_word = 0\n",
        "      old_char_poses =  encoded_inputs_dev2['offset_mapping'][j][i].detach().numpy()\n",
        "      continue\n",
        "\n",
        "    # this token's character positions\n",
        "    char_poses =  encoded_inputs_dev2['offset_mapping'][j][i].detach().numpy()\n",
        "    # print(char_poses)\n",
        "\n",
        "    if char_poses[0] == old_char_poses[1]+1:\n",
        "      which_word = which_word + 1\n",
        "\n",
        "    if (which_word == target_word_2):\n",
        "      done = True\n",
        "      pos2 = i\n",
        "      break\n",
        "\n",
        "    old_char_poses = char_poses\n",
        "\n",
        "  dev_pos_2.append(pos2)\n",
        "\n",
        "print(len(train_pos_1))\n",
        "print(len(dev_pos_2))\n",
        "\n",
        "train_pos_1 = torch.LongTensor(train_pos_1)\n",
        "train_pos_2 = torch.LongTensor(train_pos_2)\n",
        "\n",
        "train_pos = torch.stack((train_pos_1, train_pos_2), dim =1)\n",
        "\n",
        "dev_pos_1 = torch.LongTensor(dev_pos_1)\n",
        "dev_pos_2 = torch.LongTensor(dev_pos_2)\n",
        "\n",
        "dev_pos = torch.stack((dev_pos_1, dev_pos_2), dim=1)\n",
        "print((train_pos.size()))\n",
        "\n",
        "# print(dev_pos[:20] - train_pos[:20])\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5428\n",
            "638\n",
            "torch.Size([5428, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLQvrr_Auw_1",
        "outputId": "0bd7862a-3aa9-49cb-a4f0-34ad2504a4cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "# labels = torch.from_numpy(train_gold_df['label'].values)\n",
        "train_gold_df_tmp = train_gold_df.replace({'F' : 0, 'T' : 1})\n",
        "train_labels = torch.from_numpy(train_gold_df_tmp.values)\n",
        "print(train_labels)\n",
        "\n",
        "dev_gold_df_tmp = dev_gold_df.replace({'F' : 0, 'T' : 1})\n",
        "dev_labels = torch.from_numpy(dev_gold_df_tmp.values)\n",
        "print(len(dev_labels))\n",
        "\n",
        "# test_gold_df_tmp = test_gold_df.replace({'F' : 0, 'T' : 1})\n",
        "# test_labels = torch.from_numpy(test_gold_df_tmp.values)\n",
        "# print(len(test_labels))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0],\n",
            "        [0],\n",
            "        [0],\n",
            "        ...,\n",
            "        [1],\n",
            "        [1],\n",
            "        [1]])\n",
            "638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17X2mWJJFuUB"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "train_dataset = TensorDataset(encoded_inputs_train1['input_ids'], encoded_inputs_train1['token_type_ids'],\n",
        "                              encoded_inputs_train1['attention_mask'], encoded_inputs_train2['input_ids'], encoded_inputs_train2['token_type_ids'],\n",
        "                              encoded_inputs_train2['attention_mask'], train_pos, train_labels)\n",
        "\n",
        "dev_dataset = TensorDataset(encoded_inputs_dev1['input_ids'], encoded_inputs_dev1['token_type_ids'],\n",
        "                              encoded_inputs_dev1['attention_mask'], encoded_inputs_dev2['input_ids'], encoded_inputs_dev2['token_type_ids'],\n",
        "                              encoded_inputs_dev2['attention_mask'], dev_pos, dev_labels)\n",
        "\n",
        "# test_dataset = TensorDataset(encoded_inputs_test['input_ids'], encoded_inputs_test['token_type_ids'],\n",
        "#                               encoded_inputs_test['attention_mask'], test_pos, test_labels)\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIOoyHpCGo9U"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "dev_dataloader = DataLoader(\n",
        "            dev_dataset, # The validation samples.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "# test_dataloader = DataLoader(\n",
        "#             test_dataset, # The validation samples.\n",
        "#             sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
        "#             batch_size = batch_size # Evaluate with this batch size.\n",
        "#         )"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMHW4hZoFST1"
      },
      "source": [
        "**CUTOFF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odLzbaVGGw0F"
      },
      "source": [
        "from transformers import BertModel, AdamW, BertConfig\n",
        "import torch.nn as nn\n",
        "\n",
        "class BERTi(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(BERTi, self).__init__()\n",
        "\n",
        "        options_name = \"bert-base-uncased\"\n",
        "        hidden_states = True\n",
        "        self.encoder = BertModel.from_pretrained(options_name, output_hidden_states = hidden_states)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids, attention_mask):\n",
        "        last_layer, _ , hidden_states= self.encoder(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask)\n",
        "        second_last_layer = hidden_states[-2]\n",
        "        return second_last_layer"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BMpmNJmG3QN",
        "outputId": "4d274000-3464-48e0-aa88-909aa49bd4e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732,
          "referenced_widgets": [
            "4fd0dfeb361f4fdba7680c500c985097",
            "869d47c8b8e8448882e073da73a28cc5",
            "41ffb0350cd7400da84ae0a08291704b",
            "11cef1b122b448a3a8e919a5563d0443",
            "d46db668d9ad46b5ad39d5db62ddf2c5",
            "73bef72b200240fe8478bdee6e3304ba",
            "d69af1aab3ca4ce782d48c1b7e7a3d91",
            "3e4cc409261e4631a9ba4b785933b755",
            "0dbf26656def482c8a23af9a2fc08228",
            "a304455623054836b900706aa38815f8",
            "e88272100c5c44049b90f792fd443ad8",
            "a8ce4fa897384f6881dc60929ebcc210",
            "1958baab202c4ef38d16fe07f193cacf",
            "30be075cbd1c4ddd840393110ab4bb5f",
            "9e0cfe2f34d44f2890bb7ef86279a0b2",
            "8aa741e69a9e4c42bef40837d86d6d6c"
          ]
        }
      },
      "source": [
        "model_bert = BERTi().to(device)\n",
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model_bert.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4fd0dfeb361f4fdba7680c500c985097",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0dbf26656def482c8a23af9a2fc08228",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "The BERT model has 199 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "encoder.embeddings.word_embeddings.weight               (30522, 768)\n",
            "encoder.embeddings.position_embeddings.weight             (512, 768)\n",
            "encoder.embeddings.token_type_embeddings.weight             (2, 768)\n",
            "encoder.embeddings.LayerNorm.weight                           (768,)\n",
            "encoder.embeddings.LayerNorm.bias                             (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "encoder.encoder.layer.0.attention.self.query.weight       (768, 768)\n",
            "encoder.encoder.layer.0.attention.self.query.bias             (768,)\n",
            "encoder.encoder.layer.0.attention.self.key.weight         (768, 768)\n",
            "encoder.encoder.layer.0.attention.self.key.bias               (768,)\n",
            "encoder.encoder.layer.0.attention.self.value.weight       (768, 768)\n",
            "encoder.encoder.layer.0.attention.self.value.bias             (768,)\n",
            "encoder.encoder.layer.0.attention.output.dense.weight     (768, 768)\n",
            "encoder.encoder.layer.0.attention.output.dense.bias           (768,)\n",
            "encoder.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n",
            "encoder.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n",
            "encoder.encoder.layer.0.intermediate.dense.weight        (3072, 768)\n",
            "encoder.encoder.layer.0.intermediate.dense.bias              (3072,)\n",
            "encoder.encoder.layer.0.output.dense.weight              (768, 3072)\n",
            "encoder.encoder.layer.0.output.dense.bias                     (768,)\n",
            "encoder.encoder.layer.0.output.LayerNorm.weight               (768,)\n",
            "encoder.encoder.layer.0.output.LayerNorm.bias                 (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "encoder.encoder.layer.11.output.LayerNorm.weight              (768,)\n",
            "encoder.encoder.layer.11.output.LayerNorm.bias                (768,)\n",
            "encoder.pooler.dense.weight                               (768, 768)\n",
            "encoder.pooler.dense.bias                                     (768,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw4pcZ9pAiK7",
        "outputId": "b5b59a72-6141-4e2b-aa5c-d71798dfcc70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(type(model_bert.parameters()))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'generator'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0jhTg1VHfdR"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    print(pred_flat)\n",
        "    print(labels_flat)\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGjyERYSd68E"
      },
      "source": [
        "def flat_accuracy_single_logit(preds, labels):\n",
        "    pred_flat = (preds>0).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    # print(pred_flat)\n",
        "    # print(labels_flat)\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBd7Pv-yHiv8"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOtqdJXPN7Vq",
        "outputId": "127baba2-7245-499c-f060-b547ab65aaf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "t0 = time.time()\n",
        "# N x 1\n",
        "similarities = []\n",
        "labels = []\n",
        "with torch.no_grad():\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "\n",
        "          # Progress update every 40 batches.\n",
        "          if step % 50 == 0 and not step == 0:\n",
        "              # Calculate elapsed time in minutes.\n",
        "              elapsed = format_time(time.time() - t0)\n",
        "              \n",
        "              # Report progress.\n",
        "              print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "\n",
        "\n",
        "          b_input_ids1 = batch[0].to(device)\n",
        "          b_token_type_ids1 = batch[1].to(device)\n",
        "          b_attention_mask1 = batch[2].to(device)\n",
        "          b_input_ids2 = batch[3].to(device)\n",
        "          b_token_type_ids2 = batch[4].to(device)\n",
        "          b_attention_mask2 = batch[5].to(device)\n",
        "          b_poses = batch[6].to(device)\n",
        "          b_labels = batch[7].to(device)\n",
        "      \n",
        "\n",
        "          second_last_layer1 = model_bert(b_input_ids1, b_token_type_ids1, b_attention_mask1)\n",
        "\n",
        "          second_last_layer2 = model_bert(b_input_ids2, b_token_type_ids2, b_attention_mask2)\n",
        "\n",
        "          # print(second_last_layer1.size())\n",
        "          b_poses = b_poses.unsqueeze(-1).repeat(1, 1, 768)\n",
        "          # print(b_poses[:,:1,:].size())\n",
        "          gathered_activations1 = torch.gather(second_last_layer1, 1, b_poses[:,:1,:])\n",
        "          gathered_activations2 = torch.gather(second_last_layer2, 1, b_poses[:,1:2,:])\n",
        "          # print(gathered_activations2.squeeze(dim = 1).size())\n",
        "\n",
        "          similarity = cosine_similarity(gathered_activations1.squeeze(dim = 1).cpu(), gathered_activations2.squeeze(dim = 1).cpu()).diagonal().reshape(b_labels.size()[0], -1)\n",
        "          similarities.append(similarity)\n",
        "          # # VVVV IMPORTANT AS BATCHES HAVE BEEN SHUFFLED WHICH WAS NOT NECESSSARY - SAVE FILE IS USELESS\n",
        "          # labels.append(b_labels)\n",
        "          # print(similarity)\n",
        "          # print(b_labels)\n",
        "          # concatted = torch.cat((last_layer[b_poses[:,0].view(16,1),:] , last_layer[:,b_poses[:,1],:]), dim = 1)\n",
        "\n",
        "similarities_np = np.concatenate(similarities, axis = 0)\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Batch    50  of    340.    Elapsed: 0:00:09.\n",
            "  Batch   100  of    340.    Elapsed: 0:00:17.\n",
            "  Batch   150  of    340.    Elapsed: 0:00:26.\n",
            "  Batch   200  of    340.    Elapsed: 0:00:34.\n",
            "  Batch   250  of    340.    Elapsed: 0:00:43.\n",
            "  Batch   300  of    340.    Elapsed: 0:00:51.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oiyn728JtuLd"
      },
      "source": [
        "np.save(\"/content/drive/My Drive/datasets/Split_WiC_dataset/Cosine_Sim/numpy_file_cos_sim\", similarities_np)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWn-ecfxqngT"
      },
      "source": [
        "def thresholded_accuracy(labels, preds, threshold):\n",
        "  preds_th = preds.copy()\n",
        "  preds_th[preds < threshold] = 0\n",
        "  preds_th[~(preds < threshold)] = 1\n",
        "\n",
        "  correct = (preds_th == labels).sum()\n",
        "  # print(correct)\n",
        "  return correct/preds.shape[0]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md4If4GPoR0J",
        "outputId": "f21bed23-7500-44ce-f744-fa7d75cc1f33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# implement linear search\n",
        "train_labels_np = train_labels.detach().numpy()\n",
        "\n",
        "steps = 1000\n",
        "step_size = 1/steps\n",
        "\n",
        "best_accuracy = 0.0\n",
        "best_threshold = 0.0\n",
        "for i in range(steps+1):\n",
        "\n",
        "  threshold = i * step_size\n",
        "  # print(threshold)\n",
        "  accuracy = thresholded_accuracy(train_labels_np, similarities_np, threshold)\n",
        "\n",
        "  # print(accuracy)\n",
        "  if (accuracy > best_accuracy):\n",
        "    best_accuracy = accuracy\n",
        "    best_threshold = threshold\n",
        "\n",
        "print(\"Best Accuracy = \"+str(best_accuracy))\n",
        "print(\"Threshold = \"+str(best_threshold))\n",
        "# print(similarities_np[:100])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Accuracy = 0.6836772291820191\n",
            "Threshold = 0.584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA4My0bt-dXy"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "t0 = time.time()\n",
        "# N x 1\n",
        "similarities_test = []\n",
        "with torch.no_grad():\n",
        "  for step, batch in enumerate(dev_dataloader):\n",
        "\n",
        "\n",
        "          # Progress update every 40 batches.\n",
        "          if step % 50 == 0 and not step == 0:\n",
        "              # Calculate elapsed time in minutes.\n",
        "              elapsed = format_time(time.time() - t0)\n",
        "              \n",
        "              # Report progress.\n",
        "              print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "\n",
        "\n",
        "          b_input_ids1 = batch[0].to(device)\n",
        "          b_token_type_ids1 = batch[1].to(device)\n",
        "          b_attention_mask1 = batch[2].to(device)\n",
        "          b_input_ids2 = batch[3].to(device)\n",
        "          b_token_type_ids2 = batch[4].to(device)\n",
        "          b_attention_mask2 = batch[5].to(device)\n",
        "          b_poses = batch[6].to(device)\n",
        "          b_labels = batch[7].to(device)\n",
        "      \n",
        "\n",
        "          second_last_layer1 = model_bert(b_input_ids1, b_token_type_ids1, b_attention_mask1)\n",
        "\n",
        "          second_last_layer2 = model_bert(b_input_ids2, b_token_type_ids2, b_attention_mask2)\n",
        "\n",
        "          # print(second_last_layer1.size())\n",
        "          b_poses = b_poses.unsqueeze(-1).repeat(1, 1, 768)\n",
        "          # print(b_poses[:,:1,:].size())\n",
        "          gathered_activations1 = torch.gather(second_last_layer1, 1, b_poses[:,:1,:])\n",
        "          gathered_activations2 = torch.gather(second_last_layer2, 1, b_poses[:,1:2,:])\n",
        "          # print(gathered_activations2.squeeze(dim = 1).size())\n",
        "\n",
        "          similarity = cosine_similarity(gathered_activations1.squeeze(dim = 1).cpu(), gathered_activations2.squeeze(dim = 1).cpu()).diagonal().reshape(b_labels.size()[0], -1)\n",
        "          similarities_test.append(similarity)\n",
        "          # # VVVV IMPORTANT AS BATCHES HAVE BEEN SHUFFLED WHICH WAS NOT NECESSSARY - SAVE FILE IS USELESS\n",
        "          # labels.append(b_labels)\n",
        "          # print(similarity)\n",
        "          # print(b_labels)\n",
        "          # concatted = torch.cat((last_layer[b_poses[:,0].view(16,1),:] , last_layer[:,b_poses[:,1],:]), dim = 1)\n",
        "\n",
        "similarities_test_np = np.concatenate(similarities_test, axis = 0)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyrr5KOf-o4f",
        "outputId": "eb4b4a2a-d541-4079-8408-4d17069bdd3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Test\n",
        "dev_labels_np = dev_labels.detach().numpy()\n",
        "\n",
        "test_accuracy = thresholded_accuracy(dev_labels_np, similarities_test_np, best_threshold)\n",
        "\n",
        "print(\"The test accuracy with best threshold = \"+str(best_threshold)+\" is = \"+str(test_accuracy))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The test accuracy with best threshold = 0.584 is = 0.6489028213166145\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}