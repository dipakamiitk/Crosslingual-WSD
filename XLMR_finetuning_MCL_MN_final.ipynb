{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XLMR_finetuning_MCL_MN_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "370da661841b415b9c5262cc2ae199d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2d4ed51e14284a2ab503a443cac373f4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_394e3d75d47b4ff3a5f9ec6f92a01137",
              "IPY_MODEL_55e7291571ce4ffa85313c9fc76b2ad0"
            ]
          }
        },
        "2d4ed51e14284a2ab503a443cac373f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "394e3d75d47b4ff3a5f9ec6f92a01137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fe18003250d3456eb5f8e122e7f6f72d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5069051,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5069051,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b54471d4b9b7482baa4eccbde96a58db"
          }
        },
        "55e7291571ce4ffa85313c9fc76b2ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8a1ba48e5a3246f68be1c6c0fb4ddf72",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.07M/5.07M [00:05&lt;00:00, 923kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cfa5fded42bb486a8b2f2bd955cf51a0"
          }
        },
        "fe18003250d3456eb5f8e122e7f6f72d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b54471d4b9b7482baa4eccbde96a58db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a1ba48e5a3246f68be1c6c0fb4ddf72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cfa5fded42bb486a8b2f2bd955cf51a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b4228ce444dd472eb1225daf82dd4850": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5a2d0af5fd03426d97f40260f7db29eb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5e46cfee2d1b4eef8174f613deedfff1",
              "IPY_MODEL_3761f4c127bd48fc8c4868297af14118"
            ]
          }
        },
        "5a2d0af5fd03426d97f40260f7db29eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e46cfee2d1b4eef8174f613deedfff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_40ec78f426fe4ebd8b5415dc03170cb4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9096718,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9096718,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc9bede5303942df9c97beb538756f25"
          }
        },
        "3761f4c127bd48fc8c4868297af14118": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ede7760cd9754a43b22d8c54b06cf318",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9.10M/9.10M [00:02&lt;00:00, 3.62MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d2c7d9c4a47445d886e6b1c9b1cc0b52"
          }
        },
        "40ec78f426fe4ebd8b5415dc03170cb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc9bede5303942df9c97beb538756f25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ede7760cd9754a43b22d8c54b06cf318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d2c7d9c4a47445d886e6b1c9b1cc0b52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4528d61c108444008972a68e7204567e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_83bb3c06e3414d66aa72ce1968ca8a0b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_047255609d9b4b3c90134f4ef7399afc",
              "IPY_MODEL_2d0b82bb2c6449d5a1b548a4178a3308"
            ]
          }
        },
        "83bb3c06e3414d66aa72ce1968ca8a0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "047255609d9b4b3c90134f4ef7399afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f97fc2475c934109900d2f8d613bacd6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 513,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 513,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46528e479b0f4fc2bb9b885e31ab2f87"
          }
        },
        "2d0b82bb2c6449d5a1b548a4178a3308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_494966b60ba54027b7ad3400cd21ff88",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 513/513 [00:36&lt;00:00, 14.0B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a87428ab905c4c5f90b3626bb5cf6a80"
          }
        },
        "f97fc2475c934109900d2f8d613bacd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46528e479b0f4fc2bb9b885e31ab2f87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "494966b60ba54027b7ad3400cd21ff88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a87428ab905c4c5f90b3626bb5cf6a80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "23879fd7717d4a7580c505c590b97cd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a21bbda241c24f18bd474939f9965163",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3bbb6c6a05d04b2a895998a267930fb2",
              "IPY_MODEL_c1fddf7607b048b289afbe59a7564d29"
            ]
          }
        },
        "a21bbda241c24f18bd474939f9965163": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3bbb6c6a05d04b2a895998a267930fb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_661adc79f7124943892ee218222d27b2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2244861551,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2244861551,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc283b767df743c4af0946fa35995d38"
          }
        },
        "c1fddf7607b048b289afbe59a7564d29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_94a7a0890ae74ec88b30d092ddb77f68",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2.24G/2.24G [00:35&lt;00:00, 62.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c81987e98d748a1b217a40897851761"
          }
        },
        "661adc79f7124943892ee218222d27b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc283b767df743c4af0946fa35995d38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94a7a0890ae74ec88b30d092ddb77f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c81987e98d748a1b217a40897851761": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dipakamiitk/Crosslingual-WSD/blob/master/XLMR_finetuning_MCL_MN_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xya_BS1ic9q"
      },
      "source": [
        "import os\n",
        "# import pandas\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0Qy2pr4CnkY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00e794e7-e23a-48e5-f939-6aafc60c38f1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvQ33K0jOjWu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27e9729c-f75d-4b74-c9bc-75e8a08ce231"
      },
      "source": [
        "! ls \"/content/drive/My Drive/datasets/Split_WiC_dataset\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine_Sim  dev  train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMZslOtNoSby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6732d609-d6db-4f7a-81f7-268b83cb847e"
      },
      "source": [
        "# Load the mcl en data\n",
        "train_mcl_df = pd.read_csv(\"/content/drive/MyDrive/datasets/MCL_WiC_old_format/new_train_format_english_en.csv\")\n",
        "print(train_mcl_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                       id  ... tag\n",
            "0        training.en-en.0  ...   F\n",
            "1        training.en-en.1  ...   F\n",
            "2        training.en-en.2  ...   T\n",
            "3        training.en-en.3  ...   T\n",
            "4        training.en-en.4  ...   T\n",
            "...                   ...  ...  ..\n",
            "7995  training.en-en.7995  ...   T\n",
            "7996  training.en-en.7996  ...   F\n",
            "7997  training.en-en.7997  ...   T\n",
            "7998  training.en-en.7998  ...   F\n",
            "7999  training.en-en.7999  ...   T\n",
            "\n",
            "[8000 rows x 12 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "F_9OpZhY7q8m",
        "outputId": "a45b739e-cd85-4a9b-be1f-ca1d6f0ee1dc"
      },
      "source": [
        "# load OOV split data for training\r\n",
        "mix_df = pd.read_csv(\"/content/drive/MyDrive/datasets/MCL_WiC_old_format/split_dev_seq/train_combined_7.2k\")\r\n",
        "mix_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>lemma</th>\n",
              "      <th>pos</th>\n",
              "      <th>position1</th>\n",
              "      <th>start1</th>\n",
              "      <th>end1</th>\n",
              "      <th>position2</th>\n",
              "      <th>start2</th>\n",
              "      <th>end2</th>\n",
              "      <th>sent1</th>\n",
              "      <th>sent2</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dev.ar-ar.99</td>\n",
              "      <td>فَحَصَ</td>\n",
              "      <td>VERB</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>32</td>\n",
              "      <td>38</td>\n",
              "      <td>ويفحص التقرير الثاني، وهو استعراض لقدرات استجا...</td>\n",
              "      <td>كما قضت، برضا صاحبة الشكوى، بأن يفحصها في عياد...</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dev.ar-ar.100</td>\n",
              "      <td>نِظامِيٌّ</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>9</td>\n",
              "      <td>52</td>\n",
              "      <td>58</td>\n",
              "      <td>6</td>\n",
              "      <td>36</td>\n",
              "      <td>42</td>\n",
              "      <td>ومعظم هؤلاء العمال من الأميين وليس لديهم علاقا...</td>\n",
              "      <td>والمهاجرون الذين يوجدون في حالة غير نظامية هم ...</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dev.ar-ar.101</td>\n",
              "      <td>نِظامِيٌّ</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>9</td>\n",
              "      <td>52</td>\n",
              "      <td>58</td>\n",
              "      <td>11</td>\n",
              "      <td>77</td>\n",
              "      <td>83</td>\n",
              "      <td>ومعظم هؤلاء العمال من الأميين وليس لديهم علاقا...</td>\n",
              "      <td>يجب تحديد، جمع، تأكيد وتقاسم المعلومات الخاصة ...</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dev.ar-ar.103</td>\n",
              "      <td>ضَرَبَ</td>\n",
              "      <td>VERB</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>10</td>\n",
              "      <td>58</td>\n",
              "      <td>62</td>\n",
              "      <td>كما يدعي أنه ضرب في حضور مدعية عندما أنكر اعتر...</td>\n",
              "      <td>وبعد ذلك استل أحد ضابطي الشرطة هراوته وأخذ، حس...</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dev.ar-ar.104</td>\n",
              "      <td>حَطَّ</td>\n",
              "      <td>VERB</td>\n",
              "      <td>16</td>\n",
              "      <td>95</td>\n",
              "      <td>98</td>\n",
              "      <td>18</td>\n",
              "      <td>109</td>\n",
              "      <td>112</td>\n",
              "      <td>ومع ذلك تواصل الأمم المتحدة عرقلة نفسها بهيكل ...</td>\n",
              "      <td>وأفادت التقارير بأن الآلة الطائرة التي هي بدون...</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              id  ... tag\n",
              "0   dev.ar-ar.99  ...   F\n",
              "1  dev.ar-ar.100  ...   F\n",
              "2  dev.ar-ar.101  ...   F\n",
              "3  dev.ar-ar.103  ...   T\n",
              "4  dev.ar-ar.104  ...   F\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFp1xtN7RP8F"
      },
      "source": [
        "Load Xl-WiC datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "KANfN9n2-Fi9",
        "outputId": "06871c24-f716-408b-dc11-c18ef608c171"
      },
      "source": [
        "xl_zh_df = pd.read_csv(\"/content/drive/MyDrive/datasets/XL-WIC/xlwic_zh_val_deepak_format.csv\")\r\n",
        "xl_zh_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemma</th>\n",
              "      <th>pos</th>\n",
              "      <th>start1</th>\n",
              "      <th>end1</th>\n",
              "      <th>start2</th>\n",
              "      <th>end2</th>\n",
              "      <th>sent1</th>\n",
              "      <th>sent2</th>\n",
              "      <th>tag</th>\n",
              "      <th>position1</th>\n",
              "      <th>position2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>轉</td>\n",
              "      <td>V</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>44</td>\n",
              "      <td>45</td>\n",
              "      <td>為什麼我會用情至深轉不出情關，別人是在情感路上徘徊，而我是在親情的深淵裡沉淪。</td>\n",
              "      <td>他其實也明白自己的個性，常常會因一句話或一件事，被帶入死胡同裡，ㄧ直往死胡同裡鑽，然後又轉不出來。</td>\n",
              "      <td>T</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>打</td>\n",
              "      <td>V</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>莫研仰脖叫道：「你倆打屁打得還真沒完沒了地哇，我不等了，要先去紅珊姐那裡了。」</td>\n",
              "      <td>沒多久就看到顏妤佑打屁打到一半突然想到有社團表演，就帶著他們衝去活動中心看康輔的表演。</td>\n",
              "      <td>T</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>轉</td>\n",
              "      <td>V</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>凝重的天空一會兒突轉清朗，北風趕走濃雲，湖的上空出現了一片藍天。</td>\n",
              "      <td>華輝猜知了她的心意，語轉溫和，說道：「李姑娘，你只須助我拔出毒針，我要給你許許多多金銀珠寶。」</td>\n",
              "      <td>T</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>發出</td>\n",
              "      <td>V</td>\n",
              "      <td>13</td>\n",
              "      <td>15</td>\n",
              "      <td>37</td>\n",
              "      <td>39</td>\n",
              "      <td>二小時後他手上的求救器自動發出求救訊息，消防局監測人員接獲訊號後派救護車緊急將他送醫。</td>\n",
              "      <td>這是指利用儀器連續偵測、記錄環境中毒性化學物質濃度，當濃度超過設定值時，可發出警報訊號之設備。</td>\n",
              "      <td>T</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>上</td>\n",
              "      <td>V</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>她目睹兒子判若兩人的改變，毅然把才上小學的女兒也轉送到森小。</td>\n",
              "      <td>她強調自己也是平凡的大學生，剛上大一時，雖曾因這較特別的工作招來一些異樣眼光。</td>\n",
              "      <td>T</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  lemma pos  start1  ...  tag  position1  position2\n",
              "0     轉   V       9  ...    T          0          0\n",
              "1     打   V      12  ...    T          0          0\n",
              "2     轉   V       9  ...    T          0          0\n",
              "3    發出   V      13  ...    T          0          0\n",
              "4     上   V      17  ...    T          0          0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "iPBHBN8h-IKy",
        "outputId": "6787a7fd-9ea6-45eb-ce79-92a403d0e041"
      },
      "source": [
        "xl_nl_df = pd.read_csv(\"/content/drive/MyDrive/datasets/XL-WIC/xlwic_dutch_nl_val_deepak_format.csv\")\r\n",
        "xl_nl_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemma</th>\n",
              "      <th>pos</th>\n",
              "      <th>start1</th>\n",
              "      <th>end1</th>\n",
              "      <th>start2</th>\n",
              "      <th>end2</th>\n",
              "      <th>sent1</th>\n",
              "      <th>sent2</th>\n",
              "      <th>tag</th>\n",
              "      <th>position1</th>\n",
              "      <th>position2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pijn</td>\n",
              "      <td>N</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "      <td>18</td>\n",
              "      <td>ik heb pijn in mijn hoofd/aan mijn schouder.</td>\n",
              "      <td>waar doet het pijn?</td>\n",
              "      <td>T</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pijn</td>\n",
              "      <td>N</td>\n",
              "      <td>20</td>\n",
              "      <td>24</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>heb je wat tegen de pijn?</td>\n",
              "      <td>ik voel pijn in mijn linkerknie.</td>\n",
              "      <td>T</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>periode</td>\n",
              "      <td>N</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>24</td>\n",
              "      <td>31</td>\n",
              "      <td>de periode 1100 - 1300 wordt gekenmerkt door [ ].</td>\n",
              "      <td>ze is verkozen voor een periode van twee jaar.</td>\n",
              "      <td>T</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pijn</td>\n",
              "      <td>N</td>\n",
              "      <td>14</td>\n",
              "      <td>18</td>\n",
              "      <td>19</td>\n",
              "      <td>23</td>\n",
              "      <td>waar doet het pijn?</td>\n",
              "      <td>een medicijn om de pijn te stillen.</td>\n",
              "      <td>T</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>periode</td>\n",
              "      <td>N</td>\n",
              "      <td>31</td>\n",
              "      <td>38</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>het akkoord dateert nog uit de periode Lubbers-I.</td>\n",
              "      <td>een periode van bezinning/strenge vorst/schaar...</td>\n",
              "      <td>T</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     lemma pos  start1  ...  tag  position1  position2\n",
              "0     pijn   N       7  ...    T          2          3\n",
              "1     pijn   N      20  ...    T          5          2\n",
              "2  periode   N       3  ...    T          1          5\n",
              "3     pijn   N      14  ...    T          3          4\n",
              "4  periode   N      31  ...    T          6          1\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "OPIR_amQ_Soe",
        "outputId": "388cc87c-ca86-49f7-fec8-aac54d7fc984"
      },
      "source": [
        "xl_hr_df = pd.read_csv(\"/content/drive/MyDrive/datasets/XL-WIC/xlwic_croation_hr_val_deepak_format.csv\")\r\n",
        "xl_hr_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemma</th>\n",
              "      <th>pos</th>\n",
              "      <th>start1</th>\n",
              "      <th>end1</th>\n",
              "      <th>start2</th>\n",
              "      <th>end2</th>\n",
              "      <th>sent1</th>\n",
              "      <th>sent2</th>\n",
              "      <th>tag</th>\n",
              "      <th>position1</th>\n",
              "      <th>position2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>raditi</td>\n",
              "      <td>V</td>\n",
              "      <td>12</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>Naporno sam radila da bih diplomirala na vrijeme.</td>\n",
              "      <td>Radila je na poboljšanju životnih uvjeta u Afr...</td>\n",
              "      <td>T</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>traka</td>\n",
              "      <td>N</td>\n",
              "      <td>20</td>\n",
              "      <td>25</td>\n",
              "      <td>36</td>\n",
              "      <td>41</td>\n",
              "      <td>Na toj su pokretnoj traci radila tri radnika.</td>\n",
              "      <td>Cijele je noći radila u tvornici na traci.</td>\n",
              "      <td>T</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>boja</td>\n",
              "      <td>N</td>\n",
              "      <td>51</td>\n",
              "      <td>57</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>Učenici su dobili za zadaću nacrtati sliku vod...</td>\n",
              "      <td>Uljene boje omiljena su tehnika impresionistič...</td>\n",
              "      <td>T</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lik</td>\n",
              "      <td>N</td>\n",
              "      <td>50</td>\n",
              "      <td>56</td>\n",
              "      <td>50</td>\n",
              "      <td>58</td>\n",
              "      <td>Izračunavali su površine različitih geometrijs...</td>\n",
              "      <td>Pravokutnik i kvadrat pripadaju dvodimenzional...</td>\n",
              "      <td>T</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>orma</td>\n",
              "      <td>N</td>\n",
              "      <td>62</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>33</td>\n",
              "      <td>Ljepota konja dodatno se ističe kada ga se zao...</td>\n",
              "      <td>Tek s pronalaskom primjerene orme postalo je m...</td>\n",
              "      <td>T</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    lemma pos  start1  ...  tag  position1  position2\n",
              "0  raditi   V      12  ...    T          2          0\n",
              "1   traka   N      20  ...    T          4          7\n",
              "2    boja   N      51  ...    T          8          1\n",
              "3     lik   N      50  ...    T          5          5\n",
              "4    orma   N      62  ...    T         11          4\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "p1opmH2q_gZj",
        "outputId": "65ba4cc7-dacf-4dc2-86d7-0282431b92c7"
      },
      "source": [
        "xl_da_df = pd.read_csv(\"/content/drive/MyDrive/datasets/XL-WIC/xlwic_danish_da_val_deepak_format.csv\")\r\n",
        "xl_da_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemma</th>\n",
              "      <th>pos</th>\n",
              "      <th>start1</th>\n",
              "      <th>end1</th>\n",
              "      <th>start2</th>\n",
              "      <th>end2</th>\n",
              "      <th>sent1</th>\n",
              "      <th>sent2</th>\n",
              "      <th>tag</th>\n",
              "      <th>position1</th>\n",
              "      <th>position2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gratisavis</td>\n",
              "      <td>N</td>\n",
              "      <td>32</td>\n",
              "      <td>42</td>\n",
              "      <td>21</td>\n",
              "      <td>31</td>\n",
              "      <td>fremtiden er den annoncebetalte gratisavis.</td>\n",
              "      <td>Den husstandsomdelte gratisavis Dato taber ifø...</td>\n",
              "      <td>T</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>google</td>\n",
              "      <td>V</td>\n",
              "      <td>40</td>\n",
              "      <td>47</td>\n",
              "      <td>68</td>\n",
              "      <td>75</td>\n",
              "      <td>Man søger ikke efter noget længere, man google...</td>\n",
              "      <td>en stadig voksende del af befolkningen sidder ...</td>\n",
              "      <td>T</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>indie</td>\n",
              "      <td>N</td>\n",
              "      <td>91</td>\n",
              "      <td>96</td>\n",
              "      <td>55</td>\n",
              "      <td>60</td>\n",
              "      <td>Jyske troubadurer er i København omtrent lige ...</td>\n",
              "      <td>[gruppen] epo-555 kan om nogen leve op til bet...</td>\n",
              "      <td>T</td>\n",
              "      <td>14</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bringe</td>\n",
              "      <td>V</td>\n",
              "      <td>15</td>\n",
              "      <td>21</td>\n",
              "      <td>17</td>\n",
              "      <td>23</td>\n",
              "      <td>Tanken om Leon bragte blodet op i hendes kinder.</td>\n",
              "      <td>Et års nabostrid bragte mig i går på skadestue...</td>\n",
              "      <td>T</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gratisavis</td>\n",
              "      <td>N</td>\n",
              "      <td>44</td>\n",
              "      <td>56</td>\n",
              "      <td>15</td>\n",
              "      <td>27</td>\n",
              "      <td>det [er da] et udmærket initiativ med de to gr...</td>\n",
              "      <td>Abbonenter som gratisavisen Weekend Fyn kunne ...</td>\n",
              "      <td>T</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        lemma pos  start1  ...  tag  position1  position2\n",
              "0  gratisavis   N      32  ...    T          4          2\n",
              "1      google   V      40  ...    T          7         11\n",
              "2       indie   N      91  ...    T         14          9\n",
              "3      bringe   V      15  ...    T          3          3\n",
              "4  gratisavis   N      44  ...    T          9          2\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "id": "B0i1zzIvHgPC",
        "outputId": "f60f7f0c-16bd-48e4-958a-0ebc36fd4290"
      },
      "source": [
        "# combine the datasets\n",
        "train_df = pd.concat([train_mcl_df, mix_df\n",
        "                      , xl_da_df, xl_hr_df, xl_nl_df, xl_zh_df\n",
        "                      # , farsi_df\n",
        "                      ], ignore_index=True)\n",
        "print(train_df)\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                     id  ... tag\n",
            "0      training.en-en.0  ...   F\n",
            "1      training.en-en.1  ...   F\n",
            "2      training.en-en.2  ...   T\n",
            "3      training.en-en.3  ...   T\n",
            "4      training.en-en.4  ...   T\n",
            "...                 ...  ...  ..\n",
            "19447               NaN  ...   F\n",
            "19448               NaN  ...   F\n",
            "19449               NaN  ...   F\n",
            "19450               NaN  ...   F\n",
            "19451               NaN  ...   F\n",
            "\n",
            "[19452 rows x 12 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>lemma</th>\n",
              "      <th>pos</th>\n",
              "      <th>position1</th>\n",
              "      <th>start1</th>\n",
              "      <th>end1</th>\n",
              "      <th>position2</th>\n",
              "      <th>start2</th>\n",
              "      <th>end2</th>\n",
              "      <th>sent1</th>\n",
              "      <th>sent2</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>training.en-en.0</td>\n",
              "      <td>play</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>11</td>\n",
              "      <td>69</td>\n",
              "      <td>73</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>14</td>\n",
              "      <td>In that context of coordination and integratio...</td>\n",
              "      <td>A musical play on the same subject was also st...</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>training.en-en.1</td>\n",
              "      <td>play</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>11</td>\n",
              "      <td>69</td>\n",
              "      <td>73</td>\n",
              "      <td>22</td>\n",
              "      <td>112</td>\n",
              "      <td>116</td>\n",
              "      <td>In that context of coordination and integratio...</td>\n",
              "      <td>In schools, when water is needed, it is girls ...</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>training.en-en.2</td>\n",
              "      <td>esteem</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>7</td>\n",
              "      <td>33</td>\n",
              "      <td>39</td>\n",
              "      <td>19</td>\n",
              "      <td>106</td>\n",
              "      <td>112</td>\n",
              "      <td>We would also like to convey our esteem and co...</td>\n",
              "      <td>Father Lini said that, because of that, the Un...</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>training.en-en.3</td>\n",
              "      <td>esteem</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>7</td>\n",
              "      <td>33</td>\n",
              "      <td>39</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>26</td>\n",
              "      <td>We would also like to convey our esteem and co...</td>\n",
              "      <td>This attests to the esteem and trust enjoyed b...</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>training.en-en.4</td>\n",
              "      <td>holder</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>12</td>\n",
              "      <td>74</td>\n",
              "      <td>81</td>\n",
              "      <td>6</td>\n",
              "      <td>27</td>\n",
              "      <td>33</td>\n",
              "      <td>This growth is the direct result of the increa...</td>\n",
              "      <td>A person may be either the holder of an option...</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... tag\n",
              "0  training.en-en.0  ...   F\n",
              "1  training.en-en.1  ...   F\n",
              "2  training.en-en.2  ...   T\n",
              "3  training.en-en.3  ...   T\n",
              "4  training.en-en.4  ...   T\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZpa7eW2hDsY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "e38077b9-c6f0-4962-8483-d7294bb99d32"
      },
      "source": [
        "dev_df_en =pd.read_csv(\"/content/drive/MyDrive/datasets/MCL-WiC/dev_data.csv\").rename(columns={\"sentence1\":\"sent1\", \"sentence2\":\"sent2\"})\n",
        "print(dev_df_en)\n",
        "dev_df_en.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                id         lemma   pos  ... start2 end2  tag\n",
            "0      dev.en-en.0      superior  NOUN  ...     41   50    F\n",
            "1      dev.en-en.1      superior  NOUN  ...     44   53    T\n",
            "2      dev.en-en.2  acquaintance  NOUN  ...     41   54    F\n",
            "3      dev.en-en.3  acquaintance  NOUN  ...     74   86    F\n",
            "4      dev.en-en.4       baggage  NOUN  ...      6   13    T\n",
            "..             ...           ...   ...  ...    ...  ...  ...\n",
            "995  dev.en-en.995         crash  NOUN  ...     75   80    T\n",
            "996  dev.en-en.996     calculate  VERB  ...     12   22    F\n",
            "997  dev.en-en.997     calculate  VERB  ...     11   21    F\n",
            "998  dev.en-en.998         click  VERB  ...     92   98    T\n",
            "999  dev.en-en.999         click  VERB  ...     59   66    F\n",
            "\n",
            "[1000 rows x 10 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>lemma</th>\n",
              "      <th>pos</th>\n",
              "      <th>sent1</th>\n",
              "      <th>sent2</th>\n",
              "      <th>start1</th>\n",
              "      <th>end1</th>\n",
              "      <th>start2</th>\n",
              "      <th>end2</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dev.en-en.0</td>\n",
              "      <td>superior</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>No clause in a contract shall be interpreted a...</td>\n",
              "      <td>While fully aware that bishops and major super...</td>\n",
              "      <td>78</td>\n",
              "      <td>87</td>\n",
              "      <td>41</td>\n",
              "      <td>50</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dev.en-en.1</td>\n",
              "      <td>superior</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>No clause in a contract shall be interpreted a...</td>\n",
              "      <td>In Senegal too, the customs officer and his su...</td>\n",
              "      <td>78</td>\n",
              "      <td>87</td>\n",
              "      <td>44</td>\n",
              "      <td>53</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dev.en-en.2</td>\n",
              "      <td>acquaintance</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>Such acquaintance is a right and not an obliga...</td>\n",
              "      <td>The complaints tend to be lodged against acqua...</td>\n",
              "      <td>5</td>\n",
              "      <td>17</td>\n",
              "      <td>41</td>\n",
              "      <td>54</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dev.en-en.3</td>\n",
              "      <td>acquaintance</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>Such acquaintance is a right and not an obliga...</td>\n",
              "      <td>Sexual violence by non-partners refers to viol...</td>\n",
              "      <td>5</td>\n",
              "      <td>17</td>\n",
              "      <td>74</td>\n",
              "      <td>86</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dev.en-en.4</td>\n",
              "      <td>baggage</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>Where any baggage of any passenger contains fi...</td>\n",
              "      <td>In my baggage I had a Hungarian grammar book a...</td>\n",
              "      <td>10</td>\n",
              "      <td>17</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id         lemma   pos  ... start2 end2  tag\n",
              "0  dev.en-en.0      superior  NOUN  ...     41   50    F\n",
              "1  dev.en-en.1      superior  NOUN  ...     44   53    T\n",
              "2  dev.en-en.2  acquaintance  NOUN  ...     41   54    F\n",
              "3  dev.en-en.3  acquaintance  NOUN  ...     74   86    F\n",
              "4  dev.en-en.4       baggage  NOUN  ...      6   13    T\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "id": "h-gW0cuG9PAu",
        "outputId": "82c4a6d9-573e-4d11-f2f2-2d3ac6c02c48"
      },
      "source": [
        "dev_df_mix = pd.read_csv(\"/content/drive/MyDrive/datasets/MCL_WiC_old_format/split_dev_seq/dev_combined_400x2\").rename(columns={\"sentence1\":\"sent1\", \"sentence2\":\"sent2\"})\r\n",
        "print(dev_df_mix)\r\n",
        "dev_df_mix.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                id  ... tag\n",
            "0      dev.ar-ar.0  ...   T\n",
            "1      dev.ar-ar.1  ...   T\n",
            "2      dev.ar-ar.2  ...   T\n",
            "3      dev.ar-ar.3  ...   T\n",
            "4      dev.ar-ar.4  ...   F\n",
            "..             ...  ...  ..\n",
            "795   dev.zh-zh.95  ...   T\n",
            "796   dev.zh-zh.96  ...   F\n",
            "797   dev.zh-zh.97  ...   F\n",
            "798   dev.zh-zh.98  ...   F\n",
            "799  dev.zh-zh.102  ...   F\n",
            "\n",
            "[800 rows x 12 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>lemma</th>\n",
              "      <th>pos</th>\n",
              "      <th>position1</th>\n",
              "      <th>start1</th>\n",
              "      <th>end1</th>\n",
              "      <th>position2</th>\n",
              "      <th>start2</th>\n",
              "      <th>end2</th>\n",
              "      <th>sent1</th>\n",
              "      <th>sent2</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dev.ar-ar.0</td>\n",
              "      <td>مَلاك</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>10</td>\n",
              "      <td>62</td>\n",
              "      <td>66</td>\n",
              "      <td>11</td>\n",
              "      <td>66</td>\n",
              "      <td>70</td>\n",
              "      <td>ونظرا لأهمية هذه المسائل لسير عمل المحكمة مستق...</td>\n",
              "      <td>ولا توجد حراسة أمام جميع البعثات الدبلوماسية ب...</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dev.ar-ar.1</td>\n",
              "      <td>مَلاك</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>10</td>\n",
              "      <td>62</td>\n",
              "      <td>66</td>\n",
              "      <td>11</td>\n",
              "      <td>67</td>\n",
              "      <td>74</td>\n",
              "      <td>ونظرا لأهمية هذه المسائل لسير عمل المحكمة مستق...</td>\n",
              "      <td>وأعربت عن رغبتها في الحصول على معلومات بشأن مو...</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dev.ar-ar.2</td>\n",
              "      <td>فَوضَى</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>11</td>\n",
              "      <td>63</td>\n",
              "      <td>67</td>\n",
              "      <td>9</td>\n",
              "      <td>53</td>\n",
              "      <td>57</td>\n",
              "      <td>ويؤدي هذا المرض، الذي ينتشر بين أكبر قطاعات ال...</td>\n",
              "      <td>والواقع أن آلية نزع السلاح المتعددة الأطراف تع...</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dev.ar-ar.3</td>\n",
              "      <td>فَوضَى</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>11</td>\n",
              "      <td>63</td>\n",
              "      <td>67</td>\n",
              "      <td>24</td>\n",
              "      <td>129</td>\n",
              "      <td>133</td>\n",
              "      <td>ويؤدي هذا المرض، الذي ينتشر بين أكبر قطاعات ال...</td>\n",
              "      <td>وفي مقابل ذلك، فإنه في حالة تعذر حل هذه المشكل...</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dev.ar-ar.4</td>\n",
              "      <td>خَطِيئَة</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>7</td>\n",
              "      <td>43</td>\n",
              "      <td>50</td>\n",
              "      <td>14</td>\n",
              "      <td>82</td>\n",
              "      <td>87</td>\n",
              "      <td>والتشريع ذات الأولوية هو إعادة هيكلة ضرائب الخ...</td>\n",
              "      <td>وتم استحداث هذا الحل كخيار متاح للكاثوليكيين ا...</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id     lemma  ...                                              sent2  tag\n",
              "0  dev.ar-ar.0     مَلاك  ...  ولا توجد حراسة أمام جميع البعثات الدبلوماسية ب...    T\n",
              "1  dev.ar-ar.1     مَلاك  ...  وأعربت عن رغبتها في الحصول على معلومات بشأن مو...    T\n",
              "2  dev.ar-ar.2    فَوضَى  ...  والواقع أن آلية نزع السلاح المتعددة الأطراف تع...    T\n",
              "3  dev.ar-ar.3    فَوضَى  ...  وفي مقابل ذلك، فإنه في حالة تعذر حل هذه المشكل...    T\n",
              "4  dev.ar-ar.4  خَطِيئَة  ...  وتم استحداث هذا الحل كخيار متاح للكاثوليكيين ا...    F\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcOzQo2Z9Q95",
        "outputId": "1183ce9d-5725-4c7e-f743-0e966877d74f"
      },
      "source": [
        "dev_df = pd.concat([dev_df_mix, dev_df_en], ignore_index=True)\r\n",
        "print(dev_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 id  ... tag\n",
            "0       dev.ar-ar.0  ...   T\n",
            "1       dev.ar-ar.1  ...   T\n",
            "2       dev.ar-ar.2  ...   T\n",
            "3       dev.ar-ar.3  ...   T\n",
            "4       dev.ar-ar.4  ...   F\n",
            "...             ...  ...  ..\n",
            "1795  dev.en-en.995  ...   T\n",
            "1796  dev.en-en.996  ...   F\n",
            "1797  dev.en-en.997  ...   F\n",
            "1798  dev.en-en.998  ...   T\n",
            "1799  dev.en-en.999  ...   F\n",
            "\n",
            "[1800 rows x 12 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "id": "ROkWcmcjDuB7",
        "outputId": "bfa00e1a-c189-45c9-9d1e-8ff2b6d06e68"
      },
      "source": [
        "test_mix = pd.read_csv(\"/content/drive/MyDrive/datasets/MCL_WiC_old_format/Test/multi/multi_test.csv\").rename(columns={\"sentence1\":\"sent1\", \"sentence2\":\"sent2\"})\r\n",
        "print(test_mix[['sent1']])\r\n",
        "test_mix.head()\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                  sent1\n",
            "0     وكان ستون من مراقبي الشرطة هؤﻻء قد خدموا في اﻷ...\n",
            "1     وكان ستون من مراقبي الشرطة هؤﻻء قد خدموا في اﻷ...\n",
            "2     وناقشت أفرقة خبراء متعددة القوانين عبر اﻹقليمي...\n",
            "3     وناقشت أفرقة خبراء متعددة القوانين عبر اﻹقليمي...\n",
            "4     ويرى الوزير أنه لا يزال يتعين على أفراد الشعب ...\n",
            "...                                                 ...\n",
            "3995  Лидерство – феномен власти, способность одного...\n",
            "3996  Над Корсаком нависает угроза ареста, и он, пер...\n",
            "3997  Над Корсаком нависает угроза ареста, и он, пер...\n",
            "3998  Кроме того, если язык отделился от праязыка до...\n",
            "3999  Кроме того, если язык отделился от праязыка до...\n",
            "\n",
            "[4000 rows x 1 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>lemma</th>\n",
              "      <th>pos</th>\n",
              "      <th>position1</th>\n",
              "      <th>start1</th>\n",
              "      <th>end1</th>\n",
              "      <th>position2</th>\n",
              "      <th>start2</th>\n",
              "      <th>end2</th>\n",
              "      <th>sent1</th>\n",
              "      <th>sent2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test.ar-ar.0</td>\n",
              "      <td>خَدَمَ</td>\n",
              "      <td>VERB</td>\n",
              "      <td>7</td>\n",
              "      <td>35</td>\n",
              "      <td>40</td>\n",
              "      <td>17</td>\n",
              "      <td>95</td>\n",
              "      <td>100</td>\n",
              "      <td>وكان ستون من مراقبي الشرطة هؤﻻء قد خدموا في اﻷ...</td>\n",
              "      <td>وآخر فئة من الموظفين ينظر في أمر انهاء خدماتهم...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test.ar-ar.1</td>\n",
              "      <td>خَدَمَ</td>\n",
              "      <td>VERB</td>\n",
              "      <td>7</td>\n",
              "      <td>35</td>\n",
              "      <td>40</td>\n",
              "      <td>8</td>\n",
              "      <td>47</td>\n",
              "      <td>53</td>\n",
              "      <td>وكان ستون من مراقبي الشرطة هؤﻻء قد خدموا في اﻷ...</td>\n",
              "      <td>وكما ورد في تعليقنا السابق، معظم اﻷطفال الجنود...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test.ar-ar.2</td>\n",
              "      <td>نَاقَشَ</td>\n",
              "      <td>VERB</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>وناقشت أفرقة خبراء متعددة القوانين عبر اﻹقليمي...</td>\n",
              "      <td>وناقش المشتركون في اﻻجتماع ١١ ورقة عمل، واستعر...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test.ar-ar.3</td>\n",
              "      <td>نَاقَشَ</td>\n",
              "      <td>VERB</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>26</td>\n",
              "      <td>31</td>\n",
              "      <td>وناقشت أفرقة خبراء متعددة القوانين عبر اﻹقليمي...</td>\n",
              "      <td>ووافق على أنه من اﻷفضل أن تناقش هذه المادة، مع...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test.ar-ar.4</td>\n",
              "      <td>فَهِمَ</td>\n",
              "      <td>VERB</td>\n",
              "      <td>11</td>\n",
              "      <td>58</td>\n",
              "      <td>64</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>ويرى الوزير أنه لا يزال يتعين على أفراد الشعب ...</td>\n",
              "      <td>وقال إنه يفهم أن اللجنة ترغب في اتباع اﻹجراء ذ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  ...                                              sent2\n",
              "0  test.ar-ar.0  ...  وآخر فئة من الموظفين ينظر في أمر انهاء خدماتهم...\n",
              "1  test.ar-ar.1  ...  وكما ورد في تعليقنا السابق، معظم اﻷطفال الجنود...\n",
              "2  test.ar-ar.2  ...  وناقش المشتركون في اﻻجتماع ١١ ورقة عمل، واستعر...\n",
              "3  test.ar-ar.3  ...  ووافق على أنه من اﻷفضل أن تناقش هذه المادة، مع...\n",
              "4  test.ar-ar.4  ...  وقال إنه يفهم أن اللجنة ترغب في اتباع اﻹجراء ذ...\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZ4li2AH8Qzy",
        "outputId": "db0f97f8-a469-4870-d48a-398a05bbd6c9"
      },
      "source": [
        "test_df = pd.concat([test_mix], ignore_index=True)\r\n",
        "print(test_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  id  ...                                              sent2\n",
            "0       test.ar-ar.0  ...  وآخر فئة من الموظفين ينظر في أمر انهاء خدماتهم...\n",
            "1       test.ar-ar.1  ...  وكما ورد في تعليقنا السابق، معظم اﻷطفال الجنود...\n",
            "2       test.ar-ar.2  ...  وناقش المشتركون في اﻻجتماع ١١ ورقة عمل، واستعر...\n",
            "3       test.ar-ar.3  ...  ووافق على أنه من اﻷفضل أن تناقش هذه المادة، مع...\n",
            "4       test.ar-ar.4  ...  وقال إنه يفهم أن اللجنة ترغب في اتباع اﻹجراء ذ...\n",
            "...              ...  ...                                                ...\n",
            "3995  test.ru-ru.995  ...  Обычно событие заставляет человека задуматься ...\n",
            "3996  test.ru-ru.996  ...  Над дном в виде шатра нависает крыша четвёртог...\n",
            "3997  test.ru-ru.997  ...  Над залом нависает гигантский купол с деревянн...\n",
            "3998  test.ru-ru.998  ...  Человеку давно были известны простейшие кузнеч...\n",
            "3999  test.ru-ru.999  ...  Не так давно этот маленький город приносил око...\n",
            "\n",
            "[4000 rows x 11 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKzeUzVKQQBE",
        "outputId": "befb44de-31b5-4805-9ae9-e6a98429fc56"
      },
      "source": [
        "test_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6oExRDcVQgB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dda50c6c-1337-43b2-afed-8b73b5a6dce0"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jan 29 08:56:47 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0    22W / 300W |      0MiB / 16130MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmqHUdDlWC8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86f96bfd-cbf4-45ad-bd44-5b7f4c9e6004"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla V100-SXM2-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxokj4qqWRRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc7e2734-70b3-4804-e1b3-69aa35f15f87"
      },
      "source": [
        "!pip install transformers\r\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/b1/41130a228dd656a1a31ba281598a968320283f48d42782845f6ba567f00b/transformers-4.2.2-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 29.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 30.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=c69e34bbab3749dab29979bc091a6edd3f5f42525c1c9d7ff25396cb2e4686ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.2\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 4.1MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5IQYV8QWVVm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134,
          "referenced_widgets": [
            "370da661841b415b9c5262cc2ae199d6",
            "2d4ed51e14284a2ab503a443cac373f4",
            "394e3d75d47b4ff3a5f9ec6f92a01137",
            "55e7291571ce4ffa85313c9fc76b2ad0",
            "fe18003250d3456eb5f8e122e7f6f72d",
            "b54471d4b9b7482baa4eccbde96a58db",
            "8a1ba48e5a3246f68be1c6c0fb4ddf72",
            "cfa5fded42bb486a8b2f2bd955cf51a0",
            "b4228ce444dd472eb1225daf82dd4850",
            "5a2d0af5fd03426d97f40260f7db29eb",
            "5e46cfee2d1b4eef8174f613deedfff1",
            "3761f4c127bd48fc8c4868297af14118",
            "40ec78f426fe4ebd8b5415dc03170cb4",
            "fc9bede5303942df9c97beb538756f25",
            "ede7760cd9754a43b22d8c54b06cf318",
            "d2c7d9c4a47445d886e6b1c9b1cc0b52"
          ]
        },
        "outputId": "0745e587-0709-4ed4-918b-c908ff2e8c64"
      },
      "source": [
        "from transformers import XLMRobertaTokenizerFast\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading roberta tokenizer...')\n",
        "tokenizer = XLMRobertaTokenizerFast.from_pretrained('xlm-roberta-large')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading roberta tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "370da661841b415b9c5262cc2ae199d6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4228ce444dd472eb1225daf82dd4850",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=9096718.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKogR69WW9im",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2478fe09-8890-4100-ca5d-2f53e489b1a0"
      },
      "source": [
        "# sentences is a list 0f str\n",
        "\n",
        "# Adding a signal without spaces\n",
        "train_sentences_1 =  []\n",
        "train_sentences_2 = []\n",
        "\n",
        "dev_sentences_1 =  []\n",
        "dev_sentences_2 = []\n",
        "\n",
        "test_sentences_1 = []\n",
        "test_sentences_2 = []\n",
        "\n",
        "list_train_sentences_1 = list(train_df['sent1'])\n",
        "list_train_sentences_2 = list(train_df['sent2'])\n",
        "\n",
        "list_dev_sentences_1 =  list(dev_df['sent1'])\n",
        "list_dev_sentences_2 = list(dev_df['sent2'])\n",
        "\n",
        "list_test_sentences_1 =  list(test_df['sent1'])\n",
        "list_test_sentences_2 = list(test_df['sent2'])\n",
        "\n",
        "for i in range(len(list_train_sentences_1)):\n",
        "  sentence_1 = list_train_sentences_1[i]\n",
        "  # print(sentence_1)\n",
        "  s1 = int(train_df['start1'][i])\n",
        "  e1 = int(train_df['end1'][i])\n",
        "  sentence_1 = sentence_1[:s1]+'\" '+sentence_1[s1:e1]+' \"'+ sentence_1[e1:]\n",
        "  train_sentences_1.append(sentence_1)\n",
        "\n",
        "  sentence_2 = list_train_sentences_2[i]\n",
        "  # print(sentence_2)\n",
        "  s2 = int(train_df['start2'][i])\n",
        "  e2 = int(train_df['end2'][i])\n",
        "  sentence_2 = sentence_2[:s2]+'\" '+sentence_2[s2:e2]+' \"'+ sentence_2[e2:]\n",
        "  train_sentences_2.append(sentence_2)\n",
        "  # print((train_sentences_1[i], train_sentences_2[i]))\n",
        "\n",
        "for i in range(len(list_dev_sentences_1)):\n",
        "  d_sentence_1 = list_dev_sentences_1[i]\n",
        "  # print(dev_data_df['start1'][i])\n",
        "  s1 = int(dev_df['start1'][i])\n",
        "  e1 = int(dev_df['end1'][i])\n",
        "  d_sentence_1 = d_sentence_1[:s1]+'\" '+d_sentence_1[s1:e1]+' \"'+ d_sentence_1[e1:]\n",
        "  dev_sentences_1.append(d_sentence_1)\n",
        "  if i == 8:\n",
        "    ars = d_sentence_1\n",
        "\n",
        "  d_sentence_2 = list_dev_sentences_2[i]\n",
        "  s2 = int(dev_df['start2'][i])\n",
        "  e2 = int(dev_df['end2'][i])\n",
        "  d_sentence_2 = d_sentence_2[:s2]+'\" '+d_sentence_2[s2:e2]+' \"'+ d_sentence_2[e2:]\n",
        "  dev_sentences_2.append(d_sentence_2)\n",
        "\n",
        "for i in range(len(list_test_sentences_1)):\n",
        "  d_sentence_1 = list_test_sentences_1[i]\n",
        "  s1 = int(test_df['start1'][i])\n",
        "  e1 = int(test_df['end1'][i])\n",
        "  # print(d_sentence_1)\n",
        "  d_sentence_1 = d_sentence_1[:s1]+'\" '+d_sentence_1[s1:e1]+' \"'+ d_sentence_1[e1:]\n",
        "  test_sentences_1.append(d_sentence_1)\n",
        "\n",
        "  d_sentence_2 = list_test_sentences_2[i]\n",
        "  s2 = int(test_df['start2'][i])\n",
        "  e2 = int(test_df['end2'][i])\n",
        "  # if i==2:\n",
        "  #   print((s2,e2))\n",
        "  #   print(d_sentence_2)\n",
        "  #   print(d_sentence_2[:s2])\n",
        "  #   print(d_sentence_2[s2:e2])\n",
        "  #   print(d_sentence_2[e2:])\n",
        "  #   # print(d_sentence_2[:s2]+'a '+d_sentence_2[s2:e2]+' b'+ d_sentence_2[e2:])\n",
        "  #   # print(d_sentence_2[e2:]+'\" '+d_sentence_2[s2:e2]+' \"'+ d_sentence_2[:s2])\n",
        "  #   print(d_sentence_2[:s2]+'\"'+\" \"+d_sentence_2[s2:e2]+\" \"+'\"'+ d_sentence_2[e2:])\n",
        "  #   # print(d_sentence_2[e2:]+'\"'+d_sentence_2[s2:e2]+'\"'+ d_sentence_2[:s2])\n",
        "  #   print()\n",
        "\n",
        "  d_sentence_2 = d_sentence_2[:s2]+'\" '+d_sentence_2[s2:e2]+' \"'+ d_sentence_2[e2:]\n",
        "  test_sentences_2.append(d_sentence_2)\n",
        "\n",
        "  # print((dev_sentences_1[i], dev_sentences_2[i]))\n",
        "\n",
        "print((train_sentences_2[:10]))\n",
        "print((train_sentences_1[:10]))\n",
        "print(dev_sentences_1[:10])\n",
        "print(dev_sentences_2[:10])\n",
        "print(test_sentences_1[:10])\n",
        "print(test_sentences_2[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A musical \" play \" on the same subject was also staged in Kathmandu for three days.', 'In schools, when water is needed, it is girls who are sent to fetch it, taking time away from their studies and \" play \".', 'Father Lini said that, because of that, the United Nations has a very special place in the affections and \" esteem \" of the people of Vanuatu.', 'This attests to the \" esteem \" and trust enjoyed by your country.', 'A person may be either the \" holder \" of an option, being the person entitled to buy or sell; or the writer of the option, being the person required to honour the holder’s right to buy or sell.', 'Over 5,000 now hold legal immigrant documents, which, after five years of annual renewal, entitles the \" holder \" to apply for permanent residence.', 'The conclusion of the first \" reading \" would make it possible to begin negotiations on a streamlined text.', 'It was precisely that consideration which led the Commission on first \" reading \" to introduce a special regime of compulsory arbitration in cases where countermeasures have been taken.', 'UNDP defines poverty as \"human poverty\", deprivation in the most basic choices people have -- such as to live a long and \" healthy \" life, to be educated, to have the means to a decent standard of living and to be able to be a part of the life of a community.', 'The approach was to promote a \" healthy \" drug-free lifestyle, which should lead to a decline in consumption.']\n",
            "['In that context of coordination and integration, Bolivia holds a key \" play \" in any process of infrastructure development.', 'In that context of coordination and integration, Bolivia holds a key \" play \" in any process of infrastructure development.', 'We would also like to convey our \" esteem \" and congratulations to fraternal Lebanon and its people on the unconditional liberation of its southern part.', 'We would also like to convey our \" esteem \" and congratulations to fraternal Lebanon and its people on the unconditional liberation of its southern part.', 'This growth is the direct result of the increased number of baccalaureate \" holders \", who form the potential market for higher education.', 'This growth is the direct result of the increased number of baccalaureate \" holders \", who form the potential market for higher education.', 'The Units have recreation, including television, \" reading \" and exercise facilities, and arrangements for medical care.', 'The Units have recreation, including television, \" reading \" and exercise facilities, and arrangements for medical care.', 'Yet, protection of the rights of the child called for a \" healthy \" socio-economic environment, financial stability at the national level, sustained economic recovery after financial crises, and international cooperation.', 'Yet, protection of the rights of the child called for a \" healthy \" socio-economic environment, financial stability at the national level, sustained economic recovery after financial crises, and international cooperation.']\n",
            "['ونظرا لأهمية هذه المسائل لسير عمل المحكمة مستقبلا، يلزم توفير \" ملاك \" كاف من الموظفين منذ بدء عملياتها.', 'ونظرا لأهمية هذه المسائل لسير عمل المحكمة مستقبلا، يلزم توفير \" ملاك \" كاف من الموظفين منذ بدء عملياتها.', 'ويؤدي هذا المرض، الذي ينتشر بين أكبر قطاعات السكان إنتاجا، إلى \" فوضى \" اقتصادية كبيرة في البلدان النامية بصفة خاصة، وفي أفريقيا جنوب الصحراء الكبرى على وجه التخصيص.', 'ويؤدي هذا المرض، الذي ينتشر بين أكبر قطاعات السكان إنتاجا، إلى \" فوضى \" اقتصادية كبيرة في البلدان النامية بصفة خاصة، وفي أفريقيا جنوب الصحراء الكبرى على وجه التخصيص.', 'والتشريع ذات الأولوية هو إعادة هيكلة ضرائب \" الخطيئة \" لمنع الشباب من التدخين.', 'والتشريع ذات الأولوية هو إعادة هيكلة ضرائب \" الخطيئة \" لمنع الشباب من التدخين.', 'وأشارت عدة بلدان إلى حجم الموارد بوصفه أحد المعايير المهمة التي \" يحكم \" بموجبها على منظومة اﻷمم المتحدة.', 'وأشارت عدة بلدان إلى حجم الموارد بوصفه أحد المعايير المهمة التي \" يحكم \" بموجبها على منظومة اﻷمم المتحدة.', 'و\" يعكس \" التقدير انخفاضا من ٤٠٠ ٣١ دوﻻر شهريا عن الفترة السابقة نظرا ﻻنخفاض عدد اﻷفراد العسكريين والمدنيين.', 'و\" يعكس \" التقدير انخفاضا من ٤٠٠ ٣١ دوﻻر شهريا عن الفترة السابقة نظرا ﻻنخفاض عدد اﻷفراد العسكريين والمدنيين.']\n",
            "['ولا توجد حراسة أمام جميع البعثات الدبلوماسية بسبب النقص المزمن في \" ملاك \" أفراد الشرطة في مقر قيادتها في العاصمة.', 'وأعربت عن رغبتها في الحصول على معلومات بشأن موارد هاتين الوزارتين و\" ملاكهما \" وبشأن لجان إعادة التأهيل وإعادة التوطين والمساعدة الوارد ذكرها في العرض الشفوي.', 'والواقع أن آلية نزع السلاح المتعددة الأطراف تعاني من \" فوضى \" شديدة.', 'وفي مقابل ذلك، فإنه في حالة تعذر حل هذه المشكلة الخطيرة، سيحفل العالم في القرن الحادي والعشرين بما ينجم عن الفقر من عداوات وسخط و\" فوضى \" اجتماعية.', 'وتم استحداث هذا الحل كخيار متاح للكاثوليكيين الذين لا يرغبون في الطلاق لأنه يعتبر \" خطيئة \" في نظر الكنيسة.', 'تحدث عدد من النساء عن مشاهدة هن لإطلاق النار أو قيام هن بإطلاق النار على المدنيين وما تبع ذلك من شعور هن \" بالخطيئة \".', 'ويقال إن محكمة الشعب ﻹقليم فو كانه \" حكمت \" عليه مرة أخرى بالسجن المؤبد في عام ٦٨٩١ ﻷنه حاول الفرار.', 'وعموما لم تكتمل مجموعة التشريعات التي \" تحكم \" ميدان العمالة وما زالت في مرحلة التكوين.', 'وأن المجموعة على استعداد للتفاوض بحسن نية من أجل وضع جدول \" يعكس \" قدرة كل دولة عضو على الدفع.', 'غير أن المقررة الخاصة تشعر بالقلق ﻷن احصاءات اﻻغتصاب المتاحة ﻻ \" تعكس \" بالتأكيد المدى الحقيقي للمشكلة.']\n",
            "['وكان ستون من مراقبي الشرطة هؤﻻء قد \" خدموا \" في اﻷمم المتحدة من قبل.', 'وكان ستون من مراقبي الشرطة هؤﻻء قد \" خدموا \" في اﻷمم المتحدة من قبل.', '\" وناقشت \" أفرقة خبراء متعددة القوانين عبر اﻹقليمية والقوانين المتصلة بالمواد اﻹباحية المستغل فيها اﻷطفال.', '\" وناقشت \" أفرقة خبراء متعددة القوانين عبر اﻹقليمية والقوانين المتصلة بالمواد اﻹباحية المستغل فيها اﻷطفال.', 'ويرى الوزير أنه لا يزال يتعين على أفراد الشعب العاديين أن \" يفهموا \" أن التعذيب ممارسة غير قانونية وغير مقبولة.', 'ويرى الوزير أنه لا يزال يتعين على أفراد الشعب العاديين أن \" يفهموا \" أن التعذيب ممارسة غير قانونية وغير مقبولة.', 'ومن اﻷمور اﻷخرى التي \" تشغل \" البال بنفس الدرجة ضرورة تعزيز اﻷعمال الصغيرة والمتوسطة الحجم.', 'ومن اﻷمور اﻷخرى التي \" تشغل \" البال بنفس الدرجة ضرورة تعزيز اﻷعمال الصغيرة والمتوسطة الحجم.', 'ولم يمكن تحديد ما إذا كان جنود الجيش الشعبي الكوري، الذين \" ساروا \" لمسافة أكثر من ١٠٠ متر إلى الجنوب من خط تعيين الحدود العسكرية، مسلحين أم ﻻ.', 'ولم يمكن تحديد ما إذا كان جنود الجيش الشعبي الكوري، الذين \" ساروا \" لمسافة أكثر من ١٠٠ متر إلى الجنوب من خط تعيين الحدود العسكرية، مسلحين أم ﻻ.']\n",
            "['وآخر فئة من الموظفين ينظر في أمر انهاء خدماتهم بشكل غير طوعي هم الخبراء والموظفون اﻷكفاء الذين \" خدموا \" المنظمة لفترات طويلة وساهموا في نجاح المنظمة.', 'وكما ورد في تعليقنا السابق، معظم اﻷطفال الجنود \" يخدمون \" حالياً في مجموعات مسلحة غير حكومية، وفي غياب مثل هذا الحكم، سيفقد البروتوكول اﻻختياري الكثير من قوته.', '\" وناقش \" المشتركون في اﻻجتماع ١١ ورقة عمل، واستعرضوا التقدم المحرز في التعاون في ميدان التجارة والتنمية ووضعوا عدة توصيات من أجل اتخاذ إجراءات مستقبلية.', 'ووافق على أنه من اﻷفضل أن \" تناقش \" هذه المادة، مع ذكر هذه النقطة في دليل التشريع.', 'وقال إنه \" يفهم \" أن اللجنة ترغب في اتباع اﻹجراء ذاته في الدورة الحالية.', 'وقال إنه \" يفهم \" أن المكتب يرغب في الموافقة على هذه الطلبات.', 'وفي الفترة من ١٩٩١ الى ١٩٩٤ شغل منصب رئيس لجنة المراجعة الخارجية لحسابات الصندوق الدولي للتنمية الزراعية، \" وشغل \" في الفترة نفسها منصب رئيس الوفد اﻹيطالي في مؤتمر التجديد الثالث لموارد الصندوق.', 'وفي الوقت الراهن، \" تشغل \" إحدى النساء أعلى منصب وظيفي في الخدمة المدنية بإقليم هونغ كونغ اﻹداري الخاص، وهو منصب كبير أمناء اﻹدارة.', 'وفي هذه الصراعات، كانت المعاناة البشرية ضخمة، أما التنمية فلم تتوقف فحسب بل \" سارت \" في اتجاه معاكس.', 'وأوضح أن حقوق المستهلك تُصان على نحو أكثر صراحة في التشريعات المتعلقة بحماية المستهلك والتي ينبغي أن \" تسير \" جنباً إلى جنب مع قانون المنافسة.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNh3KxV_qC5q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be84b202-1cc1-4e03-cb9e-f7d5bf1dbbe8"
      },
      "source": [
        "encoded_inputs_train = tokenizer(train_sentences_1, train_sentences_2, padding = True, truncation = True, return_tensors = 'pt', return_offsets_mapping=True)\n",
        "print(len(encoded_inputs_train['input_ids'][0]))\n",
        "print(type(encoded_inputs_train['input_ids']))\n",
        "\n",
        "\n",
        "encoded_inputs_dev = tokenizer(dev_sentences_1, dev_sentences_2, padding = True, truncation = True, return_tensors = 'pt', return_offsets_mapping=True)\n",
        "print(len(encoded_inputs_dev['input_ids'][0]))\n",
        "print(type(encoded_inputs_dev['input_ids']))\n",
        "\n",
        "encoded_inputs_test = tokenizer(test_sentences_1, test_sentences_2, padding = True, truncation = True, return_tensors = 'pt', return_offsets_mapping=True)\n",
        "\n",
        "print(test_sentences_1[2])\n",
        "print(test_sentences_2[2])\n",
        "print((encoded_inputs_test['offset_mapping'][2]))\n",
        "print((encoded_inputs_test['input_ids'][2]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "250\n",
            "<class 'torch.Tensor'>\n",
            "176\n",
            "<class 'torch.Tensor'>\n",
            "\" وناقشت \" أفرقة خبراء متعددة القوانين عبر اﻹقليمية والقوانين المتصلة بالمواد اﻹباحية المستغل فيها اﻷطفال.\n",
            "\" وناقش \" المشتركون في اﻻجتماع ١١ ورقة عمل، واستعرضوا التقدم المحرز في التعاون في ميدان التجارة والتنمية ووضعوا عدة توصيات من أجل اتخاذ إجراءات مستقبلية.\n",
            "tensor([[  0,   0],\n",
            "        [  0,   1],\n",
            "        [  2,   3],\n",
            "        [  3,   7],\n",
            "        [  7,   8],\n",
            "        [  9,  10],\n",
            "        [ 11,  13],\n",
            "        [ 13,  16],\n",
            "        [ 17,  20],\n",
            "        [ 20,  22],\n",
            "        [ 23,  29],\n",
            "        [ 30,  38],\n",
            "        [ 39,  42],\n",
            "        [ 43,  49],\n",
            "        [ 49,  50],\n",
            "        [ 51,  55],\n",
            "        [ 55,  58],\n",
            "        [ 58,  60],\n",
            "        [ 61,  65],\n",
            "        [ 65,  68],\n",
            "        [ 69,  73],\n",
            "        [ 73,  76],\n",
            "        [ 77,  78],\n",
            "        [ 78,  81],\n",
            "        [ 81,  83],\n",
            "        [ 84,  89],\n",
            "        [ 89,  91],\n",
            "        [ 92,  96],\n",
            "        [ 97, 102],\n",
            "        [102, 103],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   1],\n",
            "        [  2,   3],\n",
            "        [  3,   7],\n",
            "        [  8,   9],\n",
            "        [ 10,  17],\n",
            "        [ 17,  19],\n",
            "        [ 20,  22],\n",
            "        [ 23,  29],\n",
            "        [ 30,  31],\n",
            "        [ 31,  32],\n",
            "        [ 33,  34],\n",
            "        [ 34,  37],\n",
            "        [ 38,  41],\n",
            "        [ 41,  42],\n",
            "        [ 43,  47],\n",
            "        [ 47,  50],\n",
            "        [ 50,  52],\n",
            "        [ 53,  59],\n",
            "        [ 60,  65],\n",
            "        [ 65,  66],\n",
            "        [ 67,  69],\n",
            "        [ 70,  77],\n",
            "        [ 78,  80],\n",
            "        [ 81,  86],\n",
            "        [ 87,  94],\n",
            "        [ 95, 103],\n",
            "        [104, 108],\n",
            "        [108, 110],\n",
            "        [111, 114],\n",
            "        [115, 116],\n",
            "        [115, 121],\n",
            "        [122, 124],\n",
            "        [125, 128],\n",
            "        [129, 134],\n",
            "        [135, 142],\n",
            "        [143, 149],\n",
            "        [149, 151],\n",
            "        [151, 152],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0],\n",
            "        [  0,   0]])\n",
            "tensor([     0,     44,     65,  95019,    368,     44, 127039, 102015,   5363,\n",
            "          2689, 172789, 203982,  18740, 175450,    250,  73255,  12880,    755,\n",
            "         15330, 134961,  21188,  57829,   6094, 101951,    648,  34345,  17440,\n",
            "         13061,  68225,      5,      2,      2,     44,     65,  95019,     44,\n",
            "        121349,    900,    240, 133131,  47741,  68452,     65, 102015,   4351,\n",
            "            50,  45311,  36276,   1778, 181531, 182106,   1469,    240,  93895,\n",
            "           240, 103153, 154235, 210601, 175237,   1778,  53411,      6, 240812,\n",
            "           230,  30933, 129567, 185495,  58412,    648,      5,      2,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "WRMoPIEakCZ6",
        "outputId": "8cc8103b-2242-4ada-b8d3-69f4935c46f3"
      },
      "source": [
        "train_sentences_1[800]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The \" disintegration \" of rigid systems like those of the Soviet Union and the former Yugoslavia has produced a number of new States and new Members of the United Nations.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTLVc7VGtaWs"
      },
      "source": [
        "def check_end(offsets, i, e):\r\n",
        "  d = offsets[i][0]\r\n",
        "\r\n",
        "  for j in range(i, len(offsets)):\r\n",
        "    a = offsets[j][0]\r\n",
        "    b = offsets[j][1]\r\n",
        "\r\n",
        "    if (b==e):\r\n",
        "      return True\r\n",
        "    \r\n",
        "    if (a == d):\r\n",
        "      d = b\r\n",
        "      continue\r\n",
        "    else:\r\n",
        "      return False\r\n",
        "  return False\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83_jD71Y72Xb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0527ec5e-9719-41c8-a8da-0d8683c0f220"
      },
      "source": [
        "# create wordpeice indices of the words of interest now\n",
        "# be aware, that due to signal the actual token have their positions offsetted\n",
        "train_pos_1 = []\n",
        "train_pos_2 = []\n",
        "\n",
        "for j in range(len(train_sentences_1)):\n",
        "  offsets = encoded_inputs_train['offset_mapping'][j].detach().numpy()\n",
        "  second_sent = False\n",
        "  s1 = int(train_df['start1'][j])\n",
        "  s2 = int(train_df['start2'][j])\n",
        "  e1 = int(train_df['end1'][j])\n",
        "  e2 = int(train_df['end2'][j])\n",
        "  pos1 = -1\n",
        "  pos2 = -1\n",
        "  for i, offset in enumerate(offsets):\n",
        "    if i == 0:\n",
        "      continue #cls\n",
        "    if offset[1] == 0:\n",
        "      second_sent = True\n",
        "\n",
        "    if offset[0] == s1+1+1 and second_sent == False:\n",
        "      if check_end(offsets, i, e1+1+1):\n",
        "        pos1 = i\n",
        "    elif offset[0] == s2+1+1 and second_sent == True:\n",
        "      if check_end(offsets, i, e2+1+1):\n",
        "        pos2 = i\n",
        "        break\n",
        "  if pos1 == -1 or pos2 ==-1:\n",
        "    second_sent = False\n",
        "    for i, offset in enumerate(offsets):\n",
        "      if i == 0:\n",
        "        continue #cls\n",
        "      if offset[1] == 0 and not offsets[i-1][1]==0:\n",
        "        second_sent = True\n",
        "\n",
        "      if offset[0] == s1+1 and second_sent == False:\n",
        "        if check_end(offsets, i, e1+1):\n",
        "          pos1 = i\n",
        "      elif offset[0] == s2+1 and second_sent == True:\n",
        "        if check_end(offsets, i, e2+1):\n",
        "          pos2 = i\n",
        "          break\n",
        "  if pos1 == -1 or pos2 ==-1:\n",
        "    second_sent = False\n",
        "    for i, offset in enumerate(offsets):\n",
        "      if i == 0:\n",
        "        continue #cls\n",
        "      if offset[1] == 0:\n",
        "        second_sent = True\n",
        "\n",
        "      if offset[0] == s1 and second_sent == False:\n",
        "        if check_end(offsets, i, e1):\n",
        "          pos1 = i\n",
        "      elif offset[0] == s2 and second_sent == True:\n",
        "        if check_end(offsets, i, e2):\n",
        "          pos2 = i\n",
        "          break\n",
        "  if pos1 == -1 or pos2 ==-1:\n",
        "    second_sent = False\n",
        "    for i, offset in enumerate(offsets):\n",
        "      if i == 0:\n",
        "        continue #cls\n",
        "      if offset[1] == 0:\n",
        "        second_sent = True\n",
        "\n",
        "      if offset[0] == s1-1 and second_sent == False:\n",
        "        if check_end(offsets, i, e1-1):\n",
        "          pos1 = i\n",
        "      elif offset[0] == s2-1 and second_sent == True:\n",
        "        if check_end(offsets, i, e2-1):\n",
        "          pos2 = i\n",
        "          break\n",
        "\n",
        "  if pos1 == -1 or pos2 ==-1:\n",
        "    second_sent = False\n",
        "    for i, offset in enumerate(offsets):\n",
        "      if i == 0:\n",
        "        continue #cls\n",
        "      if offset[1] == 0:\n",
        "        second_sent = True\n",
        "\n",
        "      if offset[0] == s1-2 and second_sent == False:\n",
        "        if check_end(offsets, i, e1-2):\n",
        "          pos1 = i\n",
        "      elif offset[0] == s2-2 and second_sent == True:\n",
        "        if check_end(offsets, i, e2-2):\n",
        "          pos2 = i\n",
        "          break\n",
        "  train_pos_1.append(pos1)\n",
        "  train_pos_2.append(pos2)\n",
        "# print(train_pos_1)\n",
        "# print(train_pos_2)\n",
        "\n",
        "dev_pos_1 = []\n",
        "dev_pos_2 = []\n",
        "\n",
        "for j in range(len(dev_sentences_1)):\n",
        "  offsets = encoded_inputs_dev['offset_mapping'][j].detach().numpy()\n",
        "  second_sent = False\n",
        "  s1 = int(dev_df['start1'][j])\n",
        "  s2 = int(dev_df['start2'][j])\n",
        "  e1 = int(dev_df['end1'][j])\n",
        "  e2 = int(dev_df['end2'][j])\n",
        "  pos1 = -1\n",
        "  pos2 = -1\n",
        "  for i, offset in enumerate(offsets):\n",
        "    if i == 0:\n",
        "      continue #cls\n",
        "    if offset[1] == 0:\n",
        "      second_sent = True\n",
        "\n",
        "    if offset[0] == s1+1+1 and second_sent == False:\n",
        "      if check_end(offsets, i, e1+1+1):\n",
        "        pos1 = i\n",
        "    elif offset[0] == s2+1+1 and second_sent == True:\n",
        "      if check_end(offsets, i, e2+1+1):\n",
        "        pos2 = i\n",
        "        break\n",
        "  if pos1 == -1 or pos2 ==-1:\n",
        "    second_sent = False\n",
        "    for i, offset in enumerate(offsets):\n",
        "      if i == 0:\n",
        "        continue #cls\n",
        "      if offset[1] == 0:\n",
        "        second_sent = True\n",
        "\n",
        "      if offset[0] == s1+1 and second_sent == False:\n",
        "        if check_end(offsets, i, e1+1):\n",
        "          pos1 = i\n",
        "      elif offset[0] == s2+1 and second_sent == True:\n",
        "        if check_end(offsets, i, e2+1):\n",
        "          pos2 = i\n",
        "          break\n",
        "  if pos1 == -1 or pos2 ==-1:\n",
        "    second_sent = False\n",
        "    for i, offset in enumerate(offsets):\n",
        "      if i == 0:\n",
        "        continue #cls\n",
        "      if offset[1] == 0:\n",
        "        second_sent = True\n",
        "\n",
        "      if offset[0] == s1 and second_sent == False:\n",
        "        if check_end(offsets, i, e1):\n",
        "          pos1 = i\n",
        "      elif offset[0] == s2 and second_sent == True:\n",
        "        if check_end(offsets, i, e2):\n",
        "          pos2 = i\n",
        "          break\n",
        "  if pos1 == -1 or pos2 ==-1:\n",
        "    second_sent = False\n",
        "    for i, offset in enumerate(offsets):\n",
        "      if i == 0:\n",
        "        continue #cls\n",
        "      if offset[1] == 0:\n",
        "        second_sent = True\n",
        "\n",
        "      if offset[0] == s1-1 and second_sent == False:\n",
        "        if check_end(offsets, i, e1-1):\n",
        "          pos1 = i\n",
        "      elif offset[0] == s2-1 and second_sent == True:\n",
        "        if check_end(offsets, i, e2-1):\n",
        "          pos2 = i\n",
        "          break\n",
        "\n",
        "  if pos1 == -1 or pos2 ==-1:\n",
        "    second_sent = False\n",
        "    for i, offset in enumerate(offsets):\n",
        "      if i == 0:\n",
        "        continue #cls\n",
        "      if offset[1] == 0:\n",
        "        second_sent = True\n",
        "\n",
        "      if offset[0] == s1-2 and second_sent == False:\n",
        "        if check_end(offsets, i, e1-2):\n",
        "          pos1 = i\n",
        "      elif offset[0] == s2-2 and second_sent == True:\n",
        "        if check_end(offsets, i, e2-2):\n",
        "          pos2 = i\n",
        "          break\n",
        "  dev_pos_1.append(pos1)\n",
        "  dev_pos_2.append(pos2)\n",
        "\n",
        "test_pos_1 = []\n",
        "test_pos_2 = []\n",
        "\n",
        "for j in range(len(test_sentences_1)):\n",
        "  offsets = encoded_inputs_test['offset_mapping'][j].detach().numpy()\n",
        "  second_sent = False\n",
        "  s1 = int(test_df['start1'][j])\n",
        "  s2 = int(test_df['start2'][j])\n",
        "  e1 = int(test_df['end1'][j])\n",
        "  e2 = int(test_df['end2'][j])\n",
        "  pos1 = -1\n",
        "  pos2 = -1\n",
        "  for i, offset in enumerate(offsets):\n",
        "    if i == 0:\n",
        "      continue #cls\n",
        "    if offset[1] == 0:\n",
        "      second_sent = True\n",
        "\n",
        "    if offset[0] == s1+1+1 and second_sent == False:\n",
        "      if check_end(offsets, i, e1+1+1):\n",
        "        pos1 = i\n",
        "    elif offset[0] == s2+1+1 and second_sent == True:\n",
        "      if check_end(offsets, i, e2+1+1):\n",
        "        pos2 = i\n",
        "        break\n",
        "  if pos1 == -1 or pos2 ==-1:\n",
        "    second_sent = False\n",
        "    for i, offset in enumerate(offsets):\n",
        "      if i == 0:\n",
        "        continue #cls\n",
        "      if offset[1] == 0:\n",
        "        second_sent = True\n",
        "\n",
        "      if offset[0] == s1+1 and second_sent == False:\n",
        "        if check_end(offsets, i, e1+1):\n",
        "          pos1 = i\n",
        "      elif offset[0] == s2+1 and second_sent == True:\n",
        "        if check_end(offsets, i, e2+1):\n",
        "          pos2 = i\n",
        "          break\n",
        "  if pos1 == -1 or pos2 ==-1:\n",
        "    second_sent = False\n",
        "    for i, offset in enumerate(offsets):\n",
        "      if i == 0:\n",
        "        continue #cls\n",
        "      if offset[1] == 0:\n",
        "        second_sent = True\n",
        "\n",
        "      if offset[0] == s1 and second_sent == False:\n",
        "        if check_end(offsets, i, e1):\n",
        "          pos1 = i\n",
        "      elif offset[0] == s2 and second_sent == True:\n",
        "        if check_end(offsets, i, e2):\n",
        "          pos2 = i\n",
        "          break\n",
        "  if pos1 == -1 or pos2 ==-1:\n",
        "    second_sent = False\n",
        "    for i, offset in enumerate(offsets):\n",
        "      if i == 0:\n",
        "        continue #cls\n",
        "      if offset[1] == 0:\n",
        "        second_sent = True\n",
        "\n",
        "      if offset[0] == s1-1 and second_sent == False:\n",
        "        if check_end(offsets, i, e1-1):\n",
        "          pos1 = i\n",
        "      elif offset[0] == s2-1 and second_sent == True:\n",
        "        if check_end(offsets, i, e2-1):\n",
        "          pos2 = i\n",
        "          break\n",
        "\n",
        "  if pos1 == -1 or pos2 ==-1:\n",
        "    second_sent = False\n",
        "    for i, offset in enumerate(offsets):\n",
        "      if i == 0:\n",
        "        continue #cls\n",
        "      if offset[1] == 0:\n",
        "        second_sent = True\n",
        "\n",
        "      if offset[0] == s1-2 and second_sent == False:\n",
        "        if check_end(offsets, i, e1-2):\n",
        "          pos1 = i\n",
        "      elif offset[0] == s2-2 and second_sent == True:\n",
        "        if check_end(offsets, i, e2-2):\n",
        "          pos2 = i\n",
        "          break\n",
        "  test_pos_1.append(pos1)\n",
        "  test_pos_2.append(pos2)\n",
        "print(dev_pos_1[:100])\n",
        "print(dev_pos_2[800:810])\n",
        "print(test_pos_1[:10])\n",
        "print(len(test_pos_2))\n",
        "\n",
        "train_pos_1 = torch.LongTensor(train_pos_1)\n",
        "train_pos_2 = torch.LongTensor(train_pos_2)\n",
        "\n",
        "train_pos = torch.stack((train_pos_1, train_pos_2), dim =1)\n",
        "\n",
        "dev_pos_1 = torch.LongTensor(dev_pos_1)\n",
        "dev_pos_2 = torch.LongTensor(dev_pos_2)\n",
        "\n",
        "dev_pos = torch.stack((dev_pos_1, dev_pos_2), dim=1)\n",
        "\n",
        "test_pos_1 = torch.LongTensor(test_pos_1)\n",
        "test_pos_2 = torch.LongTensor(test_pos_2)\n",
        "\n",
        "test_pos = torch.stack((test_pos_1, test_pos_2), dim=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[20, 20, 21, 21, 17, 17, 18, 18, 3, 1, 21, 21, 8, 8, 25, 25, 19, 19, 62, 62, 8, 8, 4, 4, 7, 7, 6, 6, 3, 3, 53, 53, 32, 32, 8, 8, 3, 3, 3, 3, 4, 4, 9, 9, 3, 3, 3, 3, 8, 8, 12, 12, 12, 12, 4, 4, 3, 3, 3, 3, 6, 6, 11, 11, 8, 8, 22, 22, 50, 50, 10, 10, 6, 6, 31, 31, 9, 9, 3, 3, 6, 6, 17, 17, 4, 4, 7, 7, 9, 9, 4, 4, 7, 7, 7, 7, 3, 3, 3, 6]\n",
            "[37, 38, 32, 40, 43, 68, 46, 48, 44, 53]\n",
            "[11, 11, 2, 2, 18, 18, 6, 6, 16, 16]\n",
            "4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLQvrr_Auw_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3892ae79-4dd5-42aa-ef04-872d2dd9bc36"
      },
      "source": [
        "# labels = torch.from_numpy(train_gold_df['label'].values)\n",
        "train_gold_df_tmp = train_df[['tag']].replace({'F' : 0, 'T' : 1})\n",
        "train_labels = torch.from_numpy(train_gold_df_tmp.values)\n",
        "print(train_labels)\n",
        "\n",
        "dev_gold_df_tmp = dev_df[['tag']].replace({'F' : 0, 'T' : 1})\n",
        "dev_labels = torch.from_numpy(dev_gold_df_tmp.values)\n",
        "\n",
        "# test_gold_df_tmp = test_df[['tag']].replace({'F' : 0, 'T' : 1})\n",
        "# test_labels = torch.from_numpy(test_gold_df_tmp.values)\n",
        "# print(len(test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0],\n",
            "        [0],\n",
            "        [1],\n",
            "        ...,\n",
            "        [0],\n",
            "        [0],\n",
            "        [0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17X2mWJJFuUB"
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "train_dataset = TensorDataset(encoded_inputs_train['input_ids'],\n",
        "                              encoded_inputs_train['attention_mask'], train_pos, train_labels)\n",
        "\n",
        "dev_dataset = TensorDataset(encoded_inputs_dev['input_ids'],\n",
        "                              encoded_inputs_dev['attention_mask'], dev_pos, dev_labels)\n",
        "\n",
        "test_dataset = TensorDataset(encoded_inputs_test['input_ids'],\n",
        "                              encoded_inputs_test['attention_mask'], test_pos\n",
        "                            #  , test_labels\n",
        "                             )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIOoyHpCGo9U"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 8\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "dev_dataloader = DataLoader(\n",
        "            dev_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(dev_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "            test_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMHW4hZoFST1"
      },
      "source": [
        "**Models and training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odLzbaVGGw0F"
      },
      "source": [
        "from transformers import XLMRobertaModel, AdamW, BertConfig\n",
        "import torch.nn as nn\n",
        "\n",
        "class BERTi(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(BERTi, self).__init__()\n",
        "\n",
        "        options_name = \"xlm-roberta-large\"\n",
        "        hidden_states = False\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(options_name, output_hidden_states = hidden_states, return_dict = False)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        last_layer, _ = self.encoder(input_ids = input_ids, attention_mask = attention_mask)\n",
        "\n",
        "        return last_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gfYEvqv-qET"
      },
      "source": [
        "class Logistic_Reg(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Logistic_Reg, self).__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(2048, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BMpmNJmG3QN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "4528d61c108444008972a68e7204567e",
            "83bb3c06e3414d66aa72ce1968ca8a0b",
            "047255609d9b4b3c90134f4ef7399afc",
            "2d0b82bb2c6449d5a1b548a4178a3308",
            "f97fc2475c934109900d2f8d613bacd6",
            "46528e479b0f4fc2bb9b885e31ab2f87",
            "494966b60ba54027b7ad3400cd21ff88",
            "a87428ab905c4c5f90b3626bb5cf6a80",
            "23879fd7717d4a7580c505c590b97cd5",
            "a21bbda241c24f18bd474939f9965163",
            "3bbb6c6a05d04b2a895998a267930fb2",
            "c1fddf7607b048b289afbe59a7564d29",
            "661adc79f7124943892ee218222d27b2",
            "cc283b767df743c4af0946fa35995d38",
            "94a7a0890ae74ec88b30d092ddb77f68",
            "3c81987e98d748a1b217a40897851761"
          ]
        },
        "outputId": "88e47e1a-2e32-41e2-addc-0688dffe6590"
      },
      "source": [
        "model_bert = BERTi().to(device)\n",
        "model_log_reg = Logistic_Reg().to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4528d61c108444008972a68e7204567e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=513.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23879fd7717d4a7580c505c590b97cd5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2244861551.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaxHb5XzHSA9"
      },
      "source": [
        "optimizer = AdamW(list(model_bert.parameters()) + list(model_log_reg.parameters()),\n",
        "                  lr = 1e-5, # args.learning_rate - default is 5e-5, our notebook had 1e-5\n",
        "                  eps = 1e-8 ,\n",
        "                  # weight_decay = 1 # args.adam_epsilon  - default is 1e-8.\n",
        "                  )\n",
        "\n",
        "# scheduler??\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZMmS3xuw742"
      },
      "source": [
        "def loss_fn(output, targets):\n",
        "  return nn.BCEWithLogitsLoss(reduction='mean')(output, targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzEgsIg25ivt"
      },
      "source": [
        "def cross_entropy(predictions, targets):\r\n",
        "    N = predictions.shape[0]\r\n",
        "    predictions = 1/(1+np.exp(-predictions))\r\n",
        "    ce = -np.sum(targets * np.log(predictions) + (1-targets) * np.log(1-predictions)) / N\r\n",
        "    return ce\r\n",
        "\r\n",
        "def cross_entropy_avg(predictions, targets,m):\r\n",
        "    N = predictions.shape[0]\r\n",
        "    predictions = 1/(1+np.exp(-predictions))\r\n",
        "    predictions = (predictions[:m]+predictions[m:])/2\r\n",
        "    ce = -np.sum(targets * np.log(predictions) + (1-targets) * np.log(1-predictions)) / N\r\n",
        "    return ce"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGjyERYSd68E"
      },
      "source": [
        "def flat_accuracy_single_logit(preds, labels):\n",
        "    pred_flat = (preds>0).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    # print(pred_flat.shape)\n",
        "    # print(labels_flat)\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhjY0RPw8Civ"
      },
      "source": [
        "# path_en = \"/content/drive/MyDrive/datasets/final/models/English/xlmr_mix_no_en_1\"\n",
        "path_mix = \"/content/drive/MyDrive/SemEval Models b/Mix/Seq/xlmr_spaced_mcl_xlwic_7.2k_mix_seq_run_2\"\n",
        "path_ar = \"/content/drive/MyDrive/SemEval Models b/Arabic/xlmr_spaced_mcl_xlwic_7.2k_mix_seq_run_2\"\n",
        "path_en = \"/content/drive/MyDrive/SemEval Models b/English/xlmr_spaced_mcl_xlwic_7.2k_mix_seq_run_2\"\n",
        "path_fr = \"/content/drive/MyDrive/SemEval Models b/French/xlmr_spaced_mcl_xlwic_7.2k_mix_seq_run_2\"\n",
        "path_ru = \"/content/drive/MyDrive/SemEval Models b/Russian/xlmr_spaced_mcl_xlwic_7.2k_mix_seq_run_2\"\n",
        "path_zh = \"/content/drive/MyDrive/SemEval Models b/Chinese/xlmr_spaced_mcl_xlwic_7.2k_mix_seq_run_2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBd7Pv-yHiv8"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0pG6f5CHkqF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eed57cc-4cf8-4711-ad8b-d4f8bd68e097"
      },
      "source": [
        "# import random\n",
        "# import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "epochs = 15\n",
        "best_val_accuracy = 0\n",
        "best_val_accuracy_ar = 0\n",
        "best_val_accuracy_en = 0\n",
        "best_val_accuracy_fr = 0\n",
        "best_val_accuracy_ru = 0\n",
        "best_val_accuracy_zh = 0\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model_bert.train()\n",
        "    model_log_reg.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # if epoch_i ==0:\n",
        "        #   break\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 100 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        if step == int(len(train_dataloader)/4) or step == int(2*len(train_dataloader)/4) or step == int(3*len(train_dataloader)/4):\n",
        "          print(\"\")\n",
        "          print(\"Running Validation...\")\n",
        "\n",
        "          t0 = time.time()\n",
        "\n",
        "          # Put the model in evaluation mode--the dropout layers behave differently\n",
        "          # during evaluation.\n",
        "          model_bert.eval()\n",
        "          model_log_reg.eval()\n",
        "\n",
        "          # Tracking variables \n",
        "          total_eval_accuracy = 0\n",
        "          total_eval_loss = 0\n",
        "          nb_eval_steps = 0\n",
        "\n",
        "          t_labels = []\n",
        "          t_preds = []\n",
        "\n",
        "          # Evaluate data for one epoch\n",
        "          for batch_dev in dev_dataloader:\n",
        "\n",
        "              with torch.no_grad():\n",
        "                  b_input_ids = batch_dev[0].to(device)\n",
        "                  b_attention_mask = batch_dev[1].to(device)\n",
        "                  b_poses = batch_dev[2].to(device)\n",
        "                  b_labels = batch_dev[3].to(device)        \n",
        "\n",
        "                  last_layer = model_bert(b_input_ids, b_attention_mask)\n",
        "                  b_poses = b_poses.unsqueeze(-1).repeat(1, 1, 1024)\n",
        "                  gathered_activations = torch.gather(last_layer, 1, b_poses)\n",
        "                  logits = model_log_reg(gathered_activations.view(gathered_activations.size()[0], -1))\n",
        "                  loss = loss_fn(logits, b_labels.type_as(logits))\n",
        "                  \n",
        "              # Accumulate the validation loss.\n",
        "              total_eval_loss += loss.item()\n",
        "\n",
        "              # Move logits and labels to CPU\n",
        "              logits = logits.cpu().detach().numpy()\n",
        "              # print(logits)\n",
        "              label_ids = b_labels.cpu().numpy()\n",
        "\n",
        "              t_labels.append(label_ids)\n",
        "              t_preds.append(logits)\n",
        "              \n",
        "\n",
        "          all_dev_labels = np.concatenate(t_labels, axis=0)\n",
        "          all_dev_logits = np.concatenate(t_preds, axis=0)\n",
        "          # Report the final accuracy for this validation run.\n",
        "          # print(all_dev_logits)\n",
        "          avg_val_accuracy = flat_accuracy_single_logit(all_dev_logits[:800], all_dev_labels[:800])\n",
        "          print(\"Validation Accuracy: {0:.4f}\".format(avg_val_accuracy))\n",
        "          en_dev_acc = flat_accuracy_single_logit(all_dev_logits[800:], all_dev_labels[800:])\n",
        "\n",
        "\n",
        "          # ar_dev_acc = flat_accuracy_single_logit(all_dev_logits[200:].reshape(2,200)[:,:50].ravel(), all_dev_labels[200:].reshape(2,200)[:,:50].ravel())\n",
        "          # zh_dev_acc = flat_accuracy_single_logit(all_dev_logits[200:].reshape(2,200)[:,50:100].ravel(), all_dev_labels[200:].reshape(2,200)[:,50:100].ravel())\n",
        "          # fr_dev_acc = flat_accuracy_single_logit(all_dev_logits[200:].reshape(2,200)[:,100:150].ravel(), all_dev_labels[200:].reshape(2,200)[:,100:150].ravel())\n",
        "          # ru_dev_acc = flat_accuracy_single_logit(all_dev_logits[200:].reshape(2,200)[:,150:200].ravel(), all_dev_labels[200:].reshape(2,200)[:,150:200].ravel())\n",
        "          ar_dev_acc = flat_accuracy_single_logit(all_dev_logits[:200], all_dev_labels[:200])\n",
        "          zh_dev_acc = flat_accuracy_single_logit(all_dev_logits[600:800], all_dev_labels[600:800])\n",
        "          fr_dev_acc = flat_accuracy_single_logit(all_dev_logits[200:400], all_dev_labels[200:400])\n",
        "          ru_dev_acc = flat_accuracy_single_logit(all_dev_logits[400:600], all_dev_labels[400:600])\n",
        "\n",
        "          print(\"AR dev Accuracy: {0:.4f} \".format(ar_dev_acc))\n",
        "          print(\"FR dev Accuracy: {0:.4f} \".format(fr_dev_acc))\n",
        "          print(\"RU dev Accuracy: {0:.4f} \".format(ru_dev_acc))\n",
        "          print(\"ZH dev Accuracy: {0:.4f} \".format(zh_dev_acc))\n",
        "          print(\"EN dev Accuracy: {0:.4f}\".format(en_dev_acc))\n",
        "\n",
        "          # Calculate the average loss over all of the batches.\n",
        "          avg_val_loss = cross_entropy(all_dev_logits[:800], all_dev_labels[:800])\n",
        "          \n",
        "          # Measure how long the validation run took.\n",
        "          validation_time = format_time(time.time() - t0)\n",
        "\n",
        "          if(avg_val_accuracy > best_val_accuracy):\n",
        "            flag = True\n",
        "            best_val_accuracy = avg_val_accuracy\n",
        "            best_val_preds = all_dev_logits\n",
        "            torch.save(model_bert.state_dict(), os.path.join(path_mix, \"xlmr_check_best_dev\"))\n",
        "            torch.save(model_log_reg.state_dict(), os.path.join(path_mix, \"log_reg_check_best_dev\"))\n",
        "            np.save(os.path.join(path_mix, \"best_dev_preds\"), best_val_preds)\n",
        "\n",
        "          if(ar_dev_acc > best_val_accuracy_ar):\n",
        "            flag = True\n",
        "            best_val_accuracy_ar = ar_dev_acc\n",
        "            best_val_preds_ar = all_dev_logits\n",
        "            torch.save(model_bert.state_dict(), os.path.join(path_ar, \"xlmr_check_best_dev\"))\n",
        "            torch.save(model_log_reg.state_dict(), os.path.join(path_ar, \"log_reg_check_best_dev\"))\n",
        "            np.save(os.path.join(path_ar, \"best_dev_preds\"), best_val_preds_ar)\n",
        "\n",
        "          if(fr_dev_acc > best_val_accuracy_fr):\n",
        "            flag = True\n",
        "            best_val_accuracy_fr = fr_dev_acc\n",
        "            best_val_preds_fr = all_dev_logits\n",
        "            torch.save(model_bert.state_dict(), os.path.join(path_fr, \"xlmr_check_best_dev\"))\n",
        "            torch.save(model_log_reg.state_dict(), os.path.join(path_fr, \"log_reg_check_best_dev\"))\n",
        "            np.save(os.path.join(path_fr, \"best_dev_preds\"), best_val_preds_fr)\n",
        "\n",
        "          if(ru_dev_acc > best_val_accuracy_ru):\n",
        "            flag = True\n",
        "            best_val_accuracy_ru = ru_dev_acc\n",
        "            best_val_preds_ru = all_dev_logits\n",
        "            torch.save(model_bert.state_dict(), os.path.join(path_ru, \"xlmr_check_best_dev\"))\n",
        "            torch.save(model_log_reg.state_dict(), os.path.join(path_ru, \"log_reg_check_best_dev\"))\n",
        "            np.save(os.path.join(path_ru, \"best_dev_preds\"), best_val_preds_ru)\n",
        "\n",
        "          if(zh_dev_acc > best_val_accuracy_zh):\n",
        "            flag = True\n",
        "            best_val_accuracy_zh = zh_dev_acc\n",
        "            best_val_preds_zh = all_dev_logits\n",
        "            torch.save(model_bert.state_dict(), os.path.join(path_zh, \"xlmr_check_best_dev\"))\n",
        "            torch.save(model_log_reg.state_dict(), os.path.join(path_zh, \"log_reg_check_best_dev\"))\n",
        "            np.save(os.path.join(path_zh, \"best_dev_preds\"), best_val_preds_zh)\n",
        "\n",
        "          if(en_dev_acc > best_val_accuracy_en):\n",
        "            flag = True\n",
        "            best_val_accuracy_en = en_dev_acc\n",
        "            best_val_preds_en = all_dev_logits\n",
        "            torch.save(model_bert.state_dict(), os.path.join(path_en, \"xlmr_check_best_dev\"))\n",
        "            torch.save(model_log_reg.state_dict(), os.path.join(path_en, \"log_reg_check_best_dev\"))\n",
        "            np.save(os.path.join(path_en, \"best_dev_preds\"), best_val_preds_en)\n",
        "          \n",
        "          print(\"  Validation Loss: {0:.3f}\".format(avg_val_loss))\n",
        "          print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "          model_bert.train()\n",
        "          model_log_reg.train()\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_attention_mask = batch[1].to(device)\n",
        "        b_poses = batch[2].to(device)\n",
        "        b_labels = batch[3].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        optimizer.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        last_layer = model_bert(b_input_ids, b_attention_mask)\n",
        "\n",
        "        # print(b_poses[:,0].size())\n",
        "        b_poses = b_poses.unsqueeze(-1).repeat(1, 1, 1024)\n",
        "        # print(b_poses.size())\n",
        "        gathered_activations = torch.gather(last_layer, 1, b_poses)\n",
        "\n",
        "        # concatted = torch.cat((last_layer[b_poses[:,0].view(16,1),:] , last_layer[:,b_poses[:,1],:]), dim = 1)\n",
        "\n",
        "        logits = model_log_reg(gathered_activations.view(gathered_activations.size()[0], -1))\n",
        "        # print(type(b_labels))\n",
        "        loss = loss_fn(logits, b_labels.type_as(logits))\n",
        "        # print(\"loss = \"+str(loss))\n",
        "        # print(logits.cpu().detach().numpy())\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        \n",
        "        # print(loss)\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        # TODO logsistic REG????/\n",
        "        torch.nn.utils.clip_grad_norm_(model_bert.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # # Update the learning rate.\n",
        "        # scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "    \n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model_bert.eval()\n",
        "    model_log_reg.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    t_labels = []\n",
        "    t_preds = []\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch_dev in dev_dataloader:\n",
        "\n",
        "        with torch.no_grad():\n",
        "            b_input_ids = batch_dev[0].to(device)\n",
        "            b_attention_mask = batch_dev[1].to(device)\n",
        "            b_poses = batch_dev[2].to(device)\n",
        "            b_labels = batch_dev[3].to(device)        \n",
        "\n",
        "            last_layer = model_bert(b_input_ids, b_attention_mask)\n",
        "            b_poses = b_poses.unsqueeze(-1).repeat(1, 1, 1024)\n",
        "            gathered_activations = torch.gather(last_layer, 1, b_poses)\n",
        "            logits = model_log_reg(gathered_activations.view(gathered_activations.size()[0], -1))\n",
        "            loss = loss_fn(logits, b_labels.type_as(logits))\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.cpu().detach().numpy()\n",
        "        # print(logits)\n",
        "        label_ids = b_labels.cpu().numpy()\n",
        "\n",
        "        t_labels.append(label_ids)\n",
        "        t_preds.append(logits)\n",
        "        \n",
        "\n",
        "    all_dev_labels = np.concatenate(t_labels, axis=0)\n",
        "    all_dev_logits = np.concatenate(t_preds, axis=0)\n",
        "    # Report the final accuracy for this validation run.\n",
        "    # print(all_dev_logits)\n",
        "    avg_val_accuracy = flat_accuracy_single_logit(all_dev_logits[:800], all_dev_labels[:800])\n",
        "    print(\"Validation Accuracy: {0:.4f}\".format(avg_val_accuracy))\n",
        "    en_dev_acc = flat_accuracy_single_logit(all_dev_logits[800:], all_dev_labels[800:])\n",
        "\n",
        "\n",
        "    # ar_dev_acc = flat_accuracy_single_logit(all_dev_logits[200:].reshape(2,200)[:,:50].ravel(), all_dev_labels[200:].reshape(2,200)[:,:50].ravel())\n",
        "    # zh_dev_acc = flat_accuracy_single_logit(all_dev_logits[200:].reshape(2,200)[:,50:100].ravel(), all_dev_labels[200:].reshape(2,200)[:,50:100].ravel())\n",
        "    # fr_dev_acc = flat_accuracy_single_logit(all_dev_logits[200:].reshape(2,200)[:,100:150].ravel(), all_dev_labels[200:].reshape(2,200)[:,100:150].ravel())\n",
        "    # ru_dev_acc = flat_accuracy_single_logit(all_dev_logits[200:].reshape(2,200)[:,150:200].ravel(), all_dev_labels[200:].reshape(2,200)[:,150:200].ravel())\n",
        "    ar_dev_acc = flat_accuracy_single_logit(all_dev_logits[:200], all_dev_labels[:200])\n",
        "    zh_dev_acc = flat_accuracy_single_logit(all_dev_logits[600:800], all_dev_labels[600:800])\n",
        "    fr_dev_acc = flat_accuracy_single_logit(all_dev_logits[200:400], all_dev_labels[200:400])\n",
        "    ru_dev_acc = flat_accuracy_single_logit(all_dev_logits[400:600], all_dev_labels[400:600])\n",
        "\n",
        "    print(\"AR dev Accuracy: {0:.4f} \".format(ar_dev_acc))\n",
        "    print(\"FR dev Accuracy: {0:.4f} \".format(fr_dev_acc))\n",
        "    print(\"RU dev Accuracy: {0:.4f} \".format(ru_dev_acc))\n",
        "    print(\"ZH dev Accuracy: {0:.4f} \".format(zh_dev_acc))\n",
        "    print(\"EN dev Accuracy: {0:.4f}\".format(en_dev_acc))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = cross_entropy(all_dev_logits[:800], all_dev_labels[:800])\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "\n",
        "    if(avg_val_accuracy > best_val_accuracy):\n",
        "      flag = True\n",
        "      best_val_accuracy = avg_val_accuracy\n",
        "      best_val_preds = all_dev_logits\n",
        "      torch.save(model_bert.state_dict(), os.path.join(path_mix, \"xlmr_check_best_dev\"))\n",
        "      torch.save(model_log_reg.state_dict(), os.path.join(path_mix, \"log_reg_check_best_dev\"))\n",
        "      np.save(os.path.join(path_mix, \"best_dev_preds\"), best_val_preds)\n",
        "\n",
        "    if(ar_dev_acc > best_val_accuracy_ar):\n",
        "      flag = True\n",
        "      best_val_accuracy_ar = ar_dev_acc\n",
        "      best_val_preds_ar = all_dev_logits\n",
        "      torch.save(model_bert.state_dict(), os.path.join(path_ar, \"xlmr_check_best_dev\"))\n",
        "      torch.save(model_log_reg.state_dict(), os.path.join(path_ar, \"log_reg_check_best_dev\"))\n",
        "      np.save(os.path.join(path_ar, \"best_dev_preds\"), best_val_preds_ar)\n",
        "\n",
        "    if(fr_dev_acc > best_val_accuracy_fr):\n",
        "      flag = True\n",
        "      best_val_accuracy_fr = fr_dev_acc\n",
        "      best_val_preds_fr = all_dev_logits\n",
        "      torch.save(model_bert.state_dict(), os.path.join(path_fr, \"xlmr_check_best_dev\"))\n",
        "      torch.save(model_log_reg.state_dict(), os.path.join(path_fr, \"log_reg_check_best_dev\"))\n",
        "      np.save(os.path.join(path_fr, \"best_dev_preds\"), best_val_preds_fr)\n",
        "\n",
        "    if(ru_dev_acc > best_val_accuracy_ru):\n",
        "      flag = True\n",
        "      best_val_accuracy_ru = ru_dev_acc\n",
        "      best_val_preds_ru = all_dev_logits\n",
        "      torch.save(model_bert.state_dict(), os.path.join(path_ru, \"xlmr_check_best_dev\"))\n",
        "      torch.save(model_log_reg.state_dict(), os.path.join(path_ru, \"log_reg_check_best_dev\"))\n",
        "      np.save(os.path.join(path_ru, \"best_dev_preds\"), best_val_preds_ru)\n",
        "\n",
        "    if(zh_dev_acc > best_val_accuracy_zh):\n",
        "      flag = True\n",
        "      best_val_accuracy_zh = zh_dev_acc\n",
        "      best_val_preds_zh = all_dev_logits\n",
        "      torch.save(model_bert.state_dict(), os.path.join(path_zh, \"xlmr_check_best_dev\"))\n",
        "      torch.save(model_log_reg.state_dict(), os.path.join(path_zh, \"log_reg_check_best_dev\"))\n",
        "      np.save(os.path.join(path_zh, \"best_dev_preds\"), best_val_preds_zh)\n",
        "\n",
        "    if(en_dev_acc > best_val_accuracy_en):\n",
        "      flag = True\n",
        "      best_val_accuracy_en = en_dev_acc\n",
        "      best_val_preds_en = all_dev_logits\n",
        "      torch.save(model_bert.state_dict(), os.path.join(path_en, \"xlmr_check_best_dev\"))\n",
        "      torch.save(model_log_reg.state_dict(), os.path.join(path_en, \"log_reg_check_best_dev\"))\n",
        "      np.save(os.path.join(path_en, \"best_dev_preds\"), best_val_preds_en)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.3f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "\n",
        "        # Do same on test data\n",
        "    # Tracking variables \n",
        "    # total_eval_accuracy = 0\n",
        "    # total_eval_loss = 0\n",
        "    # nb_eval_steps = 0\n",
        "\n",
        "    # t_labels = []\n",
        "    # t_preds = []\n",
        "\n",
        "    # # Evaluate data for one epoch\n",
        "    # for batch in test_dataloader:\n",
        "        \n",
        "    #     with torch.no_grad():\n",
        "    #         b_input_ids = batch[0].to(device)\n",
        "    #         b_attention_mask = batch[1].to(device)\n",
        "    #         b_poses = batch[2].to(device)\n",
        "    #         b_labels = batch[3].to(device)        \n",
        "\n",
        "    #         last_layer = model_bert(b_input_ids, b_attention_mask)\n",
        "    #         b_poses = b_poses.unsqueeze(-1).repeat(1, 1, 1024)\n",
        "    #         gathered_activations = torch.gather(last_layer, 1, b_poses)\n",
        "    #         logits = model_log_reg(gathered_activations.view(gathered_activations.size()[0], -1))\n",
        "    #         loss = loss_fn(logits, b_labels.type_as(logits))\n",
        "            \n",
        "    #     # Accumulate the validation loss.\n",
        "    #     total_eval_loss += loss.item()\n",
        "\n",
        "    #     # Move logits and labels to CPU\n",
        "    #     logits = logits.cpu().detach().numpy()\n",
        "    #     label_ids = b_labels.cpu().numpy()\n",
        "\n",
        "    #     t_labels.append(label_ids)\n",
        "    #     t_preds.append(logits)\n",
        "        \n",
        "\n",
        "    # all_dev_labels = np.concatenate(t_labels, axis=0)\n",
        "    # all_dev_logits = np.concatenate(t_preds, axis=0)\n",
        "    # # Report the final accuracy for this validation run.\n",
        "    # avg_val_accuracy = flat_accuracy_single_logit(all_dev_logits[800:], all_dev_labels[800:])\n",
        "    # print(\"Test Accuracy: {0:.4f}\".format(avg_val_accuracy))\n",
        "    # en_test_acc = flat_accuracy_single_logit(all_dev_logits[:800], all_dev_labels[:800])\n",
        "    # actual_val = (actual_val + 80*en_test_acc)/100\n",
        "    # print(\"Actual En Val Accuracy: {0:.4f}\".format(actual_val))\n",
        "    # ru_test_acc = flat_accuracy_single_logit(all_dev_logits[800:1000], all_dev_labels[800:1000])\n",
        "    # zh_test_acc = flat_accuracy_single_logit(all_dev_logits[1000:1200], all_dev_labels[1000:1200])\n",
        "    # ar_test_acc = flat_accuracy_single_logit(all_dev_logits[1200:1400], all_dev_labels[1200:1400])\n",
        "    # fr_test_acc = flat_accuracy_single_logit(all_dev_logits[1400:1600], all_dev_labels[1400:1600])\n",
        "    # print(\"EN Test Accuracy: {0:.4f}\".format(en_test_acc))\n",
        "    # print(\"RU Test Accuracy: {0:.4f}\".format(ru_test_acc))\n",
        "    # print(\"ZH Test Accuracy: {0:.4f}\".format(zh_test_acc))\n",
        "    # print(\"AR Test Accuracy: {0:.4f}\".format(ar_test_acc))\n",
        "    # print(\"FR Test Accuracy: {0:.4f}\".format(fr_test_acc))\n",
        "\n",
        "    # if flag == True:\n",
        "    #   np.save(os.path.join(path_mix, \"test_preds_at_best_val\"), all_dev_logits)\n",
        "    #   flag = False\n",
        "\n",
        "    # # if(actual_val > t_best_val_accuracy):\n",
        "    # #   t_best_val_accuracy = actual_val\n",
        "    # #   t_best_val_preds = all_dev_logits\n",
        "    # #   torch.save(model_bert.state_dict(), os.path.join(path_this, \"xlmr_check_best_test\"))\n",
        "    # #   torch.save(model_log_reg.state_dict(), os.path.join(path_this, \"log_reg_check_best_test\"))\n",
        "    # #   np.save(os.path.join(path_this, \"best_test_preds\"), t_best_val_preds)\n",
        "\n",
        "    # # Calculate the average loss over all of the batches.\n",
        "    # avg_val_loss = total_eval_loss / len(test_dataloader)\n",
        "    \n",
        "    # # Measure how long the validation run took.\n",
        "    # validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    # print(\"  Test Avg Loss: {0:.3f}\".format(avg_val_loss))\n",
        "    # print(\"  Testing Validation took: {:}\".format(validation_time))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 15 ========\n",
            "Training...\n",
            "  Batch   100  of  2,432.    Elapsed: 0:00:44.\n",
            "  Batch   200  of  2,432.    Elapsed: 0:01:27.\n",
            "  Batch   300  of  2,432.    Elapsed: 0:02:11.\n",
            "  Batch   400  of  2,432.    Elapsed: 0:02:54.\n",
            "  Batch   500  of  2,432.    Elapsed: 0:03:38.\n",
            "  Batch   600  of  2,432.    Elapsed: 0:04:22.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8013\n",
            "AR dev Accuracy: 0.7650 \n",
            "FR dev Accuracy: 0.8600 \n",
            "RU dev Accuracy: 0.8300 \n",
            "ZH dev Accuracy: 0.7500 \n",
            "EN dev Accuracy: 0.7790\n",
            "  Validation Loss: 0.478\n",
            "  Validation took: 0:00:18\n",
            "  Batch   700  of  2,432.    Elapsed: 0:04:05.\n",
            "  Batch   800  of  2,432.    Elapsed: 0:04:49.\n",
            "  Batch   900  of  2,432.    Elapsed: 0:05:32.\n",
            "  Batch 1,000  of  2,432.    Elapsed: 0:06:16.\n",
            "  Batch 1,100  of  2,432.    Elapsed: 0:07:00.\n",
            "  Batch 1,200  of  2,432.    Elapsed: 0:07:43.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.7950\n",
            "AR dev Accuracy: 0.8050 \n",
            "FR dev Accuracy: 0.8500 \n",
            "RU dev Accuracy: 0.8300 \n",
            "ZH dev Accuracy: 0.6950 \n",
            "EN dev Accuracy: 0.8550\n",
            "  Validation Loss: 0.447\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,300  of  2,432.    Elapsed: 0:01:40.\n",
            "  Batch 1,400  of  2,432.    Elapsed: 0:02:25.\n",
            "  Batch 1,500  of  2,432.    Elapsed: 0:03:08.\n",
            "  Batch 1,600  of  2,432.    Elapsed: 0:03:52.\n",
            "  Batch 1,700  of  2,432.    Elapsed: 0:04:36.\n",
            "  Batch 1,800  of  2,432.    Elapsed: 0:05:19.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.7875\n",
            "AR dev Accuracy: 0.7400 \n",
            "FR dev Accuracy: 0.8600 \n",
            "RU dev Accuracy: 0.8450 \n",
            "ZH dev Accuracy: 0.7050 \n",
            "EN dev Accuracy: 0.7980\n",
            "  Validation Loss: 0.472\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,900  of  2,432.    Elapsed: 0:01:08.\n",
            "  Batch 2,000  of  2,432.    Elapsed: 0:01:52.\n",
            "  Batch 2,100  of  2,432.    Elapsed: 0:02:36.\n",
            "  Batch 2,200  of  2,432.    Elapsed: 0:03:19.\n",
            "  Batch 2,300  of  2,432.    Elapsed: 0:04:03.\n",
            "  Batch 2,400  of  2,432.    Elapsed: 0:04:46.\n",
            "\n",
            "  Average training loss: 0.52\n",
            "  Training epcoh took: 0:05:00\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8187\n",
            "AR dev Accuracy: 0.8300 \n",
            "FR dev Accuracy: 0.8300 \n",
            "RU dev Accuracy: 0.8700 \n",
            "ZH dev Accuracy: 0.7450 \n",
            "EN dev Accuracy: 0.8610\n",
            "  Validation Loss: 0.405\n",
            "  Validation took: 0:00:18\n",
            "\n",
            "======== Epoch 2 / 15 ========\n",
            "Training...\n",
            "  Batch   100  of  2,432.    Elapsed: 0:00:45.\n",
            "  Batch   200  of  2,432.    Elapsed: 0:01:30.\n",
            "  Batch   300  of  2,432.    Elapsed: 0:02:15.\n",
            "  Batch   400  of  2,432.    Elapsed: 0:02:59.\n",
            "  Batch   500  of  2,432.    Elapsed: 0:03:42.\n",
            "  Batch   600  of  2,432.    Elapsed: 0:04:25.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8325\n",
            "AR dev Accuracy: 0.8550 \n",
            "FR dev Accuracy: 0.8200 \n",
            "RU dev Accuracy: 0.8650 \n",
            "ZH dev Accuracy: 0.7900 \n",
            "EN dev Accuracy: 0.8660\n",
            "  Validation Loss: 0.526\n",
            "  Validation took: 0:00:18\n",
            "  Batch   700  of  2,432.    Elapsed: 0:02:38.\n",
            "  Batch   800  of  2,432.    Elapsed: 0:03:22.\n",
            "  Batch   900  of  2,432.    Elapsed: 0:04:07.\n",
            "  Batch 1,000  of  2,432.    Elapsed: 0:04:51.\n",
            "  Batch 1,100  of  2,432.    Elapsed: 0:05:35.\n",
            "  Batch 1,200  of  2,432.    Elapsed: 0:06:18.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8325\n",
            "AR dev Accuracy: 0.8200 \n",
            "FR dev Accuracy: 0.8450 \n",
            "RU dev Accuracy: 0.8600 \n",
            "ZH dev Accuracy: 0.8050 \n",
            "EN dev Accuracy: 0.8630\n",
            "  Validation Loss: 0.768\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,300  of  2,432.    Elapsed: 0:01:09.\n",
            "  Batch 1,400  of  2,432.    Elapsed: 0:01:53.\n",
            "  Batch 1,500  of  2,432.    Elapsed: 0:02:36.\n",
            "  Batch 1,600  of  2,432.    Elapsed: 0:03:20.\n",
            "  Batch 1,700  of  2,432.    Elapsed: 0:04:03.\n",
            "  Batch 1,800  of  2,432.    Elapsed: 0:04:46.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8275\n",
            "AR dev Accuracy: 0.8150 \n",
            "FR dev Accuracy: 0.8250 \n",
            "RU dev Accuracy: 0.9100 \n",
            "ZH dev Accuracy: 0.7600 \n",
            "EN dev Accuracy: 0.8650\n",
            "  Validation Loss: 0.666\n",
            "  Validation took: 0:00:18\n",
            "  Batch 1,900  of  2,432.    Elapsed: 0:01:06.\n",
            "  Batch 2,000  of  2,432.    Elapsed: 0:01:50.\n",
            "  Batch 2,100  of  2,432.    Elapsed: 0:02:34.\n",
            "  Batch 2,200  of  2,432.    Elapsed: 0:03:17.\n",
            "  Batch 2,300  of  2,432.    Elapsed: 0:04:00.\n",
            "  Batch 2,400  of  2,432.    Elapsed: 0:04:44.\n",
            "\n",
            "  Average training loss: 0.36\n",
            "  Training epcoh took: 0:04:57\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8400\n",
            "AR dev Accuracy: 0.8200 \n",
            "FR dev Accuracy: 0.8500 \n",
            "RU dev Accuracy: 0.8800 \n",
            "ZH dev Accuracy: 0.8100 \n",
            "EN dev Accuracy: 0.8780\n",
            "  Validation Loss: 0.630\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "======== Epoch 3 / 15 ========\n",
            "Training...\n",
            "  Batch   100  of  2,432.    Elapsed: 0:00:44.\n",
            "  Batch   200  of  2,432.    Elapsed: 0:01:29.\n",
            "  Batch   300  of  2,432.    Elapsed: 0:02:13.\n",
            "  Batch   400  of  2,432.    Elapsed: 0:02:56.\n",
            "  Batch   500  of  2,432.    Elapsed: 0:03:39.\n",
            "  Batch   600  of  2,432.    Elapsed: 0:04:22.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8475\n",
            "AR dev Accuracy: 0.8300 \n",
            "FR dev Accuracy: 0.8850 \n",
            "RU dev Accuracy: 0.8750 \n",
            "ZH dev Accuracy: 0.8000 \n",
            "EN dev Accuracy: 0.8850\n",
            "  Validation Loss: 0.768\n",
            "  Validation took: 0:00:19\n",
            "  Batch   700  of  2,432.    Elapsed: 0:02:10.\n",
            "  Batch   800  of  2,432.    Elapsed: 0:02:55.\n",
            "  Batch   900  of  2,432.    Elapsed: 0:03:39.\n",
            "  Batch 1,000  of  2,432.    Elapsed: 0:04:22.\n",
            "  Batch 1,100  of  2,432.    Elapsed: 0:05:05.\n",
            "  Batch 1,200  of  2,432.    Elapsed: 0:05:49.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8550\n",
            "AR dev Accuracy: 0.8350 \n",
            "FR dev Accuracy: 0.8700 \n",
            "RU dev Accuracy: 0.9100 \n",
            "ZH dev Accuracy: 0.8050 \n",
            "EN dev Accuracy: 0.8890\n",
            "  Validation Loss: 0.710\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,300  of  2,432.    Elapsed: 0:01:38.\n",
            "  Batch 1,400  of  2,432.    Elapsed: 0:02:23.\n",
            "  Batch 1,500  of  2,432.    Elapsed: 0:03:06.\n",
            "  Batch 1,600  of  2,432.    Elapsed: 0:03:50.\n",
            "  Batch 1,700  of  2,432.    Elapsed: 0:04:33.\n",
            "  Batch 1,800  of  2,432.    Elapsed: 0:05:17.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8337\n",
            "AR dev Accuracy: 0.8400 \n",
            "FR dev Accuracy: 0.8550 \n",
            "RU dev Accuracy: 0.8800 \n",
            "ZH dev Accuracy: 0.7600 \n",
            "EN dev Accuracy: 0.8760\n",
            "  Validation Loss: 0.944\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,900  of  2,432.    Elapsed: 0:00:51.\n",
            "  Batch 2,000  of  2,432.    Elapsed: 0:01:35.\n",
            "  Batch 2,100  of  2,432.    Elapsed: 0:02:18.\n",
            "  Batch 2,200  of  2,432.    Elapsed: 0:03:01.\n",
            "  Batch 2,300  of  2,432.    Elapsed: 0:03:44.\n",
            "  Batch 2,400  of  2,432.    Elapsed: 0:04:28.\n",
            "\n",
            "  Average training loss: 0.28\n",
            "  Training epcoh took: 0:04:41\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8237\n",
            "AR dev Accuracy: 0.8100 \n",
            "FR dev Accuracy: 0.8350 \n",
            "RU dev Accuracy: 0.8950 \n",
            "ZH dev Accuracy: 0.7550 \n",
            "EN dev Accuracy: 0.8560\n",
            "  Validation Loss: 0.761\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "======== Epoch 4 / 15 ========\n",
            "Training...\n",
            "  Batch   100  of  2,432.    Elapsed: 0:00:43.\n",
            "  Batch   200  of  2,432.    Elapsed: 0:01:26.\n",
            "  Batch   300  of  2,432.    Elapsed: 0:02:09.\n",
            "  Batch   400  of  2,432.    Elapsed: 0:02:52.\n",
            "  Batch   500  of  2,432.    Elapsed: 0:03:36.\n",
            "  Batch   600  of  2,432.    Elapsed: 0:04:19.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8237\n",
            "AR dev Accuracy: 0.8200 \n",
            "FR dev Accuracy: 0.8300 \n",
            "RU dev Accuracy: 0.8900 \n",
            "ZH dev Accuracy: 0.7550 \n",
            "EN dev Accuracy: 0.8780\n",
            "  Validation Loss: 0.921\n",
            "  Validation took: 0:00:19\n",
            "  Batch   700  of  2,432.    Elapsed: 0:00:58.\n",
            "  Batch   800  of  2,432.    Elapsed: 0:01:42.\n",
            "  Batch   900  of  2,432.    Elapsed: 0:02:25.\n",
            "  Batch 1,000  of  2,432.    Elapsed: 0:03:08.\n",
            "  Batch 1,100  of  2,432.    Elapsed: 0:03:51.\n",
            "  Batch 1,200  of  2,432.    Elapsed: 0:04:34.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8438\n",
            "AR dev Accuracy: 0.8300 \n",
            "FR dev Accuracy: 0.8800 \n",
            "RU dev Accuracy: 0.8900 \n",
            "ZH dev Accuracy: 0.7750 \n",
            "EN dev Accuracy: 0.8780\n",
            "  Validation Loss: 0.769\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,300  of  2,432.    Elapsed: 0:00:55.\n",
            "  Batch 1,400  of  2,432.    Elapsed: 0:01:38.\n",
            "  Batch 1,500  of  2,432.    Elapsed: 0:02:21.\n",
            "  Batch 1,600  of  2,432.    Elapsed: 0:03:04.\n",
            "  Batch 1,700  of  2,432.    Elapsed: 0:03:47.\n",
            "  Batch 1,800  of  2,432.    Elapsed: 0:04:30.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8387\n",
            "AR dev Accuracy: 0.8450 \n",
            "FR dev Accuracy: 0.8500 \n",
            "RU dev Accuracy: 0.8850 \n",
            "ZH dev Accuracy: 0.7750 \n",
            "EN dev Accuracy: 0.8790\n",
            "  Validation Loss: 0.668\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,900  of  2,432.    Elapsed: 0:00:51.\n",
            "  Batch 2,000  of  2,432.    Elapsed: 0:01:34.\n",
            "  Batch 2,100  of  2,432.    Elapsed: 0:02:17.\n",
            "  Batch 2,200  of  2,432.    Elapsed: 0:03:01.\n",
            "  Batch 2,300  of  2,432.    Elapsed: 0:03:44.\n",
            "  Batch 2,400  of  2,432.    Elapsed: 0:04:27.\n",
            "\n",
            "  Average training loss: 0.18\n",
            "  Training epcoh took: 0:04:40\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8325\n",
            "AR dev Accuracy: 0.8300 \n",
            "FR dev Accuracy: 0.8600 \n",
            "RU dev Accuracy: 0.8600 \n",
            "ZH dev Accuracy: 0.7800 \n",
            "EN dev Accuracy: 0.8670\n",
            "  Validation Loss: 0.629\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "======== Epoch 5 / 15 ========\n",
            "Training...\n",
            "  Batch   100  of  2,432.    Elapsed: 0:00:43.\n",
            "  Batch   200  of  2,432.    Elapsed: 0:01:26.\n",
            "  Batch   300  of  2,432.    Elapsed: 0:02:09.\n",
            "  Batch   400  of  2,432.    Elapsed: 0:02:52.\n",
            "  Batch   500  of  2,432.    Elapsed: 0:03:35.\n",
            "  Batch   600  of  2,432.    Elapsed: 0:04:18.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8462\n",
            "AR dev Accuracy: 0.8350 \n",
            "FR dev Accuracy: 0.8750 \n",
            "RU dev Accuracy: 0.8750 \n",
            "ZH dev Accuracy: 0.8000 \n",
            "EN dev Accuracy: 0.8810\n",
            "  Validation Loss: 0.591\n",
            "  Validation took: 0:00:19\n",
            "  Batch   700  of  2,432.    Elapsed: 0:00:58.\n",
            "  Batch   800  of  2,432.    Elapsed: 0:01:41.\n",
            "  Batch   900  of  2,432.    Elapsed: 0:02:24.\n",
            "  Batch 1,000  of  2,432.    Elapsed: 0:03:07.\n",
            "  Batch 1,100  of  2,432.    Elapsed: 0:03:50.\n",
            "  Batch 1,200  of  2,432.    Elapsed: 0:04:33.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8413\n",
            "AR dev Accuracy: 0.8250 \n",
            "FR dev Accuracy: 0.8700 \n",
            "RU dev Accuracy: 0.8900 \n",
            "ZH dev Accuracy: 0.7800 \n",
            "EN dev Accuracy: 0.8710\n",
            "  Validation Loss: 0.617\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,300  of  2,432.    Elapsed: 0:00:55.\n",
            "  Batch 1,400  of  2,432.    Elapsed: 0:01:38.\n",
            "  Batch 1,500  of  2,432.    Elapsed: 0:02:20.\n",
            "  Batch 1,600  of  2,432.    Elapsed: 0:03:04.\n",
            "  Batch 1,700  of  2,432.    Elapsed: 0:03:46.\n",
            "  Batch 1,800  of  2,432.    Elapsed: 0:04:29.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8662\n",
            "AR dev Accuracy: 0.8700 \n",
            "FR dev Accuracy: 0.9100 \n",
            "RU dev Accuracy: 0.8850 \n",
            "ZH dev Accuracy: 0.8000 \n",
            "EN dev Accuracy: 0.8800\n",
            "  Validation Loss: 0.478\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,900  of  2,432.    Elapsed: 0:02:03.\n",
            "  Batch 2,000  of  2,432.    Elapsed: 0:02:48.\n",
            "  Batch 2,100  of  2,432.    Elapsed: 0:03:31.\n",
            "  Batch 2,200  of  2,432.    Elapsed: 0:04:14.\n",
            "  Batch 2,300  of  2,432.    Elapsed: 0:04:57.\n",
            "  Batch 2,400  of  2,432.    Elapsed: 0:05:40.\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Training epcoh took: 0:05:54\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8462\n",
            "AR dev Accuracy: 0.8050 \n",
            "FR dev Accuracy: 0.8550 \n",
            "RU dev Accuracy: 0.9050 \n",
            "ZH dev Accuracy: 0.8200 \n",
            "EN dev Accuracy: 0.8800\n",
            "  Validation Loss: 0.573\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "======== Epoch 6 / 15 ========\n",
            "Training...\n",
            "  Batch   100  of  2,432.    Elapsed: 0:00:44.\n",
            "  Batch   200  of  2,432.    Elapsed: 0:01:27.\n",
            "  Batch   300  of  2,432.    Elapsed: 0:02:10.\n",
            "  Batch   400  of  2,432.    Elapsed: 0:02:53.\n",
            "  Batch   500  of  2,432.    Elapsed: 0:03:36.\n",
            "  Batch   600  of  2,432.    Elapsed: 0:04:19.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8400\n",
            "AR dev Accuracy: 0.8200 \n",
            "FR dev Accuracy: 0.8600 \n",
            "RU dev Accuracy: 0.9250 \n",
            "ZH dev Accuracy: 0.7550 \n",
            "EN dev Accuracy: 0.8760\n",
            "  Validation Loss: 0.591\n",
            "  Validation took: 0:00:19\n",
            "  Batch   700  of  2,432.    Elapsed: 0:01:14.\n",
            "  Batch   800  of  2,432.    Elapsed: 0:01:57.\n",
            "  Batch   900  of  2,432.    Elapsed: 0:02:40.\n",
            "  Batch 1,000  of  2,432.    Elapsed: 0:03:23.\n",
            "  Batch 1,100  of  2,432.    Elapsed: 0:04:06.\n",
            "  Batch 1,200  of  2,432.    Elapsed: 0:04:49.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8425\n",
            "AR dev Accuracy: 0.8250 \n",
            "FR dev Accuracy: 0.8400 \n",
            "RU dev Accuracy: 0.9150 \n",
            "ZH dev Accuracy: 0.7900 \n",
            "EN dev Accuracy: 0.8700\n",
            "  Validation Loss: 0.649\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,300  of  2,432.    Elapsed: 0:00:55.\n",
            "  Batch 1,400  of  2,432.    Elapsed: 0:01:38.\n",
            "  Batch 1,500  of  2,432.    Elapsed: 0:02:21.\n",
            "  Batch 1,600  of  2,432.    Elapsed: 0:03:04.\n",
            "  Batch 1,700  of  2,432.    Elapsed: 0:03:47.\n",
            "  Batch 1,800  of  2,432.    Elapsed: 0:04:30.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8475\n",
            "AR dev Accuracy: 0.8600 \n",
            "FR dev Accuracy: 0.8850 \n",
            "RU dev Accuracy: 0.8850 \n",
            "ZH dev Accuracy: 0.7600 \n",
            "EN dev Accuracy: 0.8850\n",
            "  Validation Loss: 0.578\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,900  of  2,432.    Elapsed: 0:00:51.\n",
            "  Batch 2,000  of  2,432.    Elapsed: 0:01:34.\n",
            "  Batch 2,100  of  2,432.    Elapsed: 0:02:17.\n",
            "  Batch 2,200  of  2,432.    Elapsed: 0:03:00.\n",
            "  Batch 2,300  of  2,432.    Elapsed: 0:03:43.\n",
            "  Batch 2,400  of  2,432.    Elapsed: 0:04:26.\n",
            "\n",
            "  Average training loss: 0.11\n",
            "  Training epcoh took: 0:04:40\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8250\n",
            "AR dev Accuracy: 0.8100 \n",
            "FR dev Accuracy: 0.8650 \n",
            "RU dev Accuracy: 0.9000 \n",
            "ZH dev Accuracy: 0.7250 \n",
            "EN dev Accuracy: 0.8670\n",
            "  Validation Loss: 0.676\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "======== Epoch 7 / 15 ========\n",
            "Training...\n",
            "  Batch   100  of  2,432.    Elapsed: 0:00:43.\n",
            "  Batch   200  of  2,432.    Elapsed: 0:01:26.\n",
            "  Batch   300  of  2,432.    Elapsed: 0:02:09.\n",
            "  Batch   400  of  2,432.    Elapsed: 0:02:52.\n",
            "  Batch   500  of  2,432.    Elapsed: 0:03:35.\n",
            "  Batch   600  of  2,432.    Elapsed: 0:04:18.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8313\n",
            "AR dev Accuracy: 0.8200 \n",
            "FR dev Accuracy: 0.8750 \n",
            "RU dev Accuracy: 0.8900 \n",
            "ZH dev Accuracy: 0.7400 \n",
            "EN dev Accuracy: 0.8640\n",
            "  Validation Loss: 0.697\n",
            "  Validation took: 0:00:19\n",
            "  Batch   700  of  2,432.    Elapsed: 0:00:58.\n",
            "  Batch   800  of  2,432.    Elapsed: 0:01:41.\n",
            "  Batch   900  of  2,432.    Elapsed: 0:02:24.\n",
            "  Batch 1,000  of  2,432.    Elapsed: 0:03:07.\n",
            "  Batch 1,100  of  2,432.    Elapsed: 0:03:50.\n",
            "  Batch 1,200  of  2,432.    Elapsed: 0:04:33.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8350\n",
            "AR dev Accuracy: 0.8000 \n",
            "FR dev Accuracy: 0.8400 \n",
            "RU dev Accuracy: 0.9150 \n",
            "ZH dev Accuracy: 0.7850 \n",
            "EN dev Accuracy: 0.8620\n",
            "  Validation Loss: 0.672\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,300  of  2,432.    Elapsed: 0:00:55.\n",
            "  Batch 1,400  of  2,432.    Elapsed: 0:01:38.\n",
            "  Batch 1,500  of  2,432.    Elapsed: 0:02:21.\n",
            "  Batch 1,600  of  2,432.    Elapsed: 0:03:04.\n",
            "  Batch 1,700  of  2,432.    Elapsed: 0:03:47.\n",
            "  Batch 1,800  of  2,432.    Elapsed: 0:04:30.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8500\n",
            "AR dev Accuracy: 0.8400 \n",
            "FR dev Accuracy: 0.8600 \n",
            "RU dev Accuracy: 0.9150 \n",
            "ZH dev Accuracy: 0.7850 \n",
            "EN dev Accuracy: 0.8710\n",
            "  Validation Loss: 0.586\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,900  of  2,432.    Elapsed: 0:00:51.\n",
            "  Batch 2,000  of  2,432.    Elapsed: 0:01:34.\n",
            "  Batch 2,100  of  2,432.    Elapsed: 0:02:17.\n",
            "  Batch 2,200  of  2,432.    Elapsed: 0:03:00.\n",
            "  Batch 2,300  of  2,432.    Elapsed: 0:03:43.\n",
            "  Batch 2,400  of  2,432.    Elapsed: 0:04:26.\n",
            "\n",
            "  Average training loss: 0.10\n",
            "  Training epcoh took: 0:04:40\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8300\n",
            "AR dev Accuracy: 0.8050 \n",
            "FR dev Accuracy: 0.8350 \n",
            "RU dev Accuracy: 0.8950 \n",
            "ZH dev Accuracy: 0.7850 \n",
            "EN dev Accuracy: 0.8780\n",
            "  Validation Loss: 0.654\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "======== Epoch 8 / 15 ========\n",
            "Training...\n",
            "  Batch   100  of  2,432.    Elapsed: 0:00:43.\n",
            "  Batch   200  of  2,432.    Elapsed: 0:01:26.\n",
            "  Batch   300  of  2,432.    Elapsed: 0:02:09.\n",
            "  Batch   400  of  2,432.    Elapsed: 0:02:52.\n",
            "  Batch   500  of  2,432.    Elapsed: 0:03:35.\n",
            "  Batch   600  of  2,432.    Elapsed: 0:04:17.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8400\n",
            "AR dev Accuracy: 0.8400 \n",
            "FR dev Accuracy: 0.8600 \n",
            "RU dev Accuracy: 0.8750 \n",
            "ZH dev Accuracy: 0.7850 \n",
            "EN dev Accuracy: 0.8730\n",
            "  Validation Loss: 0.668\n",
            "  Validation took: 0:00:19\n",
            "  Batch   700  of  2,432.    Elapsed: 0:00:58.\n",
            "  Batch   800  of  2,432.    Elapsed: 0:01:41.\n",
            "  Batch   900  of  2,432.    Elapsed: 0:02:24.\n",
            "  Batch 1,000  of  2,432.    Elapsed: 0:03:07.\n",
            "  Batch 1,100  of  2,432.    Elapsed: 0:03:50.\n",
            "  Batch 1,200  of  2,432.    Elapsed: 0:04:33.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8550\n",
            "AR dev Accuracy: 0.8400 \n",
            "FR dev Accuracy: 0.8650 \n",
            "RU dev Accuracy: 0.9100 \n",
            "ZH dev Accuracy: 0.8050 \n",
            "EN dev Accuracy: 0.8590\n",
            "  Validation Loss: 0.659\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,300  of  2,432.    Elapsed: 0:00:55.\n",
            "  Batch 1,400  of  2,432.    Elapsed: 0:01:38.\n",
            "  Batch 1,500  of  2,432.    Elapsed: 0:02:20.\n",
            "  Batch 1,600  of  2,432.    Elapsed: 0:03:03.\n",
            "  Batch 1,700  of  2,432.    Elapsed: 0:03:46.\n",
            "  Batch 1,800  of  2,432.    Elapsed: 0:04:29.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8700\n",
            "AR dev Accuracy: 0.8550 \n",
            "FR dev Accuracy: 0.8850 \n",
            "RU dev Accuracy: 0.9200 \n",
            "ZH dev Accuracy: 0.8200 \n",
            "EN dev Accuracy: 0.8620\n",
            "  Validation Loss: 0.520\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,900  of  2,432.    Elapsed: 0:01:06.\n",
            "  Batch 2,000  of  2,432.    Elapsed: 0:01:49.\n",
            "  Batch 2,100  of  2,432.    Elapsed: 0:02:32.\n",
            "  Batch 2,200  of  2,432.    Elapsed: 0:03:15.\n",
            "  Batch 2,300  of  2,432.    Elapsed: 0:03:58.\n",
            "  Batch 2,400  of  2,432.    Elapsed: 0:04:41.\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Training epcoh took: 0:04:55\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8400\n",
            "AR dev Accuracy: 0.8750 \n",
            "FR dev Accuracy: 0.8400 \n",
            "RU dev Accuracy: 0.8900 \n",
            "ZH dev Accuracy: 0.7550 \n",
            "EN dev Accuracy: 0.8390\n",
            "  Validation Loss: 0.679\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "======== Epoch 9 / 15 ========\n",
            "Training...\n",
            "  Batch   100  of  2,432.    Elapsed: 0:00:44.\n",
            "  Batch   200  of  2,432.    Elapsed: 0:01:28.\n",
            "  Batch   300  of  2,432.    Elapsed: 0:02:10.\n",
            "  Batch   400  of  2,432.    Elapsed: 0:02:53.\n",
            "  Batch   500  of  2,432.    Elapsed: 0:03:36.\n",
            "  Batch   600  of  2,432.    Elapsed: 0:04:19.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8475\n",
            "AR dev Accuracy: 0.8550 \n",
            "FR dev Accuracy: 0.8800 \n",
            "RU dev Accuracy: 0.8950 \n",
            "ZH dev Accuracy: 0.7600 \n",
            "EN dev Accuracy: 0.8660\n",
            "  Validation Loss: 0.736\n",
            "  Validation took: 0:00:19\n",
            "  Batch   700  of  2,432.    Elapsed: 0:00:58.\n",
            "  Batch   800  of  2,432.    Elapsed: 0:01:41.\n",
            "  Batch   900  of  2,432.    Elapsed: 0:02:24.\n",
            "  Batch 1,000  of  2,432.    Elapsed: 0:03:07.\n",
            "  Batch 1,100  of  2,432.    Elapsed: 0:03:50.\n",
            "  Batch 1,200  of  2,432.    Elapsed: 0:04:33.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8475\n",
            "AR dev Accuracy: 0.8600 \n",
            "FR dev Accuracy: 0.8850 \n",
            "RU dev Accuracy: 0.8750 \n",
            "ZH dev Accuracy: 0.7700 \n",
            "EN dev Accuracy: 0.8590\n",
            "  Validation Loss: 0.700\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,300  of  2,432.    Elapsed: 0:00:55.\n",
            "  Batch 1,400  of  2,432.    Elapsed: 0:01:38.\n",
            "  Batch 1,500  of  2,432.    Elapsed: 0:02:21.\n",
            "  Batch 1,600  of  2,432.    Elapsed: 0:03:04.\n",
            "  Batch 1,700  of  2,432.    Elapsed: 0:03:47.\n",
            "  Batch 1,800  of  2,432.    Elapsed: 0:04:30.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8413\n",
            "AR dev Accuracy: 0.8350 \n",
            "FR dev Accuracy: 0.8750 \n",
            "RU dev Accuracy: 0.8800 \n",
            "ZH dev Accuracy: 0.7750 \n",
            "EN dev Accuracy: 0.8680\n",
            "  Validation Loss: 0.714\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,900  of  2,432.    Elapsed: 0:00:51.\n",
            "  Batch 2,000  of  2,432.    Elapsed: 0:01:34.\n",
            "  Batch 2,100  of  2,432.    Elapsed: 0:02:17.\n",
            "  Batch 2,200  of  2,432.    Elapsed: 0:03:00.\n",
            "  Batch 2,300  of  2,432.    Elapsed: 0:03:43.\n",
            "  Batch 2,400  of  2,432.    Elapsed: 0:04:26.\n",
            "\n",
            "  Average training loss: 0.08\n",
            "  Training epcoh took: 0:04:40\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8462\n",
            "AR dev Accuracy: 0.8150 \n",
            "FR dev Accuracy: 0.8750 \n",
            "RU dev Accuracy: 0.9000 \n",
            "ZH dev Accuracy: 0.7950 \n",
            "EN dev Accuracy: 0.8700\n",
            "  Validation Loss: 0.616\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "======== Epoch 10 / 15 ========\n",
            "Training...\n",
            "  Batch   100  of  2,432.    Elapsed: 0:00:43.\n",
            "  Batch   200  of  2,432.    Elapsed: 0:01:26.\n",
            "  Batch   300  of  2,432.    Elapsed: 0:02:09.\n",
            "  Batch   400  of  2,432.    Elapsed: 0:02:52.\n",
            "  Batch   500  of  2,432.    Elapsed: 0:03:35.\n",
            "  Batch   600  of  2,432.    Elapsed: 0:04:18.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8438\n",
            "AR dev Accuracy: 0.8300 \n",
            "FR dev Accuracy: 0.8750 \n",
            "RU dev Accuracy: 0.8800 \n",
            "ZH dev Accuracy: 0.7900 \n",
            "EN dev Accuracy: 0.8570\n",
            "  Validation Loss: 0.698\n",
            "  Validation took: 0:00:19\n",
            "  Batch   700  of  2,432.    Elapsed: 0:00:58.\n",
            "  Batch   800  of  2,432.    Elapsed: 0:01:41.\n",
            "  Batch   900  of  2,432.    Elapsed: 0:02:24.\n",
            "  Batch 1,000  of  2,432.    Elapsed: 0:03:07.\n",
            "  Batch 1,100  of  2,432.    Elapsed: 0:03:50.\n",
            "  Batch 1,200  of  2,432.    Elapsed: 0:04:33.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8325\n",
            "AR dev Accuracy: 0.8250 \n",
            "FR dev Accuracy: 0.8350 \n",
            "RU dev Accuracy: 0.8900 \n",
            "ZH dev Accuracy: 0.7800 \n",
            "EN dev Accuracy: 0.8640\n",
            "  Validation Loss: 0.808\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,300  of  2,432.    Elapsed: 0:00:55.\n",
            "  Batch 1,400  of  2,432.    Elapsed: 0:01:38.\n",
            "  Batch 1,500  of  2,432.    Elapsed: 0:02:21.\n",
            "  Batch 1,600  of  2,432.    Elapsed: 0:03:03.\n",
            "  Batch 1,700  of  2,432.    Elapsed: 0:03:46.\n",
            "  Batch 1,800  of  2,432.    Elapsed: 0:04:29.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8475\n",
            "AR dev Accuracy: 0.8200 \n",
            "FR dev Accuracy: 0.8700 \n",
            "RU dev Accuracy: 0.8850 \n",
            "ZH dev Accuracy: 0.8150 \n",
            "EN dev Accuracy: 0.8710\n",
            "  Validation Loss: 0.659\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,900  of  2,432.    Elapsed: 0:00:51.\n",
            "  Batch 2,000  of  2,432.    Elapsed: 0:01:34.\n",
            "  Batch 2,100  of  2,432.    Elapsed: 0:02:17.\n",
            "  Batch 2,200  of  2,432.    Elapsed: 0:03:00.\n",
            "  Batch 2,300  of  2,432.    Elapsed: 0:03:43.\n",
            "  Batch 2,400  of  2,432.    Elapsed: 0:04:26.\n",
            "\n",
            "  Average training loss: 0.06\n",
            "  Training epcoh took: 0:04:40\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8438\n",
            "AR dev Accuracy: 0.8150 \n",
            "FR dev Accuracy: 0.8550 \n",
            "RU dev Accuracy: 0.8850 \n",
            "ZH dev Accuracy: 0.8200 \n",
            "EN dev Accuracy: 0.8610\n",
            "  Validation Loss: 0.673\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "======== Epoch 11 / 15 ========\n",
            "Training...\n",
            "  Batch   100  of  2,432.    Elapsed: 0:00:43.\n",
            "  Batch   200  of  2,432.    Elapsed: 0:01:26.\n",
            "  Batch   300  of  2,432.    Elapsed: 0:02:09.\n",
            "  Batch   400  of  2,432.    Elapsed: 0:02:52.\n",
            "  Batch   500  of  2,432.    Elapsed: 0:03:35.\n",
            "  Batch   600  of  2,432.    Elapsed: 0:04:18.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8450\n",
            "AR dev Accuracy: 0.8450 \n",
            "FR dev Accuracy: 0.8800 \n",
            "RU dev Accuracy: 0.8500 \n",
            "ZH dev Accuracy: 0.8050 \n",
            "EN dev Accuracy: 0.8670\n",
            "  Validation Loss: 0.751\n",
            "  Validation took: 0:00:19\n",
            "  Batch   700  of  2,432.    Elapsed: 0:00:58.\n",
            "  Batch   800  of  2,432.    Elapsed: 0:01:41.\n",
            "  Batch   900  of  2,432.    Elapsed: 0:02:24.\n",
            "  Batch 1,000  of  2,432.    Elapsed: 0:03:07.\n",
            "  Batch 1,100  of  2,432.    Elapsed: 0:03:50.\n",
            "  Batch 1,200  of  2,432.    Elapsed: 0:04:33.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8250\n",
            "AR dev Accuracy: 0.8250 \n",
            "FR dev Accuracy: 0.8650 \n",
            "RU dev Accuracy: 0.8550 \n",
            "ZH dev Accuracy: 0.7550 \n",
            "EN dev Accuracy: 0.8620\n",
            "  Validation Loss: 0.764\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,300  of  2,432.    Elapsed: 0:00:55.\n",
            "  Batch 1,400  of  2,432.    Elapsed: 0:01:38.\n",
            "  Batch 1,500  of  2,432.    Elapsed: 0:02:20.\n",
            "  Batch 1,600  of  2,432.    Elapsed: 0:03:03.\n",
            "  Batch 1,700  of  2,432.    Elapsed: 0:03:46.\n",
            "  Batch 1,800  of  2,432.    Elapsed: 0:04:29.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8250\n",
            "AR dev Accuracy: 0.8300 \n",
            "FR dev Accuracy: 0.8400 \n",
            "RU dev Accuracy: 0.8650 \n",
            "ZH dev Accuracy: 0.7650 \n",
            "EN dev Accuracy: 0.8720\n",
            "  Validation Loss: 0.808\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,900  of  2,432.    Elapsed: 0:00:51.\n",
            "  Batch 2,000  of  2,432.    Elapsed: 0:01:34.\n",
            "  Batch 2,100  of  2,432.    Elapsed: 0:02:17.\n",
            "  Batch 2,200  of  2,432.    Elapsed: 0:03:00.\n",
            "  Batch 2,300  of  2,432.    Elapsed: 0:03:43.\n",
            "  Batch 2,400  of  2,432.    Elapsed: 0:04:26.\n",
            "\n",
            "  Average training loss: 0.06\n",
            "  Training epcoh took: 0:04:40\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8300\n",
            "AR dev Accuracy: 0.8100 \n",
            "FR dev Accuracy: 0.8600 \n",
            "RU dev Accuracy: 0.8750 \n",
            "ZH dev Accuracy: 0.7750 \n",
            "EN dev Accuracy: 0.8560\n",
            "  Validation Loss: 0.719\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "======== Epoch 12 / 15 ========\n",
            "Training...\n",
            "  Batch   100  of  2,432.    Elapsed: 0:00:43.\n",
            "  Batch   200  of  2,432.    Elapsed: 0:01:26.\n",
            "  Batch   300  of  2,432.    Elapsed: 0:02:09.\n",
            "  Batch   400  of  2,432.    Elapsed: 0:02:52.\n",
            "  Batch   500  of  2,432.    Elapsed: 0:03:35.\n",
            "  Batch   600  of  2,432.    Elapsed: 0:04:17.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8325\n",
            "AR dev Accuracy: 0.8200 \n",
            "FR dev Accuracy: 0.8600 \n",
            "RU dev Accuracy: 0.8700 \n",
            "ZH dev Accuracy: 0.7800 \n",
            "EN dev Accuracy: 0.8730\n",
            "  Validation Loss: 0.793\n",
            "  Validation took: 0:00:19\n",
            "  Batch   700  of  2,432.    Elapsed: 0:00:58.\n",
            "  Batch   800  of  2,432.    Elapsed: 0:01:41.\n",
            "  Batch   900  of  2,432.    Elapsed: 0:02:24.\n",
            "  Batch 1,000  of  2,432.    Elapsed: 0:03:07.\n",
            "  Batch 1,100  of  2,432.    Elapsed: 0:03:50.\n",
            "  Batch 1,200  of  2,432.    Elapsed: 0:04:32.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8263\n",
            "AR dev Accuracy: 0.8200 \n",
            "FR dev Accuracy: 0.8450 \n",
            "RU dev Accuracy: 0.8700 \n",
            "ZH dev Accuracy: 0.7700 \n",
            "EN dev Accuracy: 0.8690\n",
            "  Validation Loss: 0.856\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,300  of  2,432.    Elapsed: 0:00:55.\n",
            "  Batch 1,400  of  2,432.    Elapsed: 0:01:37.\n",
            "  Batch 1,500  of  2,432.    Elapsed: 0:02:20.\n",
            "  Batch 1,600  of  2,432.    Elapsed: 0:03:03.\n",
            "  Batch 1,700  of  2,432.    Elapsed: 0:03:46.\n",
            "  Batch 1,800  of  2,432.    Elapsed: 0:04:29.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8287\n",
            "AR dev Accuracy: 0.8050 \n",
            "FR dev Accuracy: 0.8600 \n",
            "RU dev Accuracy: 0.8850 \n",
            "ZH dev Accuracy: 0.7650 \n",
            "EN dev Accuracy: 0.8670\n",
            "  Validation Loss: 0.787\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,900  of  2,432.    Elapsed: 0:00:51.\n",
            "  Batch 2,000  of  2,432.    Elapsed: 0:01:34.\n",
            "  Batch 2,100  of  2,432.    Elapsed: 0:02:17.\n",
            "  Batch 2,200  of  2,432.    Elapsed: 0:03:00.\n",
            "  Batch 2,300  of  2,432.    Elapsed: 0:03:43.\n",
            "  Batch 2,400  of  2,432.    Elapsed: 0:04:26.\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epcoh took: 0:04:39\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8287\n",
            "AR dev Accuracy: 0.8200 \n",
            "FR dev Accuracy: 0.8500 \n",
            "RU dev Accuracy: 0.8700 \n",
            "ZH dev Accuracy: 0.7750 \n",
            "EN dev Accuracy: 0.8600\n",
            "  Validation Loss: 0.811\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "======== Epoch 13 / 15 ========\n",
            "Training...\n",
            "  Batch   100  of  2,432.    Elapsed: 0:00:43.\n",
            "  Batch   200  of  2,432.    Elapsed: 0:01:26.\n",
            "  Batch   300  of  2,432.    Elapsed: 0:02:09.\n",
            "  Batch   400  of  2,432.    Elapsed: 0:02:52.\n",
            "  Batch   500  of  2,432.    Elapsed: 0:03:35.\n",
            "  Batch   600  of  2,432.    Elapsed: 0:04:17.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8275\n",
            "AR dev Accuracy: 0.7700 \n",
            "FR dev Accuracy: 0.8550 \n",
            "RU dev Accuracy: 0.9050 \n",
            "ZH dev Accuracy: 0.7800 \n",
            "EN dev Accuracy: 0.8760\n",
            "  Validation Loss: 0.844\n",
            "  Validation took: 0:00:19\n",
            "  Batch   700  of  2,432.    Elapsed: 0:00:58.\n",
            "  Batch   800  of  2,432.    Elapsed: 0:01:41.\n",
            "  Batch   900  of  2,432.    Elapsed: 0:02:24.\n",
            "  Batch 1,000  of  2,432.    Elapsed: 0:03:07.\n",
            "  Batch 1,100  of  2,432.    Elapsed: 0:03:50.\n",
            "  Batch 1,200  of  2,432.    Elapsed: 0:04:33.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8375\n",
            "AR dev Accuracy: 0.8100 \n",
            "FR dev Accuracy: 0.8950 \n",
            "RU dev Accuracy: 0.8500 \n",
            "ZH dev Accuracy: 0.7950 \n",
            "EN dev Accuracy: 0.8630\n",
            "  Validation Loss: 0.697\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,300  of  2,432.    Elapsed: 0:00:55.\n",
            "  Batch 1,400  of  2,432.    Elapsed: 0:01:38.\n",
            "  Batch 1,500  of  2,432.    Elapsed: 0:02:21.\n",
            "  Batch 1,600  of  2,432.    Elapsed: 0:03:04.\n",
            "  Batch 1,700  of  2,432.    Elapsed: 0:03:47.\n",
            "  Batch 1,800  of  2,432.    Elapsed: 0:04:29.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8225\n",
            "AR dev Accuracy: 0.8150 \n",
            "FR dev Accuracy: 0.8450 \n",
            "RU dev Accuracy: 0.8700 \n",
            "ZH dev Accuracy: 0.7600 \n",
            "EN dev Accuracy: 0.8630\n",
            "  Validation Loss: 0.829\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,900  of  2,432.    Elapsed: 0:00:51.\n",
            "  Batch 2,000  of  2,432.    Elapsed: 0:01:34.\n",
            "  Batch 2,100  of  2,432.    Elapsed: 0:02:17.\n",
            "  Batch 2,200  of  2,432.    Elapsed: 0:03:00.\n",
            "  Batch 2,300  of  2,432.    Elapsed: 0:03:43.\n",
            "  Batch 2,400  of  2,432.    Elapsed: 0:04:26.\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epcoh took: 0:04:40\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8413\n",
            "AR dev Accuracy: 0.8250 \n",
            "FR dev Accuracy: 0.8500 \n",
            "RU dev Accuracy: 0.9100 \n",
            "ZH dev Accuracy: 0.7800 \n",
            "EN dev Accuracy: 0.8640\n",
            "  Validation Loss: 0.737\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "======== Epoch 14 / 15 ========\n",
            "Training...\n",
            "  Batch   100  of  2,432.    Elapsed: 0:00:43.\n",
            "  Batch   200  of  2,432.    Elapsed: 0:01:26.\n",
            "  Batch   300  of  2,432.    Elapsed: 0:02:09.\n",
            "  Batch   400  of  2,432.    Elapsed: 0:02:52.\n",
            "  Batch   500  of  2,432.    Elapsed: 0:03:35.\n",
            "  Batch   600  of  2,432.    Elapsed: 0:04:18.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8438\n",
            "AR dev Accuracy: 0.8100 \n",
            "FR dev Accuracy: 0.8850 \n",
            "RU dev Accuracy: 0.8950 \n",
            "ZH dev Accuracy: 0.7850 \n",
            "EN dev Accuracy: 0.8570\n",
            "  Validation Loss: 0.809\n",
            "  Validation took: 0:00:19\n",
            "  Batch   700  of  2,432.    Elapsed: 0:00:58.\n",
            "  Batch   800  of  2,432.    Elapsed: 0:01:41.\n",
            "  Batch   900  of  2,432.    Elapsed: 0:02:24.\n",
            "  Batch 1,000  of  2,432.    Elapsed: 0:03:07.\n",
            "  Batch 1,100  of  2,432.    Elapsed: 0:03:50.\n",
            "  Batch 1,200  of  2,432.    Elapsed: 0:04:33.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8300\n",
            "AR dev Accuracy: 0.8050 \n",
            "FR dev Accuracy: 0.8650 \n",
            "RU dev Accuracy: 0.8800 \n",
            "ZH dev Accuracy: 0.7700 \n",
            "EN dev Accuracy: 0.8700\n",
            "  Validation Loss: 0.784\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,300  of  2,432.    Elapsed: 0:00:55.\n",
            "  Batch 1,400  of  2,432.    Elapsed: 0:01:38.\n",
            "  Batch 1,500  of  2,432.    Elapsed: 0:02:21.\n",
            "  Batch 1,600  of  2,432.    Elapsed: 0:03:03.\n",
            "  Batch 1,700  of  2,432.    Elapsed: 0:03:46.\n",
            "  Batch 1,800  of  2,432.    Elapsed: 0:04:29.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8475\n",
            "AR dev Accuracy: 0.8550 \n",
            "FR dev Accuracy: 0.8750 \n",
            "RU dev Accuracy: 0.8850 \n",
            "ZH dev Accuracy: 0.7750 \n",
            "EN dev Accuracy: 0.8610\n",
            "  Validation Loss: 0.710\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,900  of  2,432.    Elapsed: 0:00:51.\n",
            "  Batch 2,000  of  2,432.    Elapsed: 0:01:34.\n",
            "  Batch 2,100  of  2,432.    Elapsed: 0:02:17.\n",
            "  Batch 2,200  of  2,432.    Elapsed: 0:03:00.\n",
            "  Batch 2,300  of  2,432.    Elapsed: 0:03:43.\n",
            "  Batch 2,400  of  2,432.    Elapsed: 0:04:26.\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epcoh took: 0:04:39\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8363\n",
            "AR dev Accuracy: 0.8200 \n",
            "FR dev Accuracy: 0.8850 \n",
            "RU dev Accuracy: 0.8750 \n",
            "ZH dev Accuracy: 0.7650 \n",
            "EN dev Accuracy: 0.8620\n",
            "  Validation Loss: 0.819\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "======== Epoch 15 / 15 ========\n",
            "Training...\n",
            "  Batch   100  of  2,432.    Elapsed: 0:00:43.\n",
            "  Batch   200  of  2,432.    Elapsed: 0:01:26.\n",
            "  Batch   300  of  2,432.    Elapsed: 0:02:09.\n",
            "  Batch   400  of  2,432.    Elapsed: 0:02:52.\n",
            "  Batch   500  of  2,432.    Elapsed: 0:03:35.\n",
            "  Batch   600  of  2,432.    Elapsed: 0:04:17.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8413\n",
            "AR dev Accuracy: 0.8200 \n",
            "FR dev Accuracy: 0.8950 \n",
            "RU dev Accuracy: 0.8700 \n",
            "ZH dev Accuracy: 0.7800 \n",
            "EN dev Accuracy: 0.8680\n",
            "  Validation Loss: 0.834\n",
            "  Validation took: 0:00:19\n",
            "  Batch   700  of  2,432.    Elapsed: 0:00:58.\n",
            "  Batch   800  of  2,432.    Elapsed: 0:01:41.\n",
            "  Batch   900  of  2,432.    Elapsed: 0:02:24.\n",
            "  Batch 1,000  of  2,432.    Elapsed: 0:03:07.\n",
            "  Batch 1,100  of  2,432.    Elapsed: 0:03:50.\n",
            "  Batch 1,200  of  2,432.    Elapsed: 0:04:33.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8250\n",
            "AR dev Accuracy: 0.8300 \n",
            "FR dev Accuracy: 0.8900 \n",
            "RU dev Accuracy: 0.8550 \n",
            "ZH dev Accuracy: 0.7250 \n",
            "EN dev Accuracy: 0.8720\n",
            "  Validation Loss: 0.881\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,300  of  2,432.    Elapsed: 0:00:55.\n",
            "  Batch 1,400  of  2,432.    Elapsed: 0:01:38.\n",
            "  Batch 1,500  of  2,432.    Elapsed: 0:02:20.\n",
            "  Batch 1,600  of  2,432.    Elapsed: 0:03:03.\n",
            "  Batch 1,700  of  2,432.    Elapsed: 0:03:46.\n",
            "  Batch 1,800  of  2,432.    Elapsed: 0:04:29.\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8250\n",
            "AR dev Accuracy: 0.8350 \n",
            "FR dev Accuracy: 0.8950 \n",
            "RU dev Accuracy: 0.8300 \n",
            "ZH dev Accuracy: 0.7400 \n",
            "EN dev Accuracy: 0.8640\n",
            "  Validation Loss: 0.811\n",
            "  Validation took: 0:00:19\n",
            "  Batch 1,900  of  2,432.    Elapsed: 0:00:51.\n",
            "  Batch 2,000  of  2,432.    Elapsed: 0:01:34.\n",
            "  Batch 2,100  of  2,432.    Elapsed: 0:02:17.\n",
            "  Batch 2,200  of  2,432.    Elapsed: 0:03:00.\n",
            "  Batch 2,300  of  2,432.    Elapsed: 0:03:43.\n",
            "  Batch 2,400  of  2,432.    Elapsed: 0:04:26.\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epcoh took: 0:04:40\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8325\n",
            "AR dev Accuracy: 0.8300 \n",
            "FR dev Accuracy: 0.8900 \n",
            "RU dev Accuracy: 0.8600 \n",
            "ZH dev Accuracy: 0.7500 \n",
            "EN dev Accuracy: 0.8580\n",
            "  Validation Loss: 0.779\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "Training complete!\n",
            "Total training took 4:53:53 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltISzD9gjlJd",
        "outputId": "b3b5de80-1f24-446b-dcf1-2e1b7477d7c7"
      },
      "source": [
        "print(best_val_accuracy) # same as none\r\n",
        "print(best_val_accuracy_ar)\r\n",
        "print(best_val_accuracy_en)\r\n",
        "print(best_val_accuracy_fr)\r\n",
        "print(best_val_accuracy_ru)\r\n",
        "print(best_val_accuracy_zh)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.87\n",
            "0.875\n",
            "0.889\n",
            "0.91\n",
            "0.925\n",
            "0.82\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}